{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:03:46.612752Z","iopub.execute_input":"2025-12-07T14:03:46.613034Z","iopub.status.idle":"2025-12-07T14:03:46.618747Z","shell.execute_reply.started":"2025-12-07T14:03:46.613019Z","shell.execute_reply":"2025-12-07T14:03:46.617837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n# # ðŸŒŒ Dark Theme Machine Learning Visualizations\n# *20+ Seaborn plots with dark theme for EDA and model analysis*\n\n# %% [code]\n# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import make_classification, make_regression, load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# %% [code]\n# Set dark theme globally\nplt.style.use('dark_background')\nsns.set_style(\"darkgrid\", {\n    'axes.facecolor': '#1e1e1e',\n    'figure.facecolor': '#121212',\n    'grid.color': '#2d2d2d',\n    'axes.edgecolor': '#444444',\n    'axes.labelcolor': '#e0e0e0',\n    'xtick.color': '#cfcfcf',\n    'ytick.color': '#cfcfcf',\n    'text.color': '#e6e6e6'\n})\n\n# Set global font size\nplt.rcParams.update({'font.size': 12})\n\n# %% [code]\n# Generate synthetic datasets\n# Classification dataset\nX_clf, y_clf = make_classification(\n    n_samples=1000, n_features=4, n_informative=3, n_redundant=1,\n    n_clusters_per_class=1, random_state=42\n)\nclf_df = pd.DataFrame(X_clf, columns=[f'Feature_{i}' for i in range(4)])\nclf_df['Target'] = y_clf\nclf_df['Target'] = clf_df['Target'].map({0: 'Class A', 1: 'Class B'})\n\n# Regression dataset\nX_reg, y_reg = make_regression(\n    n_samples=500, n_features=3, noise=15, random_state=42\n)\nreg_df = pd.DataFrame(X_reg, columns=[f'Feature_{i}' for i in range(3)])\nreg_df['Target'] = y_reg\n\n# Time series data\nnp.random.seed(42)\ndates = pd.date_range(start='2020-01-01', periods=100, freq='D')\nts_df = pd.DataFrame({\n    'Date': dates,\n    'Value': np.cumsum(np.random.randn(100)) + 50,\n    'Category': np.random.choice(['A', 'B', 'C'], 100)\n})\n\n# Iris dataset\niris = load_iris()\niris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\niris_df['Species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n\n# %% [markdown]\n# ## 1. Scatter Plot with Hue\n# Visualize feature relationships colored by class\n\n# %% [code]\nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=clf_df, \n    x='Feature_0', \n    y='Feature_1',\n    hue='Target',\n    palette='viridis',\n    alpha=0.8,\n    edgecolor='#333333',\n    s=75\n)\nplt.title('Feature Relationship by Class', fontsize=16, pad=20)\nplt.legend(title='Target Class', facecolor='#2d2d2d')\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 2. Distribution Plot (Hist + KDE)\n# Compare feature distributions between classes\n\n# %% [code]\nplt.figure(figsize=(10, 6))\nsns.histplot(\n    data=clf_df, \n    x='Feature_2', \n    hue='Target',\n    kde=True,\n    bins=30,\n    palette='rocket',\n    alpha=0.6,\n    edgecolor='#333333'\n)\nplt.title('Feature Distribution with Density Estimate', fontsize=16, pad=20)\nplt.legend(title='Class', facecolor='#2d2d2d')\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 3. Box Plot with Outliers\n# Analyze feature distribution across categories\n\n# %% [code]\nplt.figure(figsize=(12, 7))\nsns.boxplot(\n    data=iris_df,\n    x='Species',\n    y='petal length (cm)',\n    palette='mako',\n    width=0.6,\n    flierprops=dict(marker='o', markersize=6, markerfacecolor='#ff6b6b')\n)\nplt.title('Petal Length Distribution by Species', fontsize=16, pad=20)\nplt.ylabel('Petal Length (cm)', labelpad=10)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 4. Violin Plot with Split Hue\n# Compare distributions with density estimation\n\n# %% [code]\nplt.figure(figsize=(12, 7))\nsns.violinplot(\n    data=clf_df,\n    x='Target',\n    y='Feature_3',\n    hue='Target',\n    split=True,\n    inner='quartiles',\n    palette='icefire',\n    width=0.8\n)\nplt.title('Feature Distribution with Density Estimation', fontsize=16, pad=20)\nplt.legend([],[], frameon=False)  # Remove duplicate legend\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 5. Heatmap (Correlation Matrix)\n# Identify feature relationships\n\n# %% [code]\nplt.figure(figsize=(10, 8))\ncorr = iris_df.drop('Species', axis=1).corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(\n    corr,\n    mask=mask,\n    annot=True,\n    fmt=\".2f\",\n    cmap='coolwarm',\n    center=0,\n    square=True,\n    cbar_kws={'shrink': 0.8},\n    annot_kws={'color': '#ffffff'}\n)\nplt.title('Feature Correlation Matrix', fontsize=16, pad=20)\nplt.xticks(rotation=45)\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 6. Pair Plot with Regression\n# Multivariate relationships with regression lines\n\n# %% [code]\nsns.pairplot(\n    iris_df,\n    hue='Species',\n    palette='viridis',\n    diag_kind='kde',\n    plot_kws={'alpha': 0.7, 'edgecolor': '#333333'},\n    diag_kws={'fill': True, 'alpha': 0.3},\n    height=2.5\n)\nplt.suptitle('Feature Relationships by Species', y=1.02, fontsize=16)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 7. Count Plot\n# Class distribution visualization\n\n# %% [code]\nplt.figure(figsize=(10, 6))\nax = sns.countplot(\n    data=clf_df,\n    x='Target',\n    palette='crest',\n    edgecolor='#444444'\n)\nfor p in ax.patches:\n    ax.annotate(f'{int(p.get_height())}', \n                (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='center', \n                xytext=(0, 5), \n                textcoords='offset points',\n                color='#e0e0e0')\nplt.title('Class Distribution', fontsize=16, pad=20)\nplt.ylabel('Count', labelpad=10)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 8. Regression Plot\n# Feature-target relationship with confidence interval\n\n# %% [code]\nplt.figure(figsize=(10, 6))\nsns.regplot(\n    data=reg_df,\n    x='Feature_0',\n    y='Target',\n    color='#64b5f6',\n    scatter_kws={'alpha': 0.6, 'edgecolor': '#333333', 's': 60},\n    line_kws={'color': '#ff7043', 'lw': 2.5},\n    ci=95\n)\nplt.title('Feature vs Target with Confidence Interval', fontsize=16, pad=20)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 9. Residual Plot\n# Model error analysis\n\n# %% [code]\n# Train simple model for residuals\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression().fit(reg_df[['Feature_0']], reg_df['Target'])\nreg_df['Predictions'] = model.predict(reg_df[['Feature_0']])\nreg_df['Residuals'] = reg_df['Target'] - reg_df['Predictions']\n\nplt.figure(figsize=(10, 6))\nsns.residplot(\n    data=reg_df,\n    x='Predictions',\n    y='Residuals',\n    lowess=True,\n    line_kws={'color': '#ff7043', 'lw': 2},\n    scatter_kws={'alpha': 0.7, 'edgecolor': '#444444'}\n)\nplt.axhline(y=0, color='#e0e0e0', linestyle='--', alpha=0.5)\nplt.title('Residual Analysis', fontsize=16, pad=20)\nplt.xlabel('Predicted Values', labelpad=10)\nplt.ylabel('Residuals', labelpad=10)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 10. Confusion Matrix\n# Classification performance visualization\n\n# %% [code]\n# Generate predictions\nX_train, X_test, y_train, y_test = train_test_split(\n    X_clf, y_clf, test_size=0.3, random_state=42\n)\nrf = RandomForestClassifier(random_state=42).fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n\n# Create confusion matrix\ncm = confusion_matrix(y_test, y_pred)\ncm_df = pd.DataFrame(cm, \n                     index=['Actual A', 'Actual B'],\n                     columns=['Predicted A', 'Predicted B'])\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm_df,\n    annot=True,\n    fmt='d',\n    cmap='Blues',\n    cbar=False,\n    annot_kws={'size': 14, 'color': '#ffffff'},\n    linewidths=0.5,\n    linecolor='#2d2d2d'\n)\nplt.title('Confusion Matrix', fontsize=16, pad=20)\nplt.xlabel('Predicted Label', labelpad=10)\nplt.ylabel('True Label', labelpad=10)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 11. ROC Curve\n# Classifier performance across thresholds\n\n# %% [code]\ny_prob = rf.predict_proba(X_test)[:, 1]\nfpr, tpr, _ = roc_curve(y_test, y_prob)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(10, 6))\nplt.plot(fpr, tpr, color='#7e57c2', lw=2.5, \n         label=f'ROC Curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='#e0e0e0', lw=1.5, linestyle='--', alpha=0.7)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', labelpad=10)\nplt.ylabel('True Positive Rate', labelpad=10)\nplt.title('Receiver Operating Characteristic', fontsize=16, pad=20)\nplt.legend(loc=\"lower right\", facecolor='#2d2d2d')\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 12. Cluster Map\n# Hierarchical clustering of correlations\n\n# %% [code]\nplt.figure(figsize=(12, 10))\nsns.clustermap(\n    corr,\n    cmap='coolwarm',\n    center=0,\n    annot=True,\n    fmt=\".2f\",\n    annot_kws={'size': 10, 'color': '#ffffff'},\n    figsize=(10, 8),\n    cbar_pos=(0.02, 0.8, 0.05, 0.18)\n)\nplt.suptitle('Hierarchical Clustered Correlation Matrix', y=1.02, fontsize=16)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 13. Swarm + Box Plot\n# Detailed distribution with individual points\n\n# %% [code]\nplt.figure(figsize=(12, 7))\nsns.boxplot(\n    data=iris_df,\n    x='Species',\n    y='sepal width (cm)',\n    color='#2d2d2d',\n    width=0.4,\n    showfliers=False,\n    zorder=1\n)\nsns.swarmplot(\n    data=iris_df,\n    x='Species',\n    y='sepal width (cm)',\n    size=5,\n    edgecolor='#333333',\n    linewidth=0.5,\n    palette='viridis',\n    zorder=2\n)\nplt.title('Sepal Width Distribution with Individual Points', fontsize=16, pad=20)\nplt.ylabel('Sepal Width (cm)', labelpad=10)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 14. Point Plot with Error Bars\n# Mean estimates with confidence intervals\n\n# %% [code]\nplt.figure(figsize=(10, 6))\nsns.pointplot(\n    data=clf_df,\n    x='Target',\n    y='Feature_1',\n    ci=95,\n    join=True,\n    color='#ff9800',\n    markers='D',\n    scale=1.2,\n    errwidth=1.5,\n    capsize=0.1\n)\nplt.title('Mean Feature Value with 95% CI', fontsize=16, pad=20)\nplt.ylabel('Mean Feature_1 Value', labelpad=10)\nplt.grid(alpha=0.2)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 15. Joint Distribution Plot\n# Bivariate relationship with marginal distributions\n\n# %% [code]\ng = sns.JointGrid(\n    data=reg_df,\n    x='Feature_1',\n    y='Target',\n    height=8,\n    ratio=4,\n    space=0.2\n)\ng.plot_joint(\n    sns.scatterplot, \n    alpha=0.6, \n    edgecolor='#333333',\n    palette='viridis',\n    size=40\n)\ng.plot_marginals(\n    sns.histplot, \n    kde=True, \n    color='#4fc3f7', \n    alpha=0.7,\n    edgecolor='#333333'\n)\ng.ax_joint.set_title('Joint Distribution of Feature and Target', fontsize=16, pad=20)\ng.ax_joint.grid(alpha=0.2)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 16. Time Series with Shaded Area\n# Temporal trends with uncertainty bands\n\n# %% [code]\n# Create rolling statistics\nts_df['Rolling_Mean'] = ts_df['Value'].rolling(window=7).mean()\nts_df['Rolling_Std'] = ts_df['Value'].rolling(window=7).std()\n\nplt.figure(figsize=(14, 7))\nplt.plot(ts_df['Date'], ts_df['Value'], \n         color='#29b6f6', alpha=0.7, linewidth=2, label='Daily Value')\nplt.plot(ts_df['Date'], ts_df['Rolling_Mean'], \n         color='#ff7043', linewidth=3, label='7-Day Rolling Mean')\nplt.fill_between(\n    ts_df['Date'],\n    ts_df['Rolling_Mean'] - ts_df['Rolling_Std'],\n    ts_df['Rolling_Mean'] + ts_df['Rolling_Std'],\n    color='#5c6bc0',\n    alpha=0.3,\n    label='Â±1 Std Dev'\n)\nplt.title('Time Series with Rolling Statistics', fontsize=16, pad=20)\nplt.xlabel('Date', labelpad=10)\nplt.ylabel('Value', labelpad=10)\nplt.legend(facecolor='#2d2d2d')\nplt.grid(alpha=0.2)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 17. Categorical Scatter Plot\n# Relationship between categories and numerical feature\n\n# %% [code]\nplt.figure(figsize=(12, 7))\nsns.stripplot(\n    data=ts_df,\n    x='Category',\n    y='Value',\n    hue='Category',\n    palette='deep',\n    size=6,\n    alpha=0.8,\n    jitter=True,\n    edgecolor='#333333',\n    linewidth=0.5\n)\nplt.title('Value Distribution by Category', fontsize=16, pad=20)\nplt.ylabel('Value', labelpad=10)\nplt.legend(title='Category', facecolor='#2d2d2d')\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 18. KDE Plot with Multiple Distributions\n# Smooth density estimation for multiple groups\n\n# %% [code]\nplt.figure(figsize=(10, 6))\nsns.kdeplot(\n    data=iris_df,\n    x='sepal length (cm)',\n    hue='Species',\n    fill=True,\n    common_norm=False,\n    palette='viridis',\n    alpha=0.6,\n    linewidth=2,\n    edgecolor='#333333'\n)\nplt.title('Sepal Length Density by Species', fontsize=16, pad=20)\nplt.xlabel('Sepal Length (cm)', labelpad=10)\nplt.legend(title='Species', facecolor='#2d2d2d')\nplt.grid(alpha=0.2)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 19. Bar Plot with Error Bars\n# Group comparisons with confidence intervals\n\n# %% [code]\n# Generate grouped data\ngrouped = iris_df.groupby('Species').agg(\n    mean=('petal length (cm)', 'mean'),\n    std=('petal length (cm)', 'std')\n).reset_index()\n\nplt.figure(figsize=(10, 6))\nax = sns.barplot(\n    data=grouped,\n    x='Species',\n    y='mean',\n    yerr=grouped['std'],\n    capsize=0.15,\n    color='#4fc3f7',\n    edgecolor='#333333',\n    alpha=0.8\n)\nplt.title('Mean Petal Length by Species (Â±1 Std Dev)', fontsize=16, pad=20)\nplt.ylabel('Mean Petal Length (cm)', labelpad=10)\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 20. Pair Grid with Custom Plots\n# Advanced multi-plot visualization\n\n# %% [code]\ng = sns.PairGrid(\n    iris_df,\n    hue='Species',\n    palette='viridis',\n    diag_sharey=False,\n    height=2.5,\n    aspect=1.1\n)\ng.map_upper(sns.scatterplot, alpha=0.7, edgecolor='#333333')\ng.map_lower(sns.kdeplot, fill=True, alpha=0.5, common_norm=False)\ng.map_diag(sns.histplot, kde=True, alpha=0.6, edgecolor='#333333')\ng.add_legend(title='Species', facecolor='#2d2d2d')\ng.fig.suptitle('Custom Pair Grid Visualization', y=1.02, fontsize=16)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 21. Radar Chart (Spider Plot)\n# Multivariate comparison across features\n\n# %% [code]\n# Prepare data for radar chart\nfeatures = ['Feature_0', 'Feature_1', 'Feature_2', 'Feature_3']\nradar_df = clf_df.groupby('Target')[features].mean().reset_index()\nradar_df = pd.melt(radar_df, id_vars='Target', var_name='Feature', value_name='Mean')\n\n# Create radar chart\ncategories = features\nN = len(categories)\n\nangles = [n / float(N) * 2 * np.pi for n in range(N)]\nangles += angles[:1]\n\nplt.figure(figsize=(10, 8))\n\nax = plt.subplot(111, polar=True)\nplt.xticks(angles[:-1], categories, color='#e0e0e0', size=12)\n\nax.plot(np.zeros_like(angles), color='#2d2d2d', linewidth=1, linestyle='solid')\nax.fill(np.zeros_like(angles), '#2d2d2d', alpha=0.1)\n\nfor target in radar_df['Target'].unique():\n    values = radar_df[radar_df['Target'] == target]['Mean'].values.flatten().tolist()\n    values += values[:1]\n    ax.plot(angles, values, linewidth=2.5, linestyle='solid', \n            label=target, marker='o', markersize=8)\n    ax.fill(angles, values, alpha=0.15)\n\nplt.title('Mean Feature Values by Class', fontsize=16, pad=30)\nplt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), facecolor='#2d2d2d')\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## 22. Gradient Boosting Feature Importance\n# Model interpretability visualization\n\n# %% [code]\n# Train model and get feature importances\nrf.fit(X_clf, y_clf)\nimportances = pd.Series(rf.feature_importances_, index=[f'Feature_{i}' for i in range(4)])\nimportances = importances.sort_values(ascending=False)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(\n    x=importances.values,\n    y=importances.index,\n    palette='rocket',\n    edgecolor='#333333',\n    orient='h'\n)\nplt.title('Random Forest Feature Importance', fontsize=16, pad=20)\nplt.xlabel('Importance Score', labelpad=10)\nplt.grid(axis='x', alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:03:48.445421Z","iopub.execute_input":"2025-12-07T14:03:48.445714Z","iopub.status.idle":"2025-12-07T14:04:04.242231Z","shell.execute_reply.started":"2025-12-07T14:03:48.445674Z","shell.execute_reply":"2025-12-07T14:04:04.241254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [code]\n# (Only if continuing from fresh session â€” otherwise skip)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import make_classification, load_breast_cancer, load_wine\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import precision_recall_curve, classification_report\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('dark_background')\nsns.set_style(\"darkgrid\", {\n    'axes.facecolor': '#1e1e1e',\n    'figure.facecolor': '#121212',\n    'grid.color': '#2d2d2d',\n    'axes.edgecolor': '#444444',\n    'axes.labelcolor': '#e0e0e0',\n    'xtick.color': '#cfcfcf',\n    'ytick.color': '#cfcfcf',\n    'text.color': '#e6e6e6'\n})\nplt.rcParams.update({'font.size': 12})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:04.243918Z","iopub.execute_input":"2025-12-07T14:04:04.244338Z","iopub.status.idle":"2025-12-07T14:04:04.250268Z","shell.execute_reply.started":"2025-12-07T14:04:04.244303Z","shell.execute_reply":"2025-12-07T14:04:04.249431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load breast cancer dataset\ndata = load_breast_cancer()\nX, y = data.data, data.target\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X, y)\ny_scores = rf.predict_proba(X)[:, 1]\n\nprecision, recall, _ = precision_recall_curve(y, y_scores)\nplt.figure(figsize=(10, 6))\nplt.plot(recall, precision, color='#4db6ac', linewidth=2.5, label='Precision-Recall Curve')\nplt.xlabel('Recall', labelpad=10)\nplt.ylabel('Precision', labelpad=10)\nplt.title('Precision-Recall Curve', fontsize=16, pad=20)\nplt.grid(alpha=0.3)\nplt.legend(facecolor='#2d2d2d')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:04.250793Z","iopub.execute_input":"2025-12-07T14:04:04.251050Z","iopub.status.idle":"2025-12-07T14:04:04.719703Z","shell.execute_reply.started":"2025-12-07T14:04:04.251033Z","shell.execute_reply":"2025-12-07T14:04:04.718732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import learning_curve\n\ntrain_sizes, train_scores, val_scores = learning_curve(\n    RandomForestClassifier(), X, y, cv=5, n_jobs=-1,\n    train_sizes=np.linspace(0.1, 1.0, 10), random_state=42\n)\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\nval_mean = np.mean(val_scores, axis=1)\nval_std = np.std(val_scores, axis=1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(train_sizes, train_mean, 'o-', color='#64b5f6', label='Training Score')\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='#64b5f6')\nplt.plot(train_sizes, val_mean, 'o-', color='#ff7043', label='Validation Score')\nplt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.2, color='#ff7043')\nplt.xlabel('Training Set Size', labelpad=10)\nplt.ylabel('Accuracy', labelpad=10)\nplt.title('Learning Curve', fontsize=16, pad=20)\nplt.legend(facecolor='#2d2d2d')\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:04.721502Z","iopub.execute_input":"2025-12-07T14:04:04.721743Z","iopub.status.idle":"2025-12-07T14:04:07.547620Z","shell.execute_reply.started":"2025-12-07T14:04:04.721728Z","shell.execute_reply":"2025-12-07T14:04:07.546370Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import validation_curve\n\nparam_range = np.arange(10, 201, 20)\ntrain_scores, val_scores = validation_curve(\n    RandomForestClassifier(), X, y, param_name='n_estimators',\n    param_range=param_range, cv=5, n_jobs=-1\n)\n\ntrain_mean = np.mean(train_scores, axis=1)\nval_mean = np.mean(val_scores, axis=1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(param_range, train_mean, 'o-', color='#64b5f6', label='Training Score')\nplt.plot(param_range, val_mean, 'o-', color='#ff7043', label='Validation Score')\nplt.xlabel('Number of Estimators', labelpad=10)\nplt.ylabel('Accuracy', labelpad=10)\nplt.title('Validation Curve: n_estimators', fontsize=16, pad=20)\nplt.legend(facecolor='#2d2d2d')\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:07.548424Z","iopub.execute_input":"2025-12-07T14:04:07.548719Z","iopub.status.idle":"2025-12-07T14:04:10.899377Z","shell.execute_reply.started":"2025-12-07T14:04:07.548671Z","shell.execute_reply":"2025-12-07T14:04:10.898529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def ecdf(data):\n    x = np.sort(data)\n    y = np.arange(1, len(data)+1) / len(data)\n    return x, y\n\nx_ecdf, y_ecdf = ecdf(reg_df['Target'])\nplt.figure(figsize=(10, 6))\nplt.plot(x_ecdf, y_ecdf, marker='.', linestyle='none', color='#4fc3f7', alpha=0.8, markersize=4)\nplt.xlabel('Target Value', labelpad=10)\nplt.ylabel('Cumulative Probability', labelpad=10)\nplt.title('Empirical Cumulative Distribution Function (ECDF)', fontsize=16, pad=20)\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:10.900123Z","iopub.execute_input":"2025-12-07T14:04:10.900330Z","iopub.status.idle":"2025-12-07T14:04:11.138463Z","shell.execute_reply.started":"2025-12-07T14:04:10.900316Z","shell.execute_reply":"2025-12-07T14:04:11.137558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nplt.hexbin(reg_df['Feature_0'], reg_df['Target'], gridsize=30, cmap='viridis', bins='log')\nplt.colorbar(label='log10(N)')\nplt.xlabel('Feature_0', labelpad=10)\nplt.ylabel('Target', labelpad=10)\nplt.title('2D Density with Hexbin', fontsize=16, pad=20)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:11.139432Z","iopub.execute_input":"2025-12-07T14:04:11.139641Z","iopub.status.idle":"2025-12-07T14:04:11.566384Z","shell.execute_reply.started":"2025-12-07T14:04:11.139625Z","shell.execute_reply":"2025-12-07T14:04:11.564835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from matplotlib import cm\n\n# Prepare data\niris_melt = iris_df.melt(id_vars='Species', var_name='Measurement', value_name='Value')\ng = sns.FacetGrid(iris_melt, row='Measurement', hue='Species', aspect=5, height=1.2, palette='viridis')\ng.map(sns.kdeplot, 'Value', fill=True, alpha=0.7, clip_on=False)\ng.map(plt.axhline, y=0, lw=2, clip_on=False)\ng.set_titles('')\ng.set(yticks=[], ylabel='')\ng.despine(bottom=True)\nfor ax, title in zip(g.axes.flat, iris_melt['Measurement'].unique()):\n    ax.text(0.02, 0.8, title, transform=ax.transAxes, fontweight='bold', color='#e0e0e0')\nplt.suptitle('Ridgeline Plot: Feature Distributions by Species', y=1.02, fontsize=16)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:11.567823Z","iopub.execute_input":"2025-12-07T14:04:11.568144Z","iopub.status.idle":"2025-12-07T14:04:12.614327Z","shell.execute_reply.started":"2025-12-07T14:04:11.568124Z","shell.execute_reply":"2025-12-07T14:04:12.613322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.seed(42)\nbubble_df = pd.DataFrame({\n    'x': np.random.randn(50),\n    'y': np.random.randn(50),\n    'size': np.random.randint(100, 2000, 50),\n    'color': np.random.rand(50)\n})\n\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(\n    bubble_df['x'], bubble_df['y'],\n    s=bubble_df['size'],\n    c=bubble_df['color'],\n    alpha=0.6,\n    cmap='plasma',\n    edgecolors='#333333',\n    linewidth=0.5\n)\nplt.colorbar(scatter, label='Color Intensity')\nplt.xlabel('X Position', labelpad=10)\nplt.ylabel('Y Position', labelpad=10)\nplt.title('Bubble Plot with Variable Size & Color', fontsize=16, pad=20)\nplt.grid(alpha=0.2)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:12.615135Z","iopub.execute_input":"2025-12-07T14:04:12.615308Z","iopub.status.idle":"2025-12-07T14:04:12.956925Z","shell.execute_reply.started":"2025-12-07T14:04:12.615295Z","shell.execute_reply":"2025-12-07T14:04:12.955993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pandas.plotting import parallel_coordinates\n\nwine = load_wine()\nwine_df = pd.DataFrame(wine.data, columns=wine.feature_names)\nwine_df['Target'] = wine.target\nwine_df['Target'] = wine_df['Target'].map({0: 'Class 0', 1: 'Class 1', 2: 'Class 2'})\n\n# Sample and normalize\nsample = wine_df.sample(100, random_state=42)\nfeatures = ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium']\nnorm_sample = sample[features + ['Target']].copy()\nfor col in features:\n    norm_sample[col] = (norm_sample[col] - norm_sample[col].min()) / (norm_sample[col].max() - norm_sample[col].min())\n\nplt.figure(figsize=(12, 7))\nparallel_coordinates(norm_sample, 'Target', color=['#64b5f6', '#ff7043', '#4db6ac'], linewidth=1.2, alpha=0.7)\nplt.title('Parallel Coordinates Plot (Normalized)', fontsize=16, pad=20)\nplt.ylabel('Normalized Value', labelpad=10)\nplt.xticks(rotation=30)\nplt.grid(alpha=0.2)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:12.959183Z","iopub.execute_input":"2025-12-07T14:04:12.959397Z","iopub.status.idle":"2025-12-07T14:04:13.617652Z","shell.execute_reply.started":"2025-12-07T14:04:12.959381Z","shell.execute_reply":"2025-12-07T14:04:13.616326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pandas.plotting import andrews_curves\n\nplt.figure(figsize=(12, 7))\nandrews_curves(norm_sample, 'Target', color=['#64b5f6', '#ff7043', '#4db6ac'], alpha=0.7)\nplt.title('Andrews Curves for Class Separation', fontsize=16, pad=20)\nplt.grid(alpha=0.2)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:13.618800Z","iopub.execute_input":"2025-12-07T14:04:13.619059Z","iopub.status.idle":"2025-12-07T14:04:14.026961Z","shell.execute_reply.started":"2025-12-07T14:04:13.619044Z","shell.execute_reply":"2025-12-07T14:04:14.026052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.calibration import calibration_curve\n\nfraction_of_positives, mean_predicted_value = calibration_curve(y, y_scores, n_bins=10)\n\nplt.figure(figsize=(10, 6))\nplt.plot(mean_predicted_value, fraction_of_positives, \"s-\", color='#4db6ac', label='Random Forest')\nplt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\nplt.xlabel('Mean Predicted Probability', labelpad=10)\nplt.ylabel('Fraction of Positives', labelpad=10)\nplt.title('Calibration Curve', fontsize=16, pad=20)\nplt.legend(facecolor='#2d2d2d')\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:14.028329Z","iopub.execute_input":"2025-12-07T14:04:14.028822Z","iopub.status.idle":"2025-12-07T14:04:14.280308Z","shell.execute_reply.started":"2025-12-07T14:04:14.028798Z","shell.execute_reply":"2025-12-07T14:04:14.279170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.inspection import PartialDependenceDisplay\n\nfeatures = [0, 1]  # First two features\nplt.figure(figsize=(10, 6))\nPartialDependenceDisplay.from_estimator(\n    rf, X, features, \n    grid_resolution=50,\n    ax=plt.gca(),\n    line_kw={'color': '#ff7043', 'linewidth': 2.5}\n)\nplt.title('Partial Dependence Plot', fontsize=16, pad=20)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:14.281388Z","iopub.execute_input":"2025-12-07T14:04:14.281721Z","iopub.status.idle":"2025-12-07T14:04:15.414994Z","shell.execute_reply.started":"2025-12-07T14:04:14.281671Z","shell.execute_reply":"2025-12-07T14:04:15.413624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.inspection import permutation_importance\n\nperm_importance = permutation_importance(rf, X, y, n_repeats=10, random_state=42)\nperm_df = pd.DataFrame({\n    'feature': data.feature_names,\n    'importance': perm_importance.importances_mean\n}).sort_values('importance', ascending=False).head(10)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(\n    data=perm_df,\n    x='importance',\n    y='feature',\n    palette='rocket_r',\n    orient='h'\n)\nplt.title('Permutation Feature Importance (Top 10)', fontsize=16, pad=20)\nplt.xlabel('Mean Importance Decrease', labelpad=10)\nplt.grid(axis='x', alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:15.415929Z","iopub.execute_input":"2025-12-07T14:04:15.416213Z","iopub.status.idle":"2025-12-07T14:04:17.781948Z","shell.execute_reply.started":"2025-12-07T14:04:15.416197Z","shell.execute_reply":"2025-12-07T14:04:17.780579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Simulate SHAP values using feature importances scaled by sign randomness\nnp.random.seed(42)\nshap_values = np.random.randn(100, 4) * np.array(rf.feature_importances_[:4])\n\nplt.figure(figsize=(10, 6))\nfor i in range(4):\n    plt.scatter([i] * 100, shap_values[:, i], \n                c=shap_values[:, i], \n                cmap='coolwarm', \n                alpha=0.7, \n                s=30,\n                edgecolor='#333333',\n                linewidth=0.3)\nplt.axhline(0, color='#e0e0e0', linestyle='--', alpha=0.5)\nplt.xticks(range(4), [f'Feature_{i}' for i in range(4)], rotation=30)\nplt.ylabel('Impact on Prediction', labelpad=10)\nplt.title('Simulated SHAP Summary Plot', fontsize=16, pad=20)\nplt.colorbar(label='SHAP Value')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:17.783185Z","iopub.execute_input":"2025-12-07T14:04:17.783622Z","iopub.status.idle":"2025-12-07T14:04:18.070224Z","shell.execute_reply.started":"2025-12-07T14:04:17.783583Z","shell.execute_reply":"2025-12-07T14:04:18.069042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy import stats\n\nplt.figure(figsize=(8, 8))\nstats.probplot(reg_df['Target'], dist=\"norm\", plot=plt)\nplt.title('Q-Q Plot: Target vs Normal Distribution', fontsize=16, pad=20)\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:18.071111Z","iopub.execute_input":"2025-12-07T14:04:18.071379Z","iopub.status.idle":"2025-12-07T14:04:18.308595Z","shell.execute_reply.started":"2025-12-07T14:04:18.071359Z","shell.execute_reply":"2025-12-07T14:04:18.307530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sort by predicted probability\ndf_gain = pd.DataFrame({'y_true': y, 'y_score': y_scores})\ndf_gain = df_gain.sort_values('y_score', ascending=False).reset_index(drop=True)\ndf_gain['cumulative_positive'] = df_gain['y_true'].cumsum()\ndf_gain['percentile'] = np.arange(1, len(df_gain) + 1) / len(df_gain)\n\nplt.figure(figsize=(10, 6))\nplt.plot(df_gain['percentile'], df_gain['cumulative_positive'] / df_gain['cumulative_positive'].max(), \n         color='#4db6ac', linewidth=2.5, label='Model')\nplt.plot([0, 1], [0, 1], 'k--', alpha=0.7, label='Random')\nplt.xlabel('Percentage of Population', labelpad=10)\nplt.ylabel('Cumulative % of Positive Cases', labelpad=10)\nplt.title('Cumulative Gain Chart', fontsize=16, pad=20)\nplt.legend(facecolor='#2d2d2d')\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:18.309502Z","iopub.execute_input":"2025-12-07T14:04:18.309779Z","iopub.status.idle":"2025-12-07T14:04:18.565526Z","shell.execute_reply.started":"2025-12-07T14:04:18.309759Z","shell.execute_reply":"2025-12-07T14:04:18.564256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate lift\ndf_gain['lift'] = (df_gain['cumulative_positive'] / df_gain.index) / (df_gain['y_true'].mean())\n\nplt.figure(figsize=(10, 6))\nplt.plot(df_gain['percentile'], df_gain['lift'], color='#ff7043', linewidth=2.5)\nplt.xlabel('Percentage of Population', labelpad=10)\nplt.ylabel('Lift', labelpad=10)\nplt.title('Lift Chart', fontsize=16, pad=20)\nplt.axhline(y=1, color='#e0e0e0', linestyle='--', alpha=0.7)\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:18.566491Z","iopub.execute_input":"2025-12-07T14:04:18.566909Z","iopub.status.idle":"2025-12-07T14:04:18.791746Z","shell.execute_reply.started":"2025-12-07T14:04:18.566887Z","shell.execute_reply":"2025-12-07T14:04:18.790654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cv_scores = cross_val_score(rf, X, y, cv=10)\nplt.figure(figsize=(10, 6))\nsns.histplot(cv_scores, kde=True, bins=8, color='#64b5f6', alpha=0.7, edgecolor='#333333')\nplt.axvline(cv_scores.mean(), color='#ff7043', linestyle='--', linewidth=2, label=f'Mean: {cv_scores.mean():.3f}')\nplt.xlabel('CV Accuracy Score', labelpad=10)\nplt.ylabel('Frequency', labelpad=10)\nplt.title('Cross-Validation Score Distribution', fontsize=16, pad=20)\nplt.legend(facecolor='#2d2d2d')\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:18.792536Z","iopub.execute_input":"2025-12-07T14:04:18.792779Z","iopub.status.idle":"2025-12-07T14:04:20.815527Z","shell.execute_reply.started":"2025-12-07T14:04:18.792759Z","shell.execute_reply":"2025-12-07T14:04:20.814333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cv_scores = cross_val_score(rf, X, y, cv=10)\nplt.figure(figsize=(10, 6))\nsns.histplot(cv_scores, kde=True, bins=8, color='#64b5f6', alpha=0.7, edgecolor='#333333')\nplt.axvline(cv_scores.mean(), color='#ff7043', linestyle='--', linewidth=2, label=f'Mean: {cv_scores.mean():.3f}')\nplt.xlabel('CV Accuracy Score', labelpad=10)\nplt.ylabel('Frequency', labelpad=10)\nplt.title('Cross-Validation Score Distribution', fontsize=16, pad=20)\nplt.legend(facecolor='#2d2d2d')\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:20.816875Z","iopub.execute_input":"2025-12-07T14:04:20.817115Z","iopub.status.idle":"2025-12-07T14:04:22.839552Z","shell.execute_reply.started":"2025-12-07T14:04:20.817098Z","shell.execute_reply":"2025-12-07T14:04:22.838392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n\nX_clust = iris_df.drop('Species', axis=1)\nkmeans = KMeans(n_clusters=3, random_state=42)\ncluster_labels = kmeans.fit_predict(X_clust)\n\nsilhouette_avg = silhouette_score(X_clust, cluster_labels)\nsample_silhouette_values = silhouette_samples(X_clust, cluster_labels)\n\nplt.figure(figsize=(10, 7))\ny_lower = 10\nfor i in range(3):\n    ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n    ith_cluster_silhouette_values.sort()\n    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n    y_upper = y_lower + size_cluster_i\n    color = sns.color_palette(\"viridis\", 3)[i]\n    plt.fill_betweenx(np.arange(y_lower, y_upper),\n                      0, ith_cluster_silhouette_values,\n                      facecolor=color, edgecolor=color, alpha=0.7)\n    plt.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n    y_lower = y_upper + 10\n\nplt.axvline(x=silhouette_avg, color=\"#ff7043\", linestyle=\"--\", label=f'Avg Silhouette: {silhouette_avg:.3f}')\nplt.xlabel('Silhouette Coefficient Values', labelpad=10)\nplt.ylabel('Cluster Label', labelpad=10)\nplt.title('Silhouette Analysis for K=3', fontsize=16, pad=20)\nplt.legend(facecolor='#2d2d2d')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:22.840372Z","iopub.execute_input":"2025-12-07T14:04:22.840553Z","iopub.status.idle":"2025-12-07T14:04:23.314612Z","shell.execute_reply.started":"2025-12-07T14:04:22.840540Z","shell.execute_reply":"2025-12-07T14:04:23.313816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Simulate p-values for features\nnp.random.seed(42)\npvals = 10 ** (-np.random.uniform(0, 5, len(data.feature_names)))\nneg_log_pvals = -np.log10(pvals)\nmanhattan_df = pd.DataFrame({\n    'feature': data.feature_names,\n    'pval': neg_log_pvals,\n    'chrom': np.random.choice(['Chr1', 'Chr2', 'Chr3'], len(pvals))\n})\n\nplt.figure(figsize=(14, 6))\ncolors = ['#64b5f6', '#ff7043', '#4db6ac']\nfor i, chrom in enumerate(manhattan_df['chrom'].unique()):\n    idx = manhattan_df['chrom'] == chrom\n    plt.scatter(np.where(idx)[0], manhattan_df.loc[idx, 'pval'], \n                color=colors[i], label=chrom, alpha=0.8, s=40)\n\nplt.axhline(-np.log10(0.05), color='#ff5252', linestyle='--', label='Significance Threshold (0.05)')\nplt.xlabel('Features', labelpad=10)\nplt.ylabel('-log10(p-value)', labelpad=10)\nplt.title('Manhattan Plot (Simulated Feature Significance)', fontsize=16, pad=20)\nplt.legend(facecolor='#2d2d2d')\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:23.315335Z","iopub.execute_input":"2025-12-07T14:04:23.315544Z","iopub.status.idle":"2025-12-07T14:04:23.645074Z","shell.execute_reply.started":"2025-12-07T14:04:23.315526Z","shell.execute_reply":"2025-12-07T14:04:23.643593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Simulate base value and contributions\nbase = 0.5\ncontributions = np.random.randn(5) * 0.1\nfeatures = [f'Feature_{i}' for i in range(5)]\nvalues = [base] + list(np.cumsum(contributions) + base)\nchanges = [0] + list(contributions)\n\nplt.figure(figsize=(12, 7))\ncolors = ['#64b5f6' if x > 0 else '#ff7043' for x in changes]\n\nfor i in range(1, len(values)):\n    plt.bar(i-1, changes[i], bottom=values[i-1], \n            color=colors[i], edgecolor='#333333', width=0.6)\n    plt.text(i-1, values[i-1] + changes[i]/2, f'{changes[i]:+.2f}', \n             ha='center', va='center', color='white', fontweight='bold')\n\nplt.plot(range(len(values)), values, 'o-', color='#e0e0e0', markersize=8)\nplt.axhline(base, color='#aaaaaa', linestyle='--', alpha=0.5)\nplt.xticks(range(len(features)), features, rotation=45)\nplt.ylabel('Prediction Value', labelpad=10)\nplt.title('Waterfall Chart: Prediction Breakdown', fontsize=16, pad=20)\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:04:23.646196Z","iopub.execute_input":"2025-12-07T14:04:23.646548Z","iopub.status.idle":"2025-12-07T14:04:23.879448Z","shell.execute_reply.started":"2025-12-07T14:04:23.646527Z","shell.execute_reply":"2025-12-07T14:04:23.878465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}