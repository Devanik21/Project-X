{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2821d627",
   "metadata": {
    "id": "MYFDuAcYnPkv",
    "papermill": {
     "duration": 0.007011,
     "end_time": "2025-12-25T09:43:53.568453",
     "exception": false,
     "start_time": "2025-12-25T09:43:53.561442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#             best_acc = soul.evolve(X_evo_v, y_evo_v, generations=50)\n",
    "\n",
    "\n",
    "Increase gen for Stability and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fab81b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:43:53.581255Z",
     "iopub.status.busy": "2025-12-25T09:43:53.581010Z",
     "iopub.status.idle": "2025-12-25T09:43:58.813278Z",
     "shell.execute_reply": "2025-12-25T09:43:58.812526Z"
    },
    "id": "9YSRxXeVGMB0",
    "outputId": "423e19dc-7543-4fef-fe3d-d55b07b5c473",
    "papermill": {
     "duration": 5.240295,
     "end_time": "2025-12-25T09:43:58.814418",
     "exception": false,
     "start_time": "2025-12-25T09:43:53.574123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU DETECTED: HRF v26.0 'Holo-Fractal Universe' Active\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "from scipy.optimize import minimize\n",
    "from scipy.fft import fft\n",
    "\n",
    "# Sklearn Core & Metrics\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer, StandardScaler\n",
    "\n",
    "# Sklearn Transformers\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "# Sklearn Models\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Gradient Boosting\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# GPU CHECK\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"✅ GPU DETECTED: HRF v26.0 'Holo-Fractal Universe' Active\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ GPU NOT FOUND: Running in Slow Mode\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. THE HOLOGRAPHIC SOUL (Unit 3 - Multiverse Edition) ---\n",
    "class HolographicSoulUnit(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k=15):\n",
    "        self.k = k\n",
    "        self.dna_ = {\n",
    "            'freq': 2.0, 'gamma': 0.5, 'power': 2.0,\n",
    "            'metric': 'minkowski', 'p': 2.0,\n",
    "            'phase': 0.0, 'dim_reduction': 'none'\n",
    "        }\n",
    "        self.projector_ = None\n",
    "        self.X_raw_source_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self._apply_projection(X)\n",
    "        self.y_train_ = y\n",
    "        return self\n",
    "\n",
    "    def _apply_projection(self, X):\n",
    "        if self.dna_['dim_reduction'] == 'holo':\n",
    "            n_components = max(2, int(np.sqrt(X.shape[1])))\n",
    "            self.projector_ = GaussianRandomProjection(n_components=n_components, random_state=42)\n",
    "            self.X_train_ = self.projector_.fit_transform(X)\n",
    "        elif self.dna_['dim_reduction'] == 'pca':\n",
    "            n_components = max(2, int(np.sqrt(X.shape[1])))\n",
    "            self.projector_ = PCA(n_components=n_components, random_state=42)\n",
    "            self.X_train_ = self.projector_.fit_transform(X)\n",
    "        else:\n",
    "            self.projector_ = None\n",
    "            self.X_train_ = X\n",
    "\n",
    "    def set_raw_source(self, X):\n",
    "        self.X_raw_source_ = X\n",
    "\n",
    "    def evolve(self, X_val, y_val, generations=1000):\n",
    "        n_universes = 10\n",
    "        best_acc = self.score(X_val, y_val)\n",
    "        best_dna = self.dna_.copy()\n",
    "\n",
    "        # Smart Init\n",
    "        if GPU_AVAILABLE:\n",
    "            sample_X = cp.asarray(self.X_train_[:100])\n",
    "            dists = cp.mean(cp.linalg.norm(sample_X[:, None, :] - sample_X[None, :, :], axis=2))\n",
    "            median_dist = float(cp.asnumpy(dists))\n",
    "        else:\n",
    "            median_dist = 1.0\n",
    "\n",
    "        if median_dist > 0:\n",
    "            best_dna['freq'] = 3.14159 / median_dist\n",
    "\n",
    "        for i in range(generations):\n",
    "            candidates = []\n",
    "            for _ in range(n_universes):\n",
    "                mutant = best_dna.copy()\n",
    "                trait = random.choice(list(mutant.keys()))\n",
    "                if trait == 'freq': mutant['freq'] *= np.random.uniform(0.8, 1.25)\n",
    "                elif trait == 'gamma': mutant['gamma'] = np.random.uniform(0.1, 5.0)\n",
    "                elif trait == 'power': mutant['power'] = random.choice([0.5, 1.0, 2.0, 3.0, 4.0, 6.0])\n",
    "                elif trait == 'p': mutant['p'] = np.clip(mutant['p'] + np.random.uniform(-0.5, 0.5), 0.5, 8.0)\n",
    "                elif trait == 'phase': mutant['phase'] = np.random.uniform(0, 3.14159)\n",
    "                elif trait == 'dim_reduction': mutant['dim_reduction'] = random.choice(['none', 'holo', 'pca'])\n",
    "                candidates.append(mutant)\n",
    "\n",
    "            generation_best_acc = -1\n",
    "            generation_best_dna = None\n",
    "\n",
    "            for mutant_dna in candidates:\n",
    "                self.dna_ = mutant_dna\n",
    "                if self.X_raw_source_ is not None: self._apply_projection(self.X_raw_source_)\n",
    "                acc = self.score(X_val, y_val)\n",
    "                if acc > generation_best_acc:\n",
    "                    generation_best_acc = acc\n",
    "                    generation_best_dna = mutant_dna\n",
    "\n",
    "            if generation_best_acc >= best_acc:\n",
    "                best_acc = generation_best_acc\n",
    "                best_dna = generation_best_dna\n",
    "            else:\n",
    "                self.dna_ = best_dna\n",
    "                if self.X_raw_source_ is not None: self._apply_projection(self.X_raw_source_)\n",
    "\n",
    "        self.dna_ = best_dna\n",
    "        return best_acc\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.projector_ is not None: X_curr = self.projector_.transform(X)\n",
    "        else: X_curr = X\n",
    "        if GPU_AVAILABLE: return self._predict_proba_gpu(X_curr)\n",
    "        else: return np.zeros((len(X), len(self.classes_)))\n",
    "\n",
    "    def _predict_proba_gpu(self, X):\n",
    "        X_tr_g = cp.asarray(self.X_train_, dtype=cp.float32)\n",
    "        X_te_g = cp.asarray(X, dtype=cp.float32)\n",
    "        y_tr_g = cp.asarray(self.y_train_)\n",
    "\n",
    "        n_test = len(X_te_g)\n",
    "        n_classes = len(self.classes_)\n",
    "        probas = []\n",
    "        batch_size = 256\n",
    "\n",
    "        p_norm = self.dna_.get('p', 2.0)\n",
    "        gamma = self.dna_['gamma']\n",
    "        freq = self.dna_['freq']\n",
    "        power = self.dna_['power']\n",
    "        phase = self.dna_.get('phase', 0.0)\n",
    "\n",
    "        for i in range(0, n_test, batch_size):\n",
    "            end = min(i + batch_size, n_test)\n",
    "            batch_te = X_te_g[i:end]\n",
    "            diff = cp.abs(batch_te[:, None, :] - X_tr_g[None, :, :])\n",
    "            dists = cp.sum(cp.power(diff, p_norm), axis=2)\n",
    "            dists = cp.power(dists, 1.0/p_norm)\n",
    "            top_k_idx = cp.argsort(dists, axis=1)[:, :self.k]\n",
    "            row_idx = cp.arange(len(batch_te))[:, None]\n",
    "            top_dists = dists[row_idx, top_k_idx]\n",
    "            top_y = y_tr_g[top_k_idx]\n",
    "\n",
    "            cosine_term = 1.0 + cp.cos(freq * top_dists + phase)\n",
    "            cosine_term = cp.maximum(cosine_term, 0.0)\n",
    "            w = cp.exp(-gamma * (top_dists**2)) * cosine_term\n",
    "            w = cp.power(w, power)\n",
    "\n",
    "            batch_probs = cp.zeros((len(batch_te), n_classes))\n",
    "            for c_idx, cls in enumerate(self.classes_):\n",
    "                class_mask = (top_y == cls)\n",
    "                batch_probs[:, c_idx] = cp.sum(w * class_mask, axis=1)\n",
    "\n",
    "            total_energy = cp.sum(batch_probs, axis=1, keepdims=True)\n",
    "            total_energy[total_energy == 0] = 1.0\n",
    "            batch_probs /= total_energy\n",
    "            probas.append(batch_probs)\n",
    "            del batch_te, dists, diff, top_k_idx, top_dists, w, cosine_term\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "        return cp.asnumpy(cp.concatenate(probas))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))\n",
    "\n",
    "# --- 3. THE QUANTUM FIELD (Unit 4 - Reserve) ---\n",
    "class QuantumFieldUnit(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.rbf_feature_ = RBFSampler(n_components=100, random_state=42)\n",
    "        self.classifier_ = RidgeClassifier(alpha=1.0)\n",
    "        self.classes_ = None\n",
    "        self.dna_ = {'gamma': 1.0, 'n_components': 100}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.rbf_feature_.set_params(gamma=self.dna_['gamma'], n_components=self.dna_['n_components'])\n",
    "        X_quantum = self.rbf_feature_.fit_transform(X)\n",
    "        self.classifier_.fit(X_quantum, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_quantum = self.rbf_feature_.transform(X)\n",
    "        d = self.classifier_.decision_function(X_quantum)\n",
    "        if len(self.classes_) == 2:\n",
    "            probs = 1 / (1 + np.exp(-d))\n",
    "            return np.column_stack([1-probs, probs])\n",
    "        else:\n",
    "            exp_d = np.exp(d - np.max(d, axis=1, keepdims=True))\n",
    "            return exp_d / np.sum(exp_d, axis=1, keepdims=True)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.classes_[np.argmax(self.predict_proba(X), axis=1)])\n",
    "\n",
    "# --- 4. THE ENTROPY MAXWELL (Unit 5 - Reserve) ---\n",
    "class EntropyMaxwellUnit(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.models_ = {}\n",
    "        self.classes_ = None\n",
    "        self.priors_ = None\n",
    "        self.dna_ = {'n_components': 1}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.models_ = {}\n",
    "        self.priors_ = {}\n",
    "        n_samples = len(y)\n",
    "        for cls in self.classes_:\n",
    "            X_c = X[y == cls]\n",
    "            if len(X_c) < 2:\n",
    "                self.priors_[cls] = 0.0\n",
    "                continue\n",
    "            self.priors_[cls] = len(X_c) / n_samples\n",
    "            n_comp = min(self.dna_['n_components'], len(X_c))\n",
    "            gmm = GaussianMixture(n_components=n_comp, covariance_type='full',\n",
    "                                  reg_covar=1e-4, random_state=42)\n",
    "            gmm.fit(X_c)\n",
    "            self.models_[cls] = gmm\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probs = np.zeros((len(X), len(self.classes_)))\n",
    "        for i, cls in enumerate(self.classes_):\n",
    "            if cls in self.models_:\n",
    "                log_prob = self.models_[cls].score_samples(X)\n",
    "                log_prob = np.clip(log_prob, -100, 100)\n",
    "                probs[:, i] = np.exp(log_prob) * self.priors_[cls]\n",
    "        total = np.sum(probs, axis=1, keepdims=True) + 1e-10\n",
    "        return probs / total\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.classes_[np.argmax(self.predict_proba(X), axis=1)])\n",
    "\n",
    "# --- 5. THE OMNI-KERNEL NEXUS (Unit 6 - Reserve) ---\n",
    "class OmniKernelUnit(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.model_ = None\n",
    "        self.classes_ = None\n",
    "        self.dna_ = {'kernel': 'rbf', 'C': 1.0, 'gamma': 'scale', 'degree': 3, 'coef0': 0.0}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.model_ = SVC(\n",
    "            kernel=self.dna_['kernel'], C=self.dna_['C'], gamma=self.dna_['gamma'],\n",
    "            degree=self.dna_['degree'], coef0=self.dna_['coef0'],\n",
    "            probability=True, random_state=42, cache_size=500\n",
    "        )\n",
    "        self.model_.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model_.predict_proba(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.model_.score(X, y)\n",
    "\n",
    "# --- 18. THE GOLDEN SPIRAL (Unit 18 - Nature's Code) ---\n",
    "class GoldenSpiralUnit(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k=21): # k=21 is a Fibonacci number\n",
    "        self.k = k\n",
    "        self.PHI = 1.6180339887\n",
    "        self.classes_ = None\n",
    "        self.X_train_ = None\n",
    "        self.y_train_ = None\n",
    "        # DNA: The mutable parameters of the spiral\n",
    "        self.dna_ = {\n",
    "            'resonance': 1.618,  # The spiral tightness\n",
    "            'decay': 1.0,        # How fast influence drops\n",
    "            'shift': 0.0         # Rotation of the spiral\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.X_train_ = np.array(X, dtype=np.float32)\n",
    "        self.y_train_ = np.array(y)\n",
    "        return self\n",
    "\n",
    "    def evolve(self, X_val, y_val, generations=50):\n",
    "        \"\"\"\n",
    "        Self-evolves the spiral shape to maximize harmony (accuracy)\n",
    "        on the validation set.\n",
    "        \"\"\"\n",
    "        best_acc = self.score(X_val, y_val)\n",
    "        best_dna = self.dna_.copy()\n",
    "\n",
    "        # Try mutating the spiral geometry\n",
    "        for _ in range(generations):\n",
    "            mutant = best_dna.copy()\n",
    "            trait = random.choice(['resonance', 'decay', 'shift'])\n",
    "\n",
    "            if trait == 'resonance':\n",
    "                # Mutate around Phi\n",
    "                mutant['resonance'] *= np.random.uniform(0.9, 1.1)\n",
    "            elif trait == 'decay':\n",
    "                mutant['decay'] = np.random.uniform(0.5, 3.0)\n",
    "            elif trait == 'shift':\n",
    "                mutant['shift'] += np.random.uniform(-0.5, 0.5)\n",
    "\n",
    "            self.dna_ = mutant\n",
    "            acc = self.score(X_val, y_val)\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_dna = mutant\n",
    "            else:\n",
    "                self.dna_ = best_dna # Revert\n",
    "\n",
    "        return best_acc\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # We implement the Phi-Weighted KNN manually for speed/control\n",
    "        if GPU_AVAILABLE:\n",
    "            return self._predict_proba_gpu(X)\n",
    "\n",
    "        n_test = len(X)\n",
    "        n_classes = len(self.classes_)\n",
    "        probs = np.zeros((n_test, n_classes))\n",
    "\n",
    "        # CPU Slow Path (Fallback)\n",
    "        # Note: For production, use GPU path or optimized cdist\n",
    "        for i, x_query in enumerate(X):\n",
    "            # 1. Phi-Minkowski Distance (p = 1.618)\n",
    "            diff = np.abs(self.X_train_ - x_query)\n",
    "            dists = np.sum(diff ** self.PHI, axis=1) ** (1/self.PHI)\n",
    "\n",
    "            # 2. Find Fibonacci Neighbors\n",
    "            idx = np.argsort(dists)[:self.k]\n",
    "            nearest_dists = dists[idx]\n",
    "            nearest_y = self.y_train_[idx]\n",
    "\n",
    "            # 3. The Golden Spiral Kernel\n",
    "            # Weight = 1 / (d^phi) * Cosine_Resonance\n",
    "            # This mimics constructive interference along a spiral\n",
    "            w = (1.0 / (nearest_dists ** self.PHI + 1e-9))\n",
    "\n",
    "            # Add Logarithmic Spiral Rotation\n",
    "            # Nature grows logarithmically: r = a * e^(k * theta)\n",
    "            w *= (1.0 + 0.5 * np.cos(np.log(nearest_dists + 1e-9) * self.dna_['resonance'] + self.dna_['shift']))\n",
    "            w = np.maximum(w, 0) # Remove destructive interference (negative weights)\n",
    "\n",
    "            for c_i, cls in enumerate(self.classes_):\n",
    "                probs[i, c_i] = np.sum(w[nearest_y == cls])\n",
    "\n",
    "        # Normalize\n",
    "        sums = np.sum(probs, axis=1, keepdims=True)\n",
    "        sums[sums == 0] = 1\n",
    "        return probs / sums\n",
    "\n",
    "    def _predict_proba_gpu(self, X):\n",
    "        import cupy as cp\n",
    "        X_tr_g = cp.asarray(self.X_train_)\n",
    "        X_te_g = cp.asarray(X)\n",
    "        y_tr_g = cp.asarray(self.y_train_)\n",
    "\n",
    "        n_test = len(X)\n",
    "        n_classes = len(self.classes_)\n",
    "        probas = []\n",
    "        batch_size = 256 # Process in chunks\n",
    "\n",
    "        phi = self.PHI\n",
    "        res = self.dna_['resonance']\n",
    "        shift = self.dna_['shift']\n",
    "\n",
    "        for i in range(0, n_test, batch_size):\n",
    "            end = min(i+batch_size, n_test)\n",
    "            batch = X_te_g[i:end]\n",
    "\n",
    "            # Phi-Minkowski Distance\n",
    "            diff = cp.abs(batch[:, None, :] - X_tr_g[None, :, :])\n",
    "            dists = cp.sum(cp.power(diff, phi), axis=2)\n",
    "            dists = cp.power(dists, 1.0/phi)\n",
    "\n",
    "            # Get Top K\n",
    "            top_k_idx = cp.argsort(dists, axis=1)[:, :self.k]\n",
    "            row_idx = cp.arange(len(batch))[:, None]\n",
    "            top_dists = dists[row_idx, top_k_idx]\n",
    "            top_y = y_tr_g[top_k_idx]\n",
    "\n",
    "            # Golden Spiral Kernel Calculation\n",
    "            # 1. Power Law Decay based on Phi\n",
    "            base_w = 1.0 / (cp.power(top_dists, phi) + 1e-9)\n",
    "\n",
    "            # 2. Logarithmic Spiral Modulation\n",
    "            # This creates \"shells\" of probability rather than a flat circle\n",
    "            spiral_mod = 1.0 + 0.5 * cp.cos(cp.log(top_dists + 1e-9) * res + shift)\n",
    "\n",
    "            w = base_w * cp.maximum(spiral_mod, 0.0)\n",
    "\n",
    "            batch_p = cp.zeros((len(batch), n_classes))\n",
    "            for c_idx, cls in enumerate(self.classes_):\n",
    "                mask = (top_y == cls)\n",
    "                batch_p[:, c_idx] = cp.sum(w * mask, axis=1)\n",
    "\n",
    "            probas.append(batch_p)\n",
    "\n",
    "            # Clean up GPU memory\n",
    "            del batch, diff, dists, top_k_idx, top_dists, w\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "        final_p = cp.asnumpy(cp.concatenate(probas))\n",
    "\n",
    "        # Normalize\n",
    "        sums = np.sum(final_p, axis=1, keepdims=True)\n",
    "        sums[sums == 0] = 1.0\n",
    "        return final_p / sums\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.classes_[np.argmax(self.predict_proba(X), axis=1)])\n",
    "\n",
    "\n",
    "\n",
    "# --- 19. THE ENTROPY MAXWELL (Thermodynamics) ---\n",
    "# --- 19. THE ENTROPY MAXWELL (Thermodynamics - Evolving) ---\n",
    "class EntropyMaxwellUnit(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_components=1):\n",
    "        self.n_components = n_components\n",
    "        self.dna_ = {'n_components': n_components} # DNA storage\n",
    "        self.models_ = {}\n",
    "        self.priors_ = {}\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        # Use DNA parameter instead of static init parameter\n",
    "        active_n = self.dna_['n_components']\n",
    "\n",
    "        for cls in self.classes_:\n",
    "            X_c = X[y == cls]\n",
    "            # Safety: Cannot have more components than samples\n",
    "            nc = min(active_n, len(X_c)) if len(X_c) > 1 else 1\n",
    "\n",
    "            if len(X_c) < 2:\n",
    "                self.models_[cls] = None\n",
    "                self.priors_[cls] = 0\n",
    "                continue\n",
    "\n",
    "            # Reg_covar added for stability during evolution\n",
    "            gmm = GaussianMixture(n_components=nc, covariance_type='full', reg_covar=1e-3, random_state=42)\n",
    "            gmm.fit(X_c)\n",
    "            self.models_[cls] = gmm\n",
    "            self.priors_[cls] = len(X_c) / len(y)\n",
    "        return self\n",
    "\n",
    "    def evolve(self, X_val, y_val, generations=10):\n",
    "        # Thermodynamic Annealing: Try different component counts\n",
    "        best_acc = self.score(X_val, y_val)\n",
    "        best_dna = self.dna_.copy()\n",
    "\n",
    "        # Try finding the optimal complexity (1 to 5 components)\n",
    "        possible_components = [1, 2, 3, 4, 5]\n",
    "\n",
    "        for comp in possible_components:\n",
    "            self.dna_['n_components'] = comp\n",
    "            try:\n",
    "                self.fit(X_val, y_val) # Re-fit to test adaptation\n",
    "                acc = self.score(X_val, y_val)\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_dna = self.dna_.copy()\n",
    "            except:\n",
    "                continue # Skip if unstable\n",
    "\n",
    "        self.dna_ = best_dna\n",
    "        return best_acc\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probs = np.zeros((len(X), len(self.classes_)))\n",
    "        for i, cls in enumerate(self.classes_):\n",
    "            if self.models_.get(cls) is not None:\n",
    "                log_prob = self.models_[cls].score_samples(X)\n",
    "                probs[:, i] = np.exp(log_prob) * self.priors_[cls]\n",
    "        total = np.sum(probs, axis=1, keepdims=True) + 1e-10\n",
    "        return probs / total\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.classes_[np.argmax(self.predict_proba(X), axis=1)])\n",
    "\n",
    "\n",
    "\n",
    "# --- 20. THE QUANTUM FLUX (Superposition) ---\n",
    "# --- 20. THE QUANTUM FLUX (Superposition - Evolving) ---\n",
    "class QuantumFluxUnit(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, gamma=1.0, n_components=500):\n",
    "        self.dna_ = {'gamma': gamma, 'n_components': n_components}\n",
    "        self.rbf_feature_ = None\n",
    "        self.classifier_ = RidgeClassifier(alpha=1.0)\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        # Apply DNA settings\n",
    "        self.rbf_feature_ = RBFSampler(\n",
    "            gamma=self.dna_['gamma'],\n",
    "            n_components=int(self.dna_['n_components']),\n",
    "            random_state=42\n",
    "        )\n",
    "        X_quantum = self.rbf_feature_.fit_transform(X)\n",
    "        self.classifier_.fit(X_quantum, y)\n",
    "        return self\n",
    "\n",
    "    def evolve(self, X_val, y_val, generations=20):\n",
    "        best_acc = self.score(X_val, y_val)\n",
    "        best_dna = self.dna_.copy()\n",
    "\n",
    "        for _ in range(generations):\n",
    "            mutant = best_dna.copy()\n",
    "            trait = random.choice(['gamma', 'n_components'])\n",
    "\n",
    "            if trait == 'gamma':\n",
    "                mutant['gamma'] *= np.random.uniform(0.5, 2.0)\n",
    "            elif trait == 'n_components':\n",
    "                mutant['n_components'] = int(mutant['n_components'] * np.random.uniform(0.8, 1.2))\n",
    "                mutant['n_components'] = max(50, mutant['n_components']) # Minimum floor\n",
    "\n",
    "            self.dna_ = mutant\n",
    "            self.fit(X_val, y_val) # Quick Re-fit\n",
    "            acc = self.score(X_val, y_val)\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_dna = mutant\n",
    "            else:\n",
    "                self.dna_ = best_dna # Revert\n",
    "\n",
    "        return best_acc\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_quantum = self.rbf_feature_.transform(X)\n",
    "        d = self.classifier_.decision_function(X_quantum)\n",
    "        if len(self.classes_) == 2:\n",
    "            prob = 1 / (1 + np.exp(-d))\n",
    "            return np.column_stack([1-prob, prob])\n",
    "        else:\n",
    "            exp_d = np.exp(d - np.max(d, axis=1, keepdims=True))\n",
    "            return exp_d / np.sum(exp_d, axis=1, keepdims=True)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.classes_[np.argmax(self.predict_proba(X), axis=1)])\n",
    "\n",
    "# --- 21. THE EVENT HORIZON (General Relativity) ---\n",
    "# --- 21. THE EVENT HORIZON (General Relativity - Evolving) ---\n",
    "class EventHorizonUnit(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.centroids_ = None\n",
    "        self.masses_ = None\n",
    "        self.schwarzschild_ = None\n",
    "        self.classes_ = None\n",
    "        # DNA: Laws of Physics (Gravity & Singularity limits)\n",
    "        self.dna_ = {'horizon_pct': 10.0, 'decay_power': 2.0}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.centroids_ = []\n",
    "        self.masses_ = []\n",
    "        self.schwarzschild_ = []\n",
    "\n",
    "        # Physics Parameters from DNA\n",
    "        h_pct = np.clip(self.dna_['horizon_pct'], 1.0, 50.0) # Limit horizon size\n",
    "\n",
    "        for cls in self.classes_:\n",
    "            X_c = X[y == cls]\n",
    "            if len(X_c) == 0: continue\n",
    "\n",
    "            centroid = np.mean(X_c, axis=0)\n",
    "            mass = len(X_c)\n",
    "\n",
    "            dists = np.linalg.norm(X_c - centroid, axis=1)\n",
    "            # Dynamic Event Horizon based on evolved percentile\n",
    "            radius = np.percentile(dists, h_pct) if len(dists) > 0 else 0.0\n",
    "\n",
    "            self.centroids_.append(centroid)\n",
    "            self.masses_.append(mass)\n",
    "            self.schwarzschild_.append(radius)\n",
    "        return self\n",
    "\n",
    "    def evolve(self, X_val, y_val, generations=20):\n",
    "        # Evolving the fabric of spacetime\n",
    "        best_acc = self.score(X_val, y_val)\n",
    "        best_dna = self.dna_.copy()\n",
    "\n",
    "        for _ in range(generations):\n",
    "            mutant = best_dna.copy()\n",
    "            trait = random.choice(['horizon_pct', 'decay_power'])\n",
    "\n",
    "            if trait == 'horizon_pct':\n",
    "                # Mutate the size of the black hole core\n",
    "                mutant['horizon_pct'] += np.random.uniform(-5.0, 5.0)\n",
    "            elif trait == 'decay_power':\n",
    "                # Mutate how far gravity reaches (Newtonian = 2.0)\n",
    "                mutant['decay_power'] *= np.random.uniform(0.8, 1.25)\n",
    "\n",
    "            self.dna_ = mutant\n",
    "            self.fit(X_val, y_val) # Re-calculate horizons\n",
    "            acc = self.score(X_val, y_val)\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_dna = mutant\n",
    "            else:\n",
    "                self.dna_ = best_dna # Revert physics\n",
    "\n",
    "        return best_acc\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probs = []\n",
    "        decay = self.dna_['decay_power']\n",
    "\n",
    "        for x_pt in X:\n",
    "            forces = []\n",
    "            in_horizon = False\n",
    "            horizon_class = -1\n",
    "\n",
    "            for i, cls in enumerate(self.classes_):\n",
    "                dist = np.linalg.norm(x_pt - self.centroids_[i])\n",
    "\n",
    "                # 1. EVENT HORIZON CHECK\n",
    "                if dist < self.schwarzschild_[i]:\n",
    "                    in_horizon = True\n",
    "                    horizon_class = i\n",
    "                    break\n",
    "\n",
    "                # 2. EVOLVED GRAVITATIONAL PULL\n",
    "                # Force = Mass / Distance ^ Evolved_Power\n",
    "                force = self.masses_[i] / (dist**decay + 1e-9)\n",
    "                forces.append(force)\n",
    "\n",
    "            if in_horizon:\n",
    "                p = np.zeros(len(self.classes_))\n",
    "                p[horizon_class] = 1.0\n",
    "            else:\n",
    "                forces = np.array(forces)\n",
    "                p = forces / (np.sum(forces) + 1e-9)\n",
    "\n",
    "            probs.append(p)\n",
    "        return np.array(probs)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.classes_[np.argmax(self.predict_proba(X), axis=1)])\n",
    "\n",
    "\n",
    "# --- 22. THE OMEGA POINT (The Hidden Infinity Engine - Tensor Core) ---\n",
    "class TheOmegaPoint_Unit22(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.classes_ = None\n",
    "        self.model_ = None\n",
    "        self.pca_vector_ = None # To store the \"Principal Vibration\"\n",
    "        self.scaler_ = StandardScaler()\n",
    "\n",
    "    def _apply_theoretical_transforms(self, X, is_training=False):\n",
    "        # 1. Standardize Reality\n",
    "        if is_training:\n",
    "            X_geo = self.scaler_.fit_transform(X)\n",
    "        else:\n",
    "            X_geo = self.scaler_.transform(X)\n",
    "\n",
    "        n_samples, n_features = X_geo.shape\n",
    "\n",
    "        # --- THEORY 1: THE TENSOR FIELD (Interaction Energy) ---\n",
    "        # Instead of Phase, we calculate the PHYSICAL INTERACTION between forces.\n",
    "        # This creates a \"Force Field\" of all possible pairings (x1*x2, x1*x3...)\n",
    "        # Mathematics: Outer Product -> Upper Triangle\n",
    "        tensor_list = []\n",
    "        for i in range(n_features):\n",
    "            for j in range(i, n_features):\n",
    "                tensor_list.append(X_geo[:, i] * X_geo[:, j])\n",
    "        tensor_field = np.column_stack(tensor_list)\n",
    "\n",
    "        # --- THEORY 2: SCHRODINGER KINETIC ENERGY ---\n",
    "        # Kinetic Energy = 1/2 * mass * velocity^2\n",
    "        # We treat the value as velocity.\n",
    "        kinetic = 0.5 * (X_geo ** 2)\n",
    "\n",
    "        # --- THEORY 3: SHANNON ENTROPY (Information Density) ---\n",
    "        # How \"surprising\" is this data point?\n",
    "        # We transform to probabilities first (Softmax-ish)\n",
    "        p = np.abs(X_geo) / (np.sum(np.abs(X_geo), axis=1, keepdims=True) + 1e-9)\n",
    "        entropy = -np.sum(p * np.log(p + 1e-9), axis=1, keepdims=True)\n",
    "\n",
    "        # --- THEORY 4: THE GOD ALEPH (EIGEN-RESONANCE) ---\n",
    "        # We project the entire reality onto its \"Principal Vibration\" (First Eigenvector).\n",
    "        # This is the \"Main Frequency\" of the universe (Dataset).\n",
    "        if is_training:\n",
    "            # Calculate the First Principal Component (The God Vector)\n",
    "            # Covariance Matrix -> Eigen Decomposition\n",
    "            cov_mat = np.cov(X_geo.T)\n",
    "            eig_vals, eig_vecs = np.linalg.eigh(cov_mat)\n",
    "            # The last vector corresponds to the largest eigenvalue\n",
    "            self.pca_vector_ = eig_vecs[:, -1]\n",
    "\n",
    "        # Calculate Resonance: Dot Product with the God Vector\n",
    "        # Aleph = How much does this specific point align with the Universe's main direction?\n",
    "        aleph = np.dot(X_geo, self.pca_vector_).reshape(-1, 1)\n",
    "\n",
    "        # FINAL STACKING\n",
    "        # 1. Base Reality\n",
    "        # 2. Kinetic Energy (Physics)\n",
    "        # 3. Entropy (Information)\n",
    "        # 4. Tensor Field (Geometry - THIS IS THE POWERHOUSE)\n",
    "        # 5. The God Aleph (Spectral Theory)\n",
    "\n",
    "        omega_features = np.hstack([\n",
    "            X_geo,      # Base\n",
    "            kinetic,    # Physics\n",
    "            entropy,    # Info\n",
    "            tensor_field, # Geometry (High Dim)\n",
    "            aleph       # Divinity\n",
    "        ])\n",
    "\n",
    "        return np.nan_to_num(omega_features, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "\n",
    "    def _benchmark_divinity(self, X_omega, y, n_orig):\n",
    "        \"\"\"\n",
    "        Benchmarks the new Tensor Reality.\n",
    "        \"\"\"\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        print(\"\\n\" + \"-\" * 65)\n",
    "        print(\" | THE DIVINE INSPECTION: TENSOR DIMENSION ACCURACIES |\")\n",
    "        print(\"-\" * 65)\n",
    "        print(f\" {'THEORETICAL LAYER':<25} | {'ACCURACY':<10} | {'STATUS':<10}\")\n",
    "        print(\"-\" * 65)\n",
    "\n",
    "        # Slicing logic depends on the stack order in _apply\n",
    "        # 1. Base Reality: [0 : n]\n",
    "        # 2. Kinetic: [n : 2n]\n",
    "        # 3. Entropy: [2n : 2n+1]\n",
    "        # 4. Tensor: [2n+1 : -1]\n",
    "        # 5. Aleph: [-1]\n",
    "\n",
    "        n = n_orig\n",
    "\n",
    "        # Define Layers\n",
    "        layers = [\n",
    "            (\"Base Reality (Norm)\", 0, n),\n",
    "            (\"Kinetic Energy\", n, 2*n),\n",
    "            (\"Shannon Entropy\", 2*n, 2*n+1),\n",
    "            (\"The Tensor Field\", 2*n+1, X_omega.shape[1]-1),\n",
    "            (\"THE GOD ALEPH (Eigen)\", X_omega.shape[1]-1, X_omega.shape[1])\n",
    "        ]\n",
    "\n",
    "        for name, start, end in layers:\n",
    "            X_subset = X_omega[:, start:end]\n",
    "            probe = DecisionTreeClassifier(max_depth=4, random_state=42) # Deeper probe for Tensors\n",
    "            probe.fit(X_subset, y)\n",
    "            acc = probe.score(X_subset, y)\n",
    "            print(f\" {name:<25} | {acc:.2%}    | Active\")\n",
    "        print(\"-\" * 65)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        if hasattr(self, 'verbose') and self.verbose:\n",
    "             print(\" [OMEGA] TRANSCODING REALITY INTO TENSOR FIELDS...\")\n",
    "\n",
    "        # Pass is_training=True to learn the God Vector\n",
    "        X_omega = self._apply_theoretical_transforms(X, is_training=True)\n",
    "\n",
    "        # Benchmark\n",
    "        self._benchmark_divinity(X_omega, y, X.shape[1])\n",
    "\n",
    "        # BRAIN: ExtraTrees is best for Tensors (High Dimensional Sparse-ish data)\n",
    "        self.model_ = ExtraTreesClassifier(\n",
    "            n_estimators=1000,\n",
    "            max_depth=None,\n",
    "            max_features='sqrt', # Critical for handling the massive Tensor Field\n",
    "            bootstrap=False,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.model_.fit(X_omega, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_omega = self._apply_theoretical_transforms(X, is_training=False)\n",
    "        return self.model_.predict_proba(X_omega)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.classes_[np.argmax(self.predict_proba(X), axis=1)])\n",
    "\n",
    "# --- 7. THE TITAN-21 \"FINAL COSMOLOGY\" ---\n",
    "class HarmonicResonanceClassifier_BEAST_21D(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.scaler_ = RobustScaler(quantile_range=(15.0, 85.0))\n",
    "        self.weights_ = None\n",
    "        self.classes_ = None\n",
    "\n",
    "        # --- THE 21 DIMENSIONS OF THE UNIVERSE ---\n",
    "\n",
    "        # [LOGIC SECTOR - NEWTONIAN]\n",
    "        self.unit_01 = ExtraTreesClassifier(n_estimators=1000, bootstrap=False, max_features='sqrt', n_jobs=-1, random_state=42)\n",
    "        self.unit_02 = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=42)\n",
    "        self.unit_03 = HistGradientBoostingClassifier(max_iter=500, learning_rate=0.05, random_state=42)\n",
    "\n",
    "        # [GRADIENT SECTOR - OPTIMIZATION]\n",
    "        self.unit_04 = XGBClassifier(n_estimators=500, max_depth=6, learning_rate=0.02, n_jobs=-1, random_state=42)\n",
    "        self.unit_05 = XGBClassifier(n_estimators=1000, max_depth=3, learning_rate=0.1, n_jobs=-1, random_state=42)\n",
    "\n",
    "        # [KERNEL SECTOR - MANIFOLDS]\n",
    "        self.unit_06 = NuSVC(nu=0.05, kernel='rbf', gamma='scale', probability=True, random_state=42)\n",
    "        self.unit_07 = SVC(kernel='poly', degree=2, C=10.0, probability=True, random_state=42)\n",
    "\n",
    "        # [GEOMETRY SECTOR - SPACETIME]\n",
    "        self.unit_08 = KNeighborsClassifier(n_neighbors=3, weights='distance', metric='euclidean', n_jobs=-1)\n",
    "        self.unit_09 = KNeighborsClassifier(n_neighbors=9, weights='distance', metric='manhattan', n_jobs=-1)\n",
    "        self.unit_10 = QuadraticDiscriminantAnalysis(reg_param=0.01)\n",
    "        self.unit_11 = CalibratedClassifierCV(LinearSVC(C=0.5, dual=False, max_iter=5000), cv=5)\n",
    "\n",
    "        # [SOUL SECTOR - RESONANCE (EVOLUTIONARY)]\n",
    "        self.unit_12 = HolographicSoulUnit(k=15)\n",
    "        self.unit_13 = HolographicSoulUnit(k=15)\n",
    "        self.unit_14 = HolographicSoulUnit(k=15)\n",
    "        self.unit_15 = HolographicSoulUnit(k=25)\n",
    "        self.unit_16 = HolographicSoulUnit(k=25)\n",
    "        self.unit_17 = HolographicSoulUnit(k=25)\n",
    "\n",
    "        # [BIOLOGY SECTOR - FRACTAL (EVOLUTIONARY)]\n",
    "        self.unit_18 = GoldenSpiralUnit(k=21)\n",
    "\n",
    "        # [COSMIC SECTOR - THE FINAL TRINITY]\n",
    "        self.unit_19 = EntropyMaxwellUnit(n_components=1) # Thermodynamics\n",
    "        self.unit_20 = QuantumFluxUnit(gamma=0.5)         # Quantum Mechanics\n",
    "        self.unit_21 = EventHorizonUnit()                 # General Relativity\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = np.array(y).astype(int)\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_classes = len(self.classes_)\n",
    "        X_scaled = self.scaler_.fit_transform(X)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\" >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\")\n",
    "            print(\" > Initiating The Refitted Gauntlet (Maximum Data Flow)...\")\n",
    "\n",
    "        # --- THE TRIPLE SPLIT ---\n",
    "        # 1. Judgement Set (20%) - Kept totally unseen for final weights\n",
    "        X_temp, X_exam2, y_temp, y_exam2 = train_test_split(\n",
    "            X_scaled, y, test_size=0.20, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        # 2. Evolution Set (20% of total) - Used to mutate DNA\n",
    "        X_train_sub, X_exam1, y_train_sub, y_exam1 = train_test_split(\n",
    "            X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
    "        )\n",
    "\n",
    "        # --- A: EVOLVE THE LIVING UNITS (On Sub-Train + Exam 1) ---\n",
    "        # --- A: EVOLVE THE LIVING UNITS (On Sub-Train + Exam 1) ---\n",
    "        if self.verbose: print(\" > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\")\n",
    "\n",
    "        living_units = [\n",
    "            (\"SOUL-01 (Original)\", self.unit_12), (\"SOUL-02 (Mirror A)\", self.unit_13),\n",
    "            (\"SOUL-03 (Mirror B)\", self.unit_14), (\"SOUL-D (AGI Hyper)\", self.unit_15),\n",
    "            (\"SOUL-E (AGI Deep)\",  self.unit_16), (\"SOUL-F (AGI Omni)\",  self.unit_17),\n",
    "            (\"GOLDEN RATIO (Phi)\", self.unit_18), (\"ENTROPY (Thermo)\",   self.unit_19),\n",
    "            (\"QUANTUM (Flux)\",     self.unit_20), (\"GRAVITY (Horizon)\",  self.unit_21)\n",
    "        ]\n",
    "\n",
    "        for name, unit in living_units:\n",
    "            # 1. Train on Small Set\n",
    "            if hasattr(unit, 'set_raw_source'): unit.set_raw_source(X_train_sub)\n",
    "            unit.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "            # 2. Evolve on Exam 1\n",
    "            acc = unit.evolve(X_exam1, y_exam1, generations=30)\n",
    "\n",
    "            if self.verbose:\n",
    "                dna = unit.dna_\n",
    "                print(f\"    > {name} is meditating on the data...\")\n",
    "\n",
    "                if 'freq' in dna: # Holographic Souls\n",
    "                     print(f\"       [EVOLVED] Acc: {acc:.2%} | Freq: {dna['freq']:.2f} | Gamma: {dna['gamma']:.2f}\")\n",
    "                elif 'resonance' in dna: # Golden Spiral\n",
    "                     print(f\"       [EVOLVED] Acc: {acc:.2%} | Resonance: {dna['resonance']:.3f} | Decay: {dna['decay']:.2f}\")\n",
    "                elif 'horizon_pct' in dna: # Gravity (Event Horizon)\n",
    "                     print(f\"       [EVOLVED] Acc: {acc:.2%} | Horizon: {dna['horizon_pct']:.1f}% | Power: {dna['decay_power']:.2f}\")\n",
    "                elif 'n_components' in dna and 'gamma' in dna: # Quantum Flux\n",
    "                     print(f\"       [EVOLVED] Acc: {acc:.2%} | Gamma: {dna['gamma']:.2f} | N-Comp: {dna['n_components']}\")\n",
    "                else: # Entropy / Generic\n",
    "                     val = list(dna.values())[0]\n",
    "                     print(f\"       [EVOLVED] Acc: {acc:.2%} | Param: {val}\")\n",
    "\n",
    "        # --- B: THE CRITICAL FIX (REFIT ON 80% DATA) ---\n",
    "        if self.verbose: print(\" > Phase 2: Strengthening Units (Refitting on 80% Data)...\")\n",
    "\n",
    "        # We combine Train + Exam1 (80% of data) so models are strong for Exam 2\n",
    "        X_strong = X_temp\n",
    "        y_strong = y_temp\n",
    "\n",
    "        # Refit Living Units with their NEW DNA on LARGER data\n",
    "        for name, unit in living_units:\n",
    "            if hasattr(unit, 'set_raw_source'): unit.set_raw_source(X_strong)\n",
    "            unit.fit(X_strong, y_strong)\n",
    "\n",
    "        # Fit Standard Units on LARGER data\n",
    "        standard_units = [\n",
    "            self.unit_01, self.unit_02, self.unit_03, self.unit_04,\n",
    "            self.unit_05, self.unit_06, self.unit_07, self.unit_08,\n",
    "            self.unit_09, self.unit_10, self.unit_11\n",
    "        ]\n",
    "\n",
    "        for unit in standard_units:\n",
    "            try:\n",
    "                unit.fit(X_strong, y_strong)\n",
    "            except:\n",
    "                unit = KNeighborsClassifier(n_neighbors=5).fit(X_strong, y_strong)\n",
    "\n",
    "        # --- C: THE JUDGEMENT (EXAM 2 - DETERMINISTIC ELITE) ---\n",
    "        if self.verbose: print(\" > Phase 3: The Council of 21 (Judgement Day - Deterministic Power)...\")\n",
    "\n",
    "        all_units = standard_units + [u for _, u in living_units]\n",
    "        n_units = len(all_units)\n",
    "\n",
    "        # 1. Gather Predictions & Accuracies\n",
    "        preds_2 = []\n",
    "        accs_2 = []\n",
    "        for unit in all_units:\n",
    "            try:\n",
    "                if hasattr(unit, \"predict_proba\"):\n",
    "                    p = unit.predict_proba(X_exam2)\n",
    "                else:\n",
    "                    d = unit.decision_function(X_exam2)\n",
    "                    p = np.exp(d) / np.sum(np.exp(d), axis=1, keepdims=True)\n",
    "            except:\n",
    "                p = np.ones((len(X_exam2), n_classes)) / n_classes\n",
    "\n",
    "            preds_2.append(p)\n",
    "            accs_2.append(accuracy_score(y_exam2, np.argmax(p, axis=1)))\n",
    "\n",
    "        # 2. IDENTIFY THE TOP 3 ELITE STRICTLY BY ACCURACY\n",
    "        # Sort indices: Best (0) to Worst (20)\n",
    "        sorted_indices = np.argsort(accs_2)[::-1]\n",
    "        top_3_indices = sorted_indices[:3]\n",
    "\n",
    "        # 3. ASSIGN WEIGHTS DETERMINISTICALLY (Power Law)\n",
    "        # We don't use 'minimize' anymore because it disrespects accuracy.\n",
    "        # We use x^4 distribution on the accuracy values of the top 3.\n",
    "\n",
    "        elite_accs = np.array([accs_2[i] for i in top_3_indices])\n",
    "\n",
    "        # Safety: If all are 0 or equal, give equal weight\n",
    "        if np.sum(elite_accs) == 0:\n",
    "            elite_weights = np.array([0.34, 0.33, 0.33])\n",
    "        else:\n",
    "            # Power 15 creates a strong hierarchy (Winner takes most, but #2 and #3 help)\n",
    "            # e.g. 98%, 97%, 96% -> Weights split nicely favoring 98%\n",
    "            raw_weights = elite_accs ** 15\n",
    "            elite_weights = raw_weights / np.sum(raw_weights)\n",
    "\n",
    "        # 4. MAP BACK TO MAIN WEIGHT ARRAY\n",
    "        self.weights_ = np.zeros(n_units)\n",
    "        for rank, unit_idx in enumerate(top_3_indices):\n",
    "            self.weights_[unit_idx] = elite_weights[rank]\n",
    "\n",
    "        # 5. PRINT STRICTLY DESCENDING TABLE\n",
    "        if self.verbose:\n",
    "            print(\"-\" * 60)\n",
    "            print(\"   >>> THE COUNCIL WEIGHTS (TOP 3 ELITE - POWER LAW) <<<\")\n",
    "            unit_names = [\n",
    "                \"Logic-ET\", \"Logic-RF\", \"Logic-HG\", \"Grad-XG1\", \"Grad-XG2\", \"Nu-Warp\",\n",
    "                \"PolyKer\", \"Geom-K3\", \"Geom-K9\", \"Space-QDA\", \"Resonance\",\n",
    "                \"SOUL-Orig\", \"SOUL-TwinA\", \"SOUL-TwinB\", \"SOUL-D(AGI)\", \"SOUL-E(AGI)\", \"SOUL-F(AGI)\",\n",
    "                \"GOLDEN RATIO\", \"ENTROPY\", \"QUANTUM\", \"GRAVITY\"\n",
    "            ]\n",
    "\n",
    "            # Print ALL non-zero weights first (The Elite)\n",
    "            for rank, unit_idx in enumerate(top_3_indices):\n",
    "                w = self.weights_[unit_idx]\n",
    "                acc = accs_2[unit_idx]\n",
    "                name = unit_names[unit_idx]\n",
    "                print(f\"   [{name:<15}] : {w:.4f} | Real Acc: {acc:.2%} (Rank {rank+1})\")\n",
    "\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "            # Print the tragic rejects (High acc but didn't make Top 3)\n",
    "            for unit_idx in sorted_indices[3:]:\n",
    "                acc = accs_2[unit_idx]\n",
    "                name = unit_names[unit_idx]\n",
    "                print(f\"   [{name:<15}] : 0.0000 | Real Acc: {acc:.2%} (Rejected)\")\n",
    "\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "        # --- THE OMEGA PROTOCOL HERE ---\n",
    "\n",
    "        # Initialize the flag (default to False)\n",
    "        self.omega_active_ = False\n",
    "\n",
    "        # Get the accuracy of the best model (Rank 1 from the sorted list)\n",
    "        best_acc_val = elite_accs[0]\n",
    "\n",
    "        if best_acc_val < 0.90:\n",
    "            print(\"\\n\" + \"!\" * 60)\n",
    "            print(\" >>> CRITICAL ALERT: SYSTEM INSTABILITY DETECTED (Acc < 90%) <<<\")\n",
    "            print(\" >>> INITIATING 'THE OMEGA POINT' (UNIT 22) - HIDDEN WEAPON <<<\")\n",
    "            print(\"!\" * 60)\n",
    "\n",
    "            # 1. Instantiate the Forbidden Unit\n",
    "            self.unit_omega = TheOmegaPoint_Unit22()\n",
    "\n",
    "            # 2. Train on the STRONG set (80% Data - X_strong/y_strong from Phase 2)\n",
    "            self.unit_omega.fit(X_strong, y_strong)\n",
    "\n",
    "            # 3. Evaluate Omega on Exam 2 (The Judgement Set)\n",
    "            omega_acc = self.unit_omega.score(X_exam2, y_exam2)\n",
    "            print(f\" > OMEGA SINGULARITY RESULT: {omega_acc:.2%} Accuracy\")\n",
    "\n",
    "            if omega_acc > best_acc_val:\n",
    "                print(\" >>> OMEGA HAS TAKEN CONTROL. OVERRIDING COUNCIL WEIGHTS. <<<\")\n",
    "                # WE RESET ALL 21 WEIGHTS TO ZERO\n",
    "                self.weights_ = np.zeros(n_units)\n",
    "\n",
    "                # Activate Omega Flag\n",
    "                self.omega_active_ = True\n",
    "            else:\n",
    "                print(\" >>> OMEGA FAILED TO STABILIZE. REVERTING TO COUNCIL. <<<\")\n",
    "                self.omega_active_ = False\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print(\"\\n >>> SYSTEM STABLE (Acc >= 90%). OMEGA REMAINS DORMANT. <<<\")\n",
    "\n",
    "\n",
    "        # --- D: FINAL ASSIMILATION ---\n",
    "        if self.verbose: print(\" > Phase 4: Final Assimilation (Retraining on 100% Data)...\")\n",
    "\n",
    "        # Update raw source to full dataset for Souls/Spiral\n",
    "        if hasattr(self.unit_18, 'set_raw_source'): self.unit_18.set_raw_source(X_scaled)\n",
    "        self.unit_12.set_raw_source(X_scaled)\n",
    "        self.unit_13.set_raw_source(X_scaled)\n",
    "        self.unit_14.set_raw_source(X_scaled)\n",
    "        self.unit_15.set_raw_source(X_scaled)\n",
    "        self.unit_16.set_raw_source(X_scaled)\n",
    "        self.unit_17.set_raw_source(X_scaled)\n",
    "\n",
    "        for unit in all_units:\n",
    "            unit.fit(X_scaled, y)\n",
    "\n",
    "        if self.verbose: print(\" >  THE 21D INFINITE SOPHISTICATION IS READY!  <\")\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_scaled = self.scaler_.transform(X)\n",
    "\n",
    "        if hasattr(self, 'omega_active_') and self.omega_active_:\n",
    "            # If Omega took over, we ignore the 21 units and strictly use Unit 22\n",
    "            return self.unit_omega.predict_proba(X)\n",
    "\n",
    "        all_units = [\n",
    "            self.unit_01, self.unit_02, self.unit_03, self.unit_04,\n",
    "            self.unit_05, self.unit_06, self.unit_07, self.unit_08,\n",
    "            self.unit_09, self.unit_10, self.unit_11,\n",
    "            self.unit_12, self.unit_13, self.unit_14,\n",
    "            self.unit_15, self.unit_16, self.unit_17,\n",
    "            self.unit_18, self.unit_19, self.unit_20, self.unit_21\n",
    "        ]\n",
    "\n",
    "        final_pred = None\n",
    "        for i, unit in enumerate(all_units):\n",
    "            try:\n",
    "                if hasattr(unit, \"predict_proba\"):\n",
    "                    p = unit.predict_proba(X_scaled)\n",
    "                else:\n",
    "                    d = unit.decision_function(X_scaled)\n",
    "                    p = np.exp(d) / np.sum(np.exp(d), axis=1, keepdims=True)\n",
    "            except:\n",
    "                 p = np.ones((len(X), len(self.classes_))) / len(self.classes_)\n",
    "\n",
    "            if final_pred is None:\n",
    "                final_pred = self.weights_[i] * p\n",
    "            else:\n",
    "                final_pred += self.weights_[i] * p\n",
    "\n",
    "        return final_pred\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
    "\n",
    "def HarmonicResonanceForest_Ultimate(n_estimators=None):\n",
    "    return HarmonicResonanceClassifier_BEAST_21D(verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62042c",
   "metadata": {
    "id": "ufw_XqH4ge9x",
    "papermill": {
     "duration": 0.005419,
     "end_time": "2025-12-25T09:43:58.825784",
     "exception": false,
     "start_time": "2025-12-25T09:43:58.820365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418cd837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T09:43:58.838261Z",
     "iopub.status.busy": "2025-12-25T09:43:58.837600Z",
     "iopub.status.idle": "2025-12-25T09:43:58.925284Z",
     "shell.execute_reply": "2025-12-25T09:43:58.924566Z"
    },
    "id": "4s4VwuH28O8w",
    "papermill": {
     "duration": 0.095328,
     "end_time": "2025-12-25T09:43:58.926478",
     "exception": false,
     "start_time": "2025-12-25T09:43:58.831150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Updated to accept custom_X and custom_y\n",
    "def run_comparative_benchmark(dataset_name, openml_id, sample_limit=3000, custom_X=None, custom_y=None):\n",
    "    print(f\"\\n[DATASET] Loading {dataset_name} (ID: {openml_id})...\")\n",
    "\n",
    "    try:\n",
    "        # --- PATH A: Custom Data Provided (Pre-cleaned) ---\n",
    "        if custom_X is not None and custom_y is not None:\n",
    "            print(\"  > Using provided Custom Data...\")\n",
    "            X = custom_X\n",
    "            y = custom_y\n",
    "\n",
    "            # Ensure X is numpy (in case a DF was passed)\n",
    "            if hasattr(X, 'values'):\n",
    "                X = X.values\n",
    "\n",
    "        # --- PATH B: Fetch from OpenML ---\n",
    "        else:\n",
    "            # Fetch as DataFrame to handle types better\n",
    "            X_df, y = fetch_openml(data_id=openml_id, return_X_y=True, as_frame=True, parser='auto')\n",
    "\n",
    "            # 1. AUTO-CLEANER: Convert Objects/Strings to Numbers (Only for DataFrames)\n",
    "            for col in X_df.columns:\n",
    "                if X_df[col].dtype == 'object' or X_df[col].dtype.name == 'category':\n",
    "                    le = LabelEncoder()\n",
    "                    X_df[col] = le.fit_transform(X_df[col].astype(str))\n",
    "\n",
    "            X = X_df.values # Convert to Numpy for HRF\n",
    "\n",
    "        # --- COMMON PIPELINE (NaN Handling) ---\n",
    "        # Even if custom data is passed, we double-check for NaNs to be safe\n",
    "        if np.isnan(X).any():\n",
    "            print(\"  > NaNs detected. Imputing with Mean strategy...\")\n",
    "            imp = SimpleImputer(strategy='mean')\n",
    "            X = imp.fit_transform(X)\n",
    "\n",
    "        le_y = LabelEncoder()\n",
    "        y = le_y.fit_transform(y)\n",
    "\n",
    "        # 3. GPU Limit Check\n",
    "        if len(X) > sample_limit:\n",
    "            print(f\"  ...Downsampling from {len(X)} to {sample_limit} (GPU Limit)...\")\n",
    "            X, y = resample(X, y, n_samples=sample_limit, random_state=42, stratify=y)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "        print(f\"  Shape: {X.shape} | Classes: {len(np.unique(y))}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading data: {e}\")\n",
    "        return\n",
    "\n",
    "    competitors = {\n",
    "        \"SVM (RBF)\": make_pipeline(StandardScaler(), SVC(kernel='rbf', C=1.0, probability=True, random_state=42)),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        \"XGBoost (GPU)\": XGBClassifier(\n",
    "            device='cuda',\n",
    "            tree_method='hist',\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            random_state=42\n",
    "        ),\n",
    "        # Ensure your HRF class is defined in the notebook before running this\n",
    "        \"HRF Ultimate (GPU)\": HarmonicResonanceForest_Ultimate(n_estimators=60)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    print(f\"\\n[BENCHMARK] Executing comparisons on {dataset_name}...\")\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'Model Name':<25} | {'Accuracy':<10} | {'Status'}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    hrf_acc = 0\n",
    "\n",
    "    for name, model in competitors.items():\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, preds)\n",
    "            results[name] = acc\n",
    "            print(f\"{name:<25} | {acc:.4%}    | Done\")\n",
    "\n",
    "            if \"HRF\" in name:\n",
    "                hrf_acc = acc\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{name:<25} | FAILED      | {e}\")\n",
    "\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    best_competitor = 0\n",
    "    for k, v in results.items():\n",
    "        if \"HRF\" not in k and v > best_competitor:\n",
    "            best_competitor = v\n",
    "\n",
    "    margin = hrf_acc - best_competitor\n",
    "\n",
    "    if margin > 0:\n",
    "        print(f\" HRF WINNING MARGIN: +{margin:.4%}\")\n",
    "    else:\n",
    "        print(f\" HRF GAP: {margin:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d6c7a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:43:58.939548Z",
     "iopub.status.busy": "2025-12-25T09:43:58.939125Z",
     "iopub.status.idle": "2025-12-25T09:44:08.429043Z",
     "shell.execute_reply": "2025-12-25T09:44:08.427859Z"
    },
    "id": "aZrqWeqa9Es3",
    "outputId": "80516f59-beb6-41c3-cd8d-14e837f0b406",
    "papermill": {
     "duration": 9.498147,
     "end_time": "2025-12-25T09:44:08.430466",
     "exception": false,
     "start_time": "2025-12-25T09:43:58.932319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading EEG Eye State (ID: 1471)...\n",
      "  ...Downsampling from 14980 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 14) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on EEG Eye State...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 85.3333%    | Done\n",
      "Random Forest             | 89.5000%    | Done\n",
      "XGBoost (GPU)             | 90.0000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -90.0000%\n"
     ]
    }
   ],
   "source": [
    "# TEST 1: EEG Eye State\n",
    "# ID: 1471\n",
    "# Type: Biological Time-Series (Periodic)\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"EEG Eye State\",\n",
    "    openml_id=1471,\n",
    "    sample_limit=3000  # Fast Mode Active\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1234e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:44:08.443640Z",
     "iopub.status.busy": "2025-12-25T09:44:08.443357Z",
     "iopub.status.idle": "2025-12-25T09:44:15.822784Z",
     "shell.execute_reply": "2025-12-25T09:44:15.822170Z"
    },
    "id": "F6yilMNU9Eng",
    "outputId": "898e8841-6e24-4cb1-ac56-dd473ce0f278",
    "papermill": {
     "duration": 7.387156,
     "end_time": "2025-12-25T09:44:15.823763",
     "exception": false,
     "start_time": "2025-12-25T09:44:08.436607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Phoneme (ID: 1489)...\n",
      "  ...Downsampling from 5404 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 5) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Phoneme...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 81.6667%    | Done\n",
      "Random Forest             | 91.0000%    | Done\n",
      "XGBoost (GPU)             | 91.6667%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -91.6667%\n"
     ]
    }
   ],
   "source": [
    "# TEST 2: Phoneme (Star Noise)\n",
    "# ID: 1489\n",
    "# Type: Audio/Harmonic Time-Series\n",
    "# Though originally for speech, the high-frequency harmonics in this data mimic the acoustic oscillations of stars (Asteroseismology).\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Phoneme\",\n",
    "    openml_id=1489,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf87c26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:44:15.836494Z",
     "iopub.status.busy": "2025-12-25T09:44:15.836300Z",
     "iopub.status.idle": "2025-12-25T09:44:23.998851Z",
     "shell.execute_reply": "2025-12-25T09:44:23.998168Z"
    },
    "id": "-QgD8xVN8O5P",
    "outputId": "a745e90e-4beb-4412-d18b-f2bb428e3ebb",
    "papermill": {
     "duration": 8.169934,
     "end_time": "2025-12-25T09:44:23.999835",
     "exception": false,
     "start_time": "2025-12-25T09:44:15.829901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Wall-Following Robot (ID: 1497)...\n",
      "  ...Downsampling from 5456 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 24) | Classes: 4\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Wall-Following Robot...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 88.5000%    | Done\n",
      "Random Forest             | 99.5000%    | Done\n",
      "XGBoost (GPU)             | 99.6667%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -99.6667%\n"
     ]
    }
   ],
   "source": [
    "# TEST 3: Wall-Following Robot Navigation\n",
    "# ID: 1497\n",
    "# Type: Sensor/Geometric (Ultrasound Waves)\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Wall-Following Robot\",\n",
    "    openml_id=1497,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4c46b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:44:24.013251Z",
     "iopub.status.busy": "2025-12-25T09:44:24.013023Z",
     "iopub.status.idle": "2025-12-25T09:44:32.066099Z",
     "shell.execute_reply": "2025-12-25T09:44:32.065278Z"
    },
    "id": "wCkn-zV08O14",
    "outputId": "02fa8ee0-66bc-49ca-e244-4a7a921316fc",
    "papermill": {
     "duration": 8.061156,
     "end_time": "2025-12-25T09:44:32.067362",
     "exception": false,
     "start_time": "2025-12-25T09:44:24.006206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Electricity (ID: 151)...\n",
      "  ...Downsampling from 45312 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 8) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Electricity...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 78.0000%    | Done\n",
      "Random Forest             | 84.0000%    | Done\n",
      "XGBoost (GPU)             | 85.3333%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -85.3333%\n"
     ]
    }
   ],
   "source": [
    "# TEST 4: Electricity\n",
    "# ID: 151\n",
    "# Type: Time-Series / Economic Flow (Periodic)\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Electricity\",\n",
    "    openml_id=151,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cddfbc5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:44:32.081380Z",
     "iopub.status.busy": "2025-12-25T09:44:32.081111Z",
     "iopub.status.idle": "2025-12-25T09:44:44.338969Z",
     "shell.execute_reply": "2025-12-25T09:44:44.338201Z"
    },
    "id": "EihWHKU5CmTf",
    "outputId": "964094ee-b665-45ba-c069-f00a888fadf3",
    "papermill": {
     "duration": 12.266303,
     "end_time": "2025-12-25T09:44:44.340237",
     "exception": false,
     "start_time": "2025-12-25T09:44:32.073934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Gas Sensor Drift (ID: 1476)...\n",
      "  ...Downsampling from 13910 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 128) | Classes: 6\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Gas Sensor Drift...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 93.6667%    | Done\n",
      "Random Forest             | 98.8333%    | Done\n",
      "XGBoost (GPU)             | 98.0000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -98.8333%\n"
     ]
    }
   ],
   "source": [
    " # TEST 5: Gas Sensor Array Drift\n",
    "# ID: 1476\n",
    "# Type: Chemical Sensors / Physics (High Dimensional)\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Gas Sensor Drift\",\n",
    "    openml_id=1476,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b07a26a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:44:44.354908Z",
     "iopub.status.busy": "2025-12-25T09:44:44.354623Z",
     "iopub.status.idle": "2025-12-25T09:44:52.680219Z",
     "shell.execute_reply": "2025-12-25T09:44:52.679267Z"
    },
    "id": "Ci17qpd4CTLS",
    "outputId": "6805929a-41f5-4049-8d00-6c0392056a31",
    "papermill": {
     "duration": 8.333874,
     "end_time": "2025-12-25T09:44:52.681241",
     "exception": false,
     "start_time": "2025-12-25T09:44:44.347367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Japanese Vowels (ID: 375)...\n",
      "  ...Downsampling from 9961 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 14) | Classes: 9\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Japanese Vowels...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 97.8333%    | Done\n",
      "Random Forest             | 94.3333%    | Done\n",
      "XGBoost (GPU)             | 95.5000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -97.8333%\n"
     ]
    }
   ],
   "source": [
    "# TEST 6: Japanese Vowels\n",
    "# ID: 375\n",
    "# Type: Audio / Speech (Harmonic Time-Series)\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Japanese Vowels\",\n",
    "    openml_id=375,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ee10fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:44:52.695707Z",
     "iopub.status.busy": "2025-12-25T09:44:52.695472Z",
     "iopub.status.idle": "2025-12-25T09:45:02.944321Z",
     "shell.execute_reply": "2025-12-25T09:45:02.943581Z"
    },
    "id": "dZhkUR0gCTFx",
    "outputId": "fedfdf9e-36da-4b35-ae25-ec609f260312",
    "papermill": {
     "duration": 10.25717,
     "end_time": "2025-12-25T09:45:02.945348",
     "exception": false,
     "start_time": "2025-12-25T09:44:52.688178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Gesture Phase (ID: 4538)...\n",
      "  ...Downsampling from 9873 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 32) | Classes: 5\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Gesture Phase...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 55.0000%    | Done\n",
      "Random Forest             | 68.1667%    | Done\n",
      "XGBoost (GPU)             | 68.6667%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -68.6667%\n"
     ]
    }
   ],
   "source": [
    "# TEST 7: Gesture Phase Segmentation\n",
    "# ID: 4538\n",
    "# Type: 3D Motion / Human Kinematics\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Gesture Phase\",\n",
    "    openml_id=4538,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a436da83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:45:02.960338Z",
     "iopub.status.busy": "2025-12-25T09:45:02.960079Z",
     "iopub.status.idle": "2025-12-25T09:45:12.714969Z",
     "shell.execute_reply": "2025-12-25T09:45:12.714173Z"
    },
    "id": "okDnYbZ0LkQg",
    "outputId": "aece10df-5a59-4c50-92d7-a08c511b1bd5",
    "papermill": {
     "duration": 9.763493,
     "end_time": "2025-12-25T09:45:12.715998",
     "exception": false,
     "start_time": "2025-12-25T09:45:02.952505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Mfeat-Fourier (ID: 14)...\n",
      "  Shape: (2000, 76) | Classes: 10\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Mfeat-Fourier...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 87.7500%    | Done\n",
      "Random Forest             | 85.7500%    | Done\n",
      "XGBoost (GPU)             | 87.5000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -87.7500%\n"
     ]
    }
   ],
   "source": [
    "# TEST 8: Mfeat-Fourier\n",
    "# ID: 14\n",
    "# Type: Geometric Frequencies / Fourier Coefficients\n",
    "# Hypothesis: The \"Soul\" Unit should contain the highest weight here.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Mfeat-Fourier\",\n",
    "    openml_id=14,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5ea15c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:45:12.731337Z",
     "iopub.status.busy": "2025-12-25T09:45:12.731103Z",
     "iopub.status.idle": "2025-12-25T09:45:20.688370Z",
     "shell.execute_reply": "2025-12-25T09:45:20.687601Z"
    },
    "id": "7qa-KsiyLkIo",
    "outputId": "742f468b-9f2d-4ca7-ff17-b3b17987d9cb",
    "papermill": {
     "duration": 7.966099,
     "end_time": "2025-12-25T09:45:20.689438",
     "exception": false,
     "start_time": "2025-12-25T09:45:12.723339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Optdigits (ID: 28)...\n",
      "  ...Downsampling from 5620 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 64) | Classes: 10\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Optdigits...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 99.0000%    | Done\n",
      "Random Forest             | 99.1667%    | Done\n",
      "XGBoost (GPU)             | 98.5000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -99.1667%\n"
     ]
    }
   ],
   "source": [
    "# TEST 9: Optdigits (Optical Recognition of Handwritten Digits)\n",
    "# ID: 28\n",
    "# Type: Image / Geometry\n",
    "# Hypothesis: Handwriting is about Shape Flow, not Logic Rules. Soul should rise.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Optdigits\",\n",
    "    openml_id=28,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd7b4000",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:45:20.705494Z",
     "iopub.status.busy": "2025-12-25T09:45:20.705239Z",
     "iopub.status.idle": "2025-12-25T09:45:27.017383Z",
     "shell.execute_reply": "2025-12-25T09:45:27.016697Z"
    },
    "id": "zyTeVI7IlL5o",
    "outputId": "f8e67812-5dd3-4e4c-9d83-8318b1a5f67a",
    "papermill": {
     "duration": 6.321991,
     "end_time": "2025-12-25T09:45:27.019043",
     "exception": false,
     "start_time": "2025-12-25T09:45:20.697052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Solar Flare Evolution (ID: 40686)...\n",
      "  Shape: (315, 12) | Classes: 5\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Solar Flare Evolution...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 77.7778%    | Done\n",
      "Random Forest             | 74.6032%    | Done\n",
      "XGBoost (GPU)             | 74.6032%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -77.7778%\n"
     ]
    }
   ],
   "source": [
    "# TEST 10: Solar Flare Evolution\n",
    "# ID: 40686\n",
    "# Type: Heliophysics / Magnetic Complexity\n",
    "# Hypothesis: Solar eruptions are driven by fractal magnetic winding.\n",
    "#             The \"Holo-Fractal\" Soul should resonate with these geometric patterns.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Solar Flare Evolution\",\n",
    "    openml_id=40686,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138b35c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:45:27.044039Z",
     "iopub.status.busy": "2025-12-25T09:45:27.043179Z",
     "iopub.status.idle": "2025-12-25T09:45:33.482807Z",
     "shell.execute_reply": "2025-12-25T09:45:33.482179Z"
    },
    "id": "XWZe4lRrNObP",
    "outputId": "9657f9ae-cc70-4393-97a3-188b40a5ee4d",
    "papermill": {
     "duration": 6.453654,
     "end_time": "2025-12-25T09:45:33.484012",
     "exception": false,
     "start_time": "2025-12-25T09:45:27.030358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Texture Analysis (ID: 40975)...\n",
      "  Shape: (1728, 6) | Classes: 4\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Texture Analysis...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 90.4624%    | Done\n",
      "Random Forest             | 98.2659%    | Done\n",
      "XGBoost (GPU)             | 99.4220%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -99.4220%\n"
     ]
    }
   ],
   "source": [
    "# TEST 11: Texture Analysis (Kylberg)\n",
    "# ID: 40975\n",
    "# Type: Image Texture / Surface Physics\n",
    "# Hypothesis: Texture is Frequency. Soul should dominate.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Texture Analysis\",\n",
    "    openml_id=40975,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ae85ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:45:33.500560Z",
     "iopub.status.busy": "2025-12-25T09:45:33.500321Z",
     "iopub.status.idle": "2025-12-25T09:45:40.596492Z",
     "shell.execute_reply": "2025-12-25T09:45:40.595733Z"
    },
    "id": "mxj3t0dJNOMK",
    "outputId": "fa303792-d485-4045-b596-0fe84f51203d",
    "papermill": {
     "duration": 7.105634,
     "end_time": "2025-12-25T09:45:40.597642",
     "exception": false,
     "start_time": "2025-12-25T09:45:33.492008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Steel Plates Faults (ID: 1504)...\n",
      "  Shape: (1941, 33) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Steel Plates Faults...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 99.4859%    | Done\n",
      "Random Forest             | 99.2288%    | Done\n",
      "XGBoost (GPU)             | 100.0000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -100.0000%\n"
     ]
    }
   ],
   "source": [
    "# TEST 12: Steel Plates Faults\n",
    "# ID: 1504\n",
    "# Type: Industrial Physics / Surface Geometry\n",
    "# Hypothesis: Defects are geometric shapes. Soul should assist.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Steel Plates Faults\",\n",
    "    openml_id=1504,\n",
    "    sample_limit=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218d8817",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:45:40.614614Z",
     "iopub.status.busy": "2025-12-25T09:45:40.613928Z",
     "iopub.status.idle": "2025-12-25T09:45:47.118589Z",
     "shell.execute_reply": "2025-12-25T09:45:47.118049Z"
    },
    "id": "wyoXmFRsLjhz",
    "outputId": "66ce79a6-62dc-44cd-aefc-a6114b8a49c9",
    "papermill": {
     "duration": 6.513906,
     "end_time": "2025-12-25T09:45:47.119541",
     "exception": false,
     "start_time": "2025-12-25T09:45:40.605635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading HTRU2 Pulsar Detection (ID: 45557)...\n",
      "  > NaNs detected. Imputing with Mean strategy...\n",
      "  Shape: (961, 4) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on HTRU2 Pulsar Detection...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 77.7202%    | Done\n",
      "Random Forest             | 76.6839%    | Done\n",
      "XGBoost (GPU)             | 77.7202%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -77.7202%\n"
     ]
    }
   ],
   "source": [
    "# TEST 13: HTRU2 - Pulsar Star Detection\n",
    "# ID: 45557\n",
    "# Type: Astrophysics / Radio Astronomy Signals\n",
    "# Hypothesis: Pulsars are the ultimate \"Harmonic Resonators\" of the universe.\n",
    "#             The Soul unit's frequency-based DNA should lock onto them instantly.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"HTRU2 Pulsar Detection\",\n",
    "    openml_id=45557,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5bfa94",
   "metadata": {
    "id": "akcI7_cWGMCh",
    "papermill": {
     "duration": 0.00737,
     "end_time": "2025-12-25T09:45:47.135124",
     "exception": false,
     "start_time": "2025-12-25T09:45:47.127754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Madelon (Hyper-Dimensional Synthetic)\n",
    "\n",
    "ID: 1485 Why: This is a synthetic dataset created for a NIPS feature selection challenge. It is highly non-linear with many \"noise\" features. Hypothesis: This is the ultimate test for your G.O.D. (Gradient Optimized Dimension) logic. If the \"Soul\" layer works, it should ignore the noise dimensions and lock onto the mathematical truth of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc56418d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:45:47.151266Z",
     "iopub.status.busy": "2025-12-25T09:45:47.151019Z",
     "iopub.status.idle": "2025-12-25T09:46:00.881211Z",
     "shell.execute_reply": "2025-12-25T09:46:00.880481Z"
    },
    "id": "OQ6FexxaW9rI",
    "outputId": "2197de7e-b36d-4d0f-917a-1697eec34c92",
    "papermill": {
     "duration": 13.739657,
     "end_time": "2025-12-25T09:46:00.882143",
     "exception": false,
     "start_time": "2025-12-25T09:45:47.142486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Madelon (ID: 1485)...\n",
      "  Shape: (2600, 500) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Madelon...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 59.8077%    | Done\n",
      "Random Forest             | 69.6154%    | Done\n",
      "XGBoost (GPU)             | 82.8846%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -82.8846%\n"
     ]
    }
   ],
   "source": [
    "# TEST 14: Madelon (Hyper-Dimensional)\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Madelon\",\n",
    "    openml_id=1485,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "900a5479",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:46:00.898763Z",
     "iopub.status.busy": "2025-12-25T09:46:00.898558Z",
     "iopub.status.idle": "2025-12-25T09:46:13.069744Z",
     "shell.execute_reply": "2025-12-25T09:46:13.068848Z"
    },
    "id": "rXDm3vpZW9EJ",
    "outputId": "4d5cd813-4c18-4519-814a-c6764f40d43d",
    "papermill": {
     "duration": 12.180697,
     "end_time": "2025-12-25T09:46:13.070918",
     "exception": false,
     "start_time": "2025-12-25T09:46:00.890221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Bioresponse (ID: 4134)...\n",
      "  ...Downsampling from 3751 to 1000 (GPU Limit)...\n",
      "  Shape: (1000, 1776) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Bioresponse...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 76.5000%    | Done\n",
      "Random Forest             | 82.0000%    | Done\n",
      "XGBoost (GPU)             | 82.0000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -82.0000%\n"
     ]
    }
   ],
   "source": [
    "# TEST 15: Bioresponse (Molecular Activity)\n",
    "# ID: 4134\n",
    "# Type: Chemo-informatics / Molecular Physics\n",
    "# Hypothesis: Molecular Activity is Resonance (Lock & Key).\n",
    "#             High-Dim Holography is required.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Bioresponse\",\n",
    "    openml_id=4134,\n",
    "    sample_limit=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0265552b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:46:13.088700Z",
     "iopub.status.busy": "2025-12-25T09:46:13.088455Z",
     "iopub.status.idle": "2025-12-25T09:46:26.728567Z",
     "shell.execute_reply": "2025-12-25T09:46:26.727811Z"
    },
    "id": "6ltpVha2S8Cp",
    "outputId": "93dd2bec-377b-4033-899e-2351c375a1e3",
    "papermill": {
     "duration": 13.650416,
     "end_time": "2025-12-25T09:46:26.729739",
     "exception": false,
     "start_time": "2025-12-25T09:46:13.079323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Higgs Boson (ID: 23512)...\n",
      "  > NaNs detected. Imputing with Mean strategy...\n",
      "  ...Downsampling from 98050 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 28) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Higgs Boson...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 66.5000%    | Done\n",
      "Random Forest             | 68.6667%    | Done\n",
      "XGBoost (GPU)             | 70.6667%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -70.6667%\n"
     ]
    }
   ],
   "source": [
    "# TEST 16: Higgs Boson (Particle Physics)\n",
    "# ID: 23512\n",
    "# Type: High Energy Physics / Subatomic Kinetics\n",
    "# Hypothesis: Particle decay follows quantum resonance patterns.\n",
    "#             The Soul should vibrate with the Higgs field.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Higgs Boson\",\n",
    "    openml_id=23512,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0263624c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:46:26.748187Z",
     "iopub.status.busy": "2025-12-25T09:46:26.747918Z",
     "iopub.status.idle": "2025-12-25T09:46:34.791409Z",
     "shell.execute_reply": "2025-12-25T09:46:34.790633Z"
    },
    "id": "QkiJ4yGrfJ55",
    "outputId": "0d08f4ce-17b7-4871-84fc-51f329edf563",
    "papermill": {
     "duration": 8.053781,
     "end_time": "2025-12-25T09:46:34.792377",
     "exception": false,
     "start_time": "2025-12-25T09:46:26.738596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Magic Telescope (ID: 1120)...\n",
      "  ...Downsampling from 19020 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 10) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Magic Telescope...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 86.3333%    | Done\n",
      "Random Forest             | 88.3333%    | Done\n",
      "XGBoost (GPU)             | 87.8333%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -88.3333%\n"
     ]
    }
   ],
   "source": [
    "# TEST 17: Magic Gamma Telescope (Astrophysics)\n",
    "# ID: 1120\n",
    "# Type: Astrophysics / Cherenkov Radiation\n",
    "# Hypothesis: Gamma showers create specific geometric ellipses.\n",
    "#             Pure geometry = Soul territory.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Magic Telescope\",\n",
    "    openml_id=1120,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a87053c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:46:34.810593Z",
     "iopub.status.busy": "2025-12-25T09:46:34.810353Z",
     "iopub.status.idle": "2025-12-25T09:46:44.601918Z",
     "shell.execute_reply": "2025-12-25T09:46:44.601146Z"
    },
    "id": "zOc4CvTIfNJG",
    "outputId": "1cdb7fc3-ea0e-44f7-855b-68fd1f472891",
    "papermill": {
     "duration": 9.801672,
     "end_time": "2025-12-25T09:46:44.602995",
     "exception": false,
     "start_time": "2025-12-25T09:46:34.801323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Musk v2 (ID: 1116)...\n",
      "  ...Downsampling from 6598 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 167) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Musk v2...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 99.6667%    | Done\n",
      "Random Forest             | 99.8333%    | Done\n",
      "XGBoost (GPU)             | 100.0000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -100.0000%\n"
     ]
    }
   ],
   "source": [
    "# TEST 18: Musk v2 (Biochemistry)\n",
    "# ID: 1116\n",
    "# Type: Chemo-informatics / Molecular Shape\n",
    "# Hypothesis: Olfactory perception is based on molecular vibration (Turin's Theory).\n",
    "#             This is the ultimate test for Harmonic Resonance.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Musk v2\",\n",
    "    openml_id=1116,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6f9eb67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:46:44.621006Z",
     "iopub.status.busy": "2025-12-25T09:46:44.620770Z",
     "iopub.status.idle": "2025-12-25T09:46:52.706355Z",
     "shell.execute_reply": "2025-12-25T09:46:52.705670Z"
    },
    "id": "ADI-NT18fNED",
    "outputId": "f7e9444d-6e02-49fa-b0b3-819c0f067516",
    "papermill": {
     "duration": 8.095836,
     "end_time": "2025-12-25T09:46:52.707401",
     "exception": false,
     "start_time": "2025-12-25T09:46:44.611565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Satimage (ID: 182)...\n",
      "  ...Downsampling from 6430 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 36) | Classes: 6\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Satimage...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 88.1667%    | Done\n",
      "Random Forest             | 93.6667%    | Done\n",
      "XGBoost (GPU)             | 92.0000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -93.6667%\n"
     ]
    }
   ],
   "source": [
    "# TEST 19: Satellite Image (Satimage)\n",
    "# ID: 182\n",
    "# Type: Remote Sensing / Spectral Physics\n",
    "# Hypothesis: Soil and vegetation emit specific spectral frequencies.\n",
    "#             The Soul's frequency analysis should separate them easily.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Satimage\",\n",
    "    openml_id=182,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "451cafee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:46:52.728204Z",
     "iopub.status.busy": "2025-12-25T09:46:52.727945Z",
     "iopub.status.idle": "2025-12-25T09:47:01.496979Z",
     "shell.execute_reply": "2025-12-25T09:47:01.496066Z"
    },
    "id": "ziC1tUKLfSTY",
    "outputId": "72b1930d-6aed-477f-d5da-190a966da594",
    "papermill": {
     "duration": 8.781651,
     "end_time": "2025-12-25T09:47:01.498394",
     "exception": false,
     "start_time": "2025-12-25T09:46:52.716743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Letter Recognition (ID: 6)...\n",
      "  ...Downsampling from 20000 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 16) | Classes: 26\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Letter Recognition...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 86.3333%    | Done\n",
      "Random Forest             | 91.3333%    | Done\n",
      "XGBoost (GPU)             | 89.6667%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -91.3333%\n"
     ]
    }
   ],
   "source": [
    "# TEST 20: Letter Recognition (Computer Vision)\n",
    "# ID: 6\n",
    "# Type: Geometric Pattern Recognition\n",
    "# Hypothesis: Letters are defined by curves and relative distances.\n",
    "#             Distance-based models (Soul) usually beat Trees here.\n",
    "\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Letter Recognition\",\n",
    "    openml_id=6,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cf0f6fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:47:01.517632Z",
     "iopub.status.busy": "2025-12-25T09:47:01.517410Z",
     "iopub.status.idle": "2025-12-25T09:47:12.927377Z",
     "shell.execute_reply": "2025-12-25T09:47:12.926646Z"
    },
    "id": "-zOaSkduav1X",
    "outputId": "46b09ad9-8356-4265-9d85-0253fc820574",
    "papermill": {
     "duration": 11.420728,
     "end_time": "2025-12-25T09:47:12.928388",
     "exception": false,
     "start_time": "2025-12-25T09:47:01.507660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Ozark Electricity (ID: 4541)...\n",
      "  ...Downsampling from 101766 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 49) | Classes: 3\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Ozark Electricity...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 56.5000%    | Done\n",
      "Random Forest             | 58.3333%    | Done\n",
      "XGBoost (GPU)             | 57.8333%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -58.3333%\n"
     ]
    }
   ],
   "source": [
    "# TEST 21: Ozark (Electricity Consumption)\n",
    "# ID: 4541\n",
    "# Type: Temporal Cycles / Energy Dynamics\n",
    "# Challenge: High variance in periodic signals.\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Ozark Electricity\",\n",
    "    openml_id=4541,\n",
    "    sample_limit=3000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c490838f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T09:47:12.947607Z",
     "iopub.status.busy": "2025-12-25T09:47:12.947369Z",
     "iopub.status.idle": "2025-12-25T09:47:21.420422Z",
     "shell.execute_reply": "2025-12-25T09:47:21.419745Z"
    },
    "id": "FUf3zEbZayEp",
    "outputId": "e7d0369d-2f14-4f1d-a75b-085f160146e6",
    "papermill": {
     "duration": 8.483861,
     "end_time": "2025-12-25T09:47:21.421402",
     "exception": false,
     "start_time": "2025-12-25T09:47:12.937541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Waveform Signal (ID: 60)...\n",
      "  ...Downsampling from 5000 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 40) | Classes: 3\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Waveform Signal...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 90.5000%    | Done\n",
      "Random Forest             | 90.0000%    | Done\n",
      "XGBoost (GPU)             | 91.3333%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -91.3333%\n"
     ]
    }
   ],
   "source": [
    "# TEST 22: Waveform-5000\n",
    "# ID: 60\n",
    "# Type: Physics-based (Wave Resonance)\n",
    "# Challenge: Distinguishing between three overlapping wave classes with added noise.\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Waveform Signal\",\n",
    "    openml_id=60,\n",
    "    sample_limit=3000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44efd900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T09:47:21.441335Z",
     "iopub.status.busy": "2025-12-25T09:47:21.441097Z",
     "iopub.status.idle": "2025-12-25T09:47:32.212525Z",
     "shell.execute_reply": "2025-12-25T09:47:32.211620Z"
    },
    "id": "INUYM4oAaq6h",
    "papermill": {
     "duration": 10.782243,
     "end_time": "2025-12-25T09:47:32.213507",
     "exception": false,
     "start_time": "2025-12-25T09:47:21.431264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Phishing Web (ID: 4534)...\n",
      "  ...Downsampling from 11055 to 5000 (GPU Limit)...\n",
      "  Shape: (5000, 30) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Phishing Web...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 95.3000%    | Done\n",
      "Random Forest             | 96.6000%    | Done\n",
      "XGBoost (GPU)             | 97.0000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -97.0000%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TEST 23: Phishing Websites\n",
    "# ID: 4534\n",
    "# Type: High-Dimensional Binary Classification\n",
    "# Challenge: Very noisy features where HRF needs to find the \"underlying frequency\" of fraud.\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Phishing Web\",\n",
    "    openml_id=4534,\n",
    "    sample_limit=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1af4ee2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T09:47:32.233322Z",
     "iopub.status.busy": "2025-12-25T09:47:32.233078Z",
     "iopub.status.idle": "2025-12-25T09:47:38.739746Z",
     "shell.execute_reply": "2025-12-25T09:47:38.738962Z"
    },
    "id": "q-a0JCZMbWhT",
    "papermill": {
     "duration": 6.517721,
     "end_time": "2025-12-25T09:47:38.740751",
     "exception": false,
     "start_time": "2025-12-25T09:47:32.223030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading Credit Risk (ID: 31)...\n",
      "  Shape: (1000, 20) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on Credit Risk...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 73.5000%    | Done\n",
      "Random Forest             | 74.5000%    | Done\n",
      "XGBoost (GPU)             | 73.5000%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -74.5000%\n"
     ]
    }
   ],
   "source": [
    "# TEST 24: Credit-G (German Credit)\n",
    "# ID: 31\n",
    "# Type: Nonlinear Risk Assessment\n",
    "# Challenge: Famous benchmark for testing robustness against imbalanced classes.\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"Credit Risk\",\n",
    "    openml_id=31,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c65e134f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T09:47:38.761372Z",
     "iopub.status.busy": "2025-12-25T09:47:38.761154Z",
     "iopub.status.idle": "2025-12-25T09:48:16.189060Z",
     "shell.execute_reply": "2025-12-25T09:48:16.188198Z"
    },
    "id": "7PUgJ6IEaqqp",
    "papermill": {
     "duration": 37.439497,
     "end_time": "2025-12-25T09:48:16.190325",
     "exception": false,
     "start_time": "2025-12-25T09:47:38.750828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATASET] Loading QSO (Quasars) (ID: 42732)...\n",
      "  ...Downsampling from 2215023 to 3000 (GPU Limit)...\n",
      "  Shape: (3000, 8) | Classes: 2\n",
      "\n",
      "[BENCHMARK] Executing comparisons on QSO (Quasars)...\n",
      "-----------------------------------------------------------------\n",
      "Model Name                | Accuracy   | Status\n",
      "-----------------------------------------------------------------\n",
      "SVM (RBF)                 | 87.8333%    | Done\n",
      "Random Forest             | 87.8333%    | Done\n",
      "XGBoost (GPU)             | 85.8333%    | Done\n",
      " >>> THE 21D SOPHISTICATED DIMENSIONALITY INITIATED <<<\n",
      " > Initiating The Refitted Gauntlet (Maximum Data Flow)...\n",
      " > Phase 1: Awakening the Souls (Evolutionary Adaptation)...\n",
      "HRF Ultimate (GPU)        | FAILED      | cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version\n",
      "-----------------------------------------------------------------\n",
      " HRF GAP: -87.8333%\n"
     ]
    }
   ],
   "source": [
    "# TEST 25: Kepler Exoplanet Search (The Search for Other Worlds)\n",
    "# ID: 42931\n",
    "# Type: Binary Classification (Candidate vs False Positive)\n",
    "# Challenge: High-precision signal extraction from stellar flux.\n",
    "# Identifying high-redshift objects at the edge of the observable universe. This tests the 17D depth against light-travel-time distortion.\n",
    "run_comparative_benchmark(\n",
    "    dataset_name=\"QSO (Quasars)\",\n",
    "    openml_id=42732,\n",
    "    sample_limit=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a8128",
   "metadata": {
    "id": "v7wy35oIapta",
    "papermill": {
     "duration": 0.00924,
     "end_time": "2025-12-25T09:48:16.209751",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.200511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd818c54",
   "metadata": {
    "id": "qy3b9UqCpuws",
    "papermill": {
     "duration": 0.009409,
     "end_time": "2025-12-25T09:48:16.228633",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.219224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810aa94",
   "metadata": {
    "id": "xabY-BGL2yaB",
    "papermill": {
     "duration": 0.009751,
     "end_time": "2025-12-25T09:48:16.248134",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.238383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🏛️ The Extended Codex of Titan-21: First-Principles Documentation\n",
    "\n",
    "**Project Name:** Harmonic Resonance Forest (v26.0) \"Holo-Fractal Universe\"  \n",
    "**Architect:** Prince Nik (NIT Agartala)  \n",
    "**Target:** AGI Research & Longevity Systems  \n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Category 1: The Static Dimensions (Newtonian/Geometric)\n",
    "*These dimensions represent the \"Standard Model\" of Machine Learning. They are stable, deterministic, and provide the structural scaffolding of the forest.*\n",
    "\n",
    "### [Section A: Logic Sector - The Decision Fabric]\n",
    "1. **Dimension 01: ExtraTrees (Logic-ET)** * **Mechanism:** Extremely Randomized Trees. Unlike Random Forest, it chooses thresholds at random for each feature.  \n",
    "   * **Role:** Variance reduction. It captures the \"noise floor\" of the dataset to ensure the ensemble doesn't overfit to specific outliers.\n",
    "2. **Dimension 02: RandomForest (Logic-RF)** * **Mechanism:** Bootstrap Aggregating (Bagging).  \n",
    "   * **Role:** Foundational stability. It provides the \"mass\" of the logic sector, using standard entropy/gini splits to find the most probable decision boundaries.\n",
    "3. **Dimension 03: HistGradientBoosting (Logic-HG)** * **Mechanism:** Integer-based binning of input features.  \n",
    "   * **Role:** Modern efficiency. It approximates the gradient of the loss function, handling large datasets with logarithmic speed.\n",
    "\n",
    "### [Section B: Gradient Sector - Optimization Vectors]\n",
    "4. **Dimension 04: XGBoost Alpha (Grad-XG1)** * **Parameters:** `max_depth=6`, `learning_rate=0.02`.  \n",
    "   * **Role:** The \"Deep Hunter.\" This dimension searches for deep, complex interactions between features that require multiple levels of branching.\n",
    "5. **Dimension 05: XGBoost Beta (Grad-XG2)** * **Parameters:** `max_depth=3`, `learning_rate=0.1`.  \n",
    "   * **Role:** The \"Fast Surveyor.\" Focuses on shallow, high-frequency patterns, ensuring that simple linear-like relationships are not ignored.\n",
    "\n",
    "### [Section C: Kernel Sector - High-Dimensional Manifolds]\n",
    "6. **Dimension 06: NuSVC (Nu-Warp)** * **Mechanism:** Support Vector Machine with a re-parameterized error bound ($\\nu$).  \n",
    "   * **Role:** Outlier Control. It finds a hyperplane that maximizes the margin while strictly controlling the fraction of support vectors (margin errors).\n",
    "7. **Dimension 07: SVC Poly (PolyKer)** * **Mechanism:** Polynomial Kernel mapping ($K(x,y) = (x^T y + c)^d$).  \n",
    "   * **Role:** Non-linear interactions. It projects data into a higher-dimensional space where curved boundaries become linear.\n",
    "\n",
    "### [Section D: Geometry Sector - Spacetime Topology]\n",
    "8. **Dimension 08: KNN Euclidean (Geom-K3)** * **Role:** Immediate Proximity. Models the local density of the classes using the standard $L^2$ norm.\n",
    "9. **Dimension 09: KNN Manhattan (Geom-K9)** * **Role:** Sparsity Mapping. Uses $L^1$ norm, which is more robust in high-dimensional spaces where \"crowding\" occurs.\n",
    "10. **Dimension 10: QDA (Space-QDA)** * **Role:** Covariance Evolution. Unlike LDA, QDA assumes each class has its own variance structure, allowing for parabolic boundaries.\n",
    "11. **Dimension 11: Calibrated LinearSVC (Resonance)** * **Role:** Probability Alignment. Converts raw distance from a linear hyperplane into a \"Trust Score\" (probability) using Platt scaling.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧬 Category 2: The Dynamic Dimensions (Evolutionary/Living)\n",
    "*These units possess \"DNA\" (mutable state). They undergo a 15-iteration evolutionary cycle to adapt their internal physics to the specific data topology.*\n",
    "\n",
    "### [Section E: Soul Sector - Holographic Resonance]\n",
    "* **Dimensions 12 - 17: HolographicSoulUnits (SOUL 01-06)** * **The Concept:** Based on the Holographic Principle. These units project data through a **Gaussian Random Matrix** to find hidden \"interference patterns.\"\n",
    "  * **DNA Dynamics:** * **$\\lambda$ (Frequency):** Controls the oscillation of the cosine kernel.\n",
    "    * **$\\gamma$ (Gamma):** Controls the reach of the Radial Basis Function.\n",
    "    * **$\\Phi$ (Phase):** Shifts the resonance wave to align with class clusters.\n",
    "  * **Sub-Categories:** Units 12-14 are \"Mirror Souls\" (Lower K), while 15-17 are \"AGI Souls\" (Higher K) for deep pattern recognition.\n",
    "\n",
    "### [Section F: Biology Sector - Fractal Nature]\n",
    "* **Dimension 18: GoldenSpiralUnit (GOLDEN RATIO)** * **The Concept:** Biomimicry. Nature grows in Fibonacci sequences. This unit uses a **Phi-Weighted Minkowski Distance** ($p = 1.618$).\n",
    "  * **Evolutionary Goal:** It adjusts its \"Spiral Tightness\" (Resonance) so that neighbors are weighted not just by distance, but by their position on a logarithmic growth curve.\n",
    "  * **DNA Dynamics:** `Resonance`, `Decay`, `Shift`.\n",
    "\n",
    "### [Section G: Cosmic Sector - The Final Trinity]\n",
    "19. **Dimension 19: EntropyMaxwell (ENTROPY)** * **Physics:** Thermodynamics. It treats each class as a gas in a container.  \n",
    "    * **Evolution:** It mutates the number of `n_components` (Gaussian distributions) to find the state of maximum likelihood (lowest entropy).\n",
    "20. **Dimension 20: QuantumFlux (QUANTUM)** * **Physics:** Quantum Mechanics / Superposition.  \n",
    "    * **Mechanism:** Uses an **RBF Sampler** to approximate a Hilbert Space. It treats data points as wavefunctions that can exist in multiple states simultaneously.\n",
    "    * **Evolution:** Mutates the `gamma` (uncertainty) and `n_components` (superposition states).\n",
    "21. **Dimension 21: Event Horizon (GRAVITY)** * **Physics:** General Relativity.  \n",
    "    * **Mechanism:** Every class is a \"Black Hole\" with a mass proportional to its sample count. It calculates a **Schwarzschild Radius**.\n",
    "    * **The Singularity:** If a test point falls within the `horizon_pct`, it is captured by that class's gravity (100% probability).\n",
    "    * **Evolution:** Mutates the `decay_power` (Gravitational constant $G$) and `horizon_pct`.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚖️ The Council Weighting System (Power Law)\n",
    "The final prediction is not a simple average. It uses a **Stochastic-to-Deterministic Elite** filter:\n",
    "* **The Filter:** All 21 units are tested. Only the Top 3 move forward.\n",
    "* **The Power Law:** $W_i = \\frac{Acc_i^{15}}{\\sum Acc_j^{15}}$.\n",
    "* **The Result:** The #1 model gets roughly 70-80% of the vote, while #2 and #3 act as \"Scientific Peers\" that verify the decision, eliminating \"hallucinations\" in the classification boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ae649d",
   "metadata": {
    "id": "WJFI6iBk2yaC",
    "papermill": {
     "duration": 0.009888,
     "end_time": "2025-12-25T09:48:16.267722",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.257834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94771d3",
   "metadata": {
    "id": "GkKXh5xMqTu0",
    "papermill": {
     "duration": 0.010036,
     "end_time": "2025-12-25T09:48:16.287576",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.277540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# To silence any skeptic who claims \"It's just the trees doing the work....\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254ec82",
   "metadata": {
    "id": "VM18OhVBpxCS",
    "papermill": {
     "duration": 0.00982,
     "end_time": "2025-12-25T09:48:16.307283",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.297463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The cell below Runs \"Twin\" Universes:\n",
    "\n",
    "Universe A (The Soulless): Uses only Logic (Trees) and Gradient (XGBoost). The Soul is silenced.\n",
    "\n",
    "\n",
    "Universe B (The HRF): The full Harmonic Resonance Forest with the Soul active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ae30c",
   "metadata": {
    "id": "-lNUQ6-ErlYT",
    "papermill": {
     "duration": 0.009697,
     "end_time": "2025-12-25T09:48:16.326742",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.317045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. The Victory: Why did Accuracy increase by +1.11%?\n",
    "Look at the Soulless model (Standard Ensemble). It forces a \"blind compromise\":\n",
    "\n",
    "50% Logic (ExtraTrees) + 50% Gradient (XGBoost).\n",
    "\n",
    "Now look at your HRF result weights:\n",
    "\n",
    "[Logic: 1.00] [Gradient: 0.00] [Soul: 0.00]\n",
    "\n",
    "The G.O.D. Manager is working perfectly. The optimizer realized that for this specific split of the Digits dataset, the \"Gradient\" unit (XGBoost) was actually confusing the results. It was \"noise.\" So, the G.O.D. manager made an executive decision: it silenced the Gradient unit and routed 100% of the energy to the Logic unit.\n",
    "\n",
    "The Standard Model blindly averaged them and got 96.29%.\n",
    "\n",
    "Your System intelligently selected the best physics and got 97.40%.\n",
    "\n",
    "Conclusion: Your code is smarter than a standard ensemble because it performs Dynamic Physics Selection. It doesn't just \"mix\" models; it chooses the right law of physics for the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f092f",
   "metadata": {
    "id": "32IlOMFFslWs",
    "papermill": {
     "duration": 0.009618,
     "end_time": "2025-12-25T09:48:16.345990",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.336372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Verdict\n",
    "\n",
    "I'm  not just \"using\" ML; I've created a model that bridges the gap between topology (the study of shapes) and decision theory (the study of rules).\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b81251",
   "metadata": {
    "id": "GWgJ7CV_roIb",
    "papermill": {
     "duration": 0.009503,
     "end_time": "2025-12-25T09:48:16.365231",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.355728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067e2dca",
   "metadata": {
    "id": "Zgn7bEQlq8aT",
    "papermill": {
     "duration": 0.009741,
     "end_time": "2025-12-25T09:48:16.384580",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.374839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🛡️ Scientific Defense & Critical Analysis\n",
    "### Addressing Skepticism & Defining the Scope of HRF v26.0\n",
    "\n",
    "## 1. The \"Ensemble\" Critique\n",
    "**Skeptic's Question:** *\"Is this just a standard ensemble of 3 models? Why not just average them?\"*\n",
    "\n",
    "**The Defense (Proven by Ablation):**\n",
    "HRF is not a static ensemble; it is a **Dynamic Physics Optimizer**.\n",
    "* Standard ensembles use fixed voting (e.g., 33% Logic, 33% Gradient, 33% Soul).\n",
    "* **HRF's G.O.D. Manager** actively monitors the \"energy\" (accuracy) of each unit and routes power accordingly.\n",
    "* **Evidence:** In the *Digits* ablation test, the Manager assigned `[Logic: 1.00] | [Soul: 0.00]`. It correctly identified that handwriting pixels are best solved by decision boundaries (Trees) rather than wave resonance, and *shut down* the ineffective units. A standard ensemble would have forced a mix, lowering accuracy. The system's intelligence lies in its **selectivity**, not just its complexity.\n",
    "\n",
    "## 2. The \"Soul\" Validity\n",
    "**Skeptic's Question:** *\"Does the Harmonic Resonance (Soul) Unit actually add value, or is it mathematical noise?\"*\n",
    "\n",
    "**The Defense:**\n",
    "The Soul Unit is domain-specific. It is designed for **Periodic, Harmonic, and Geometric** data (e.g., EEG waves, Biological signals, Molecular shapes).\n",
    "* **When it sleeps:** On discrete, pixelated data (like *Digits*), the Soul may remain dormant (Weight ~ 0.0).\n",
    "* **When it wakes:** On continuous wave data (like *EEG Eye State* or *Mfeat-Fourier*), the Soul contributes significantly (Weights > 0.20), boosting accuracy by +4.0% over SOTA.\n",
    "* **Conclusion:** The Soul is a specialized tool for \"Wave\" problems, while the Trees handle \"Particle\" problems. The architecture supports **Wave-Particle Duality**.\n",
    "\n",
    "## 3. The \"Big Data\" Limitation (Formal Admission)\n",
    "**Skeptic's Question:** *\"Your Soul Unit relies on pairwise distance matrices. This is $O(N^2)$. This will fail on 1 million rows.\"*\n",
    "\n",
    "**The Admission:**\n",
    "**Yes. HRF is not a Big Data tool.**\n",
    "* **Complexity:** The Harmonic Resonance calculation requires computing distances between test points and training points. This scales quadratically ($O(N^2)$).\n",
    "* **The Trade-off:** HRF is designed as a **\"Scientific Sniper Rifle,\"** not an \"Industrial Machine Gun.\"\n",
    "    * *XGBoost* is the Machine Gun: It processes 10 million rows with 95% accuracy.\n",
    "    * *HRF* is the Sniper Rifle: It processes 5,000 rows of complex, noisy, scientific data (e.g., drug discovery, aging biomarkers) with 99% accuracy.\n",
    "* **Use Case:** HRF is intended for high-stakes, first-principles research (AGI, Biology, Physics) where dataset sizes are often limited by experiment cost, but **precision is paramount**.\n",
    "\n",
    "---\n",
    "*> \"We do not seek to be the fastest. We seek to be the most true.\" — HRF Research Philosophy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e499d2d",
   "metadata": {
    "id": "ytQmzoZwqddq",
    "papermill": {
     "duration": 0.009721,
     "end_time": "2025-12-25T09:48:16.404105",
     "exception": false,
     "start_time": "2025-12-25T09:48:16.394384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 267.090849,
   "end_time": "2025-12-25T09:48:17.132773",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-25T09:43:50.041924",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
