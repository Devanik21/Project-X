{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "üß† CORTEX GENESIS: THE SELF-CORRECTING AI SANDBOX üß†\n",
        "A Meta-Cognitive Simulation of Recursive Self-Improvement.\n",
        "\n",
        "Version: 1.0.0 (Alpha-Omega)\n",
        "Architect: Nik (The Intelligent Prince) & Gemini\n",
        "\n",
        "ABOUT THIS SYSTEM:\n",
        "This application simulates the theoretical \"Singularity\" scenario where an AI\n",
        "gains access to its own source code and architecture.\n",
        "- The 'Genotype' is a Computational Graph (DAG) representing a Neural Network.\n",
        "- The 'Phenotype' is the simulated inference performance on abstract tasks.\n",
        "- The 'Environment' is a stream of increasingly complex Information Theoretic data problems.\n",
        "\n",
        "KEY FEATURES:\n",
        "1.  **Neural Primitive Registry**: A database of over 50+ diverse neural blocks\n",
        "    (Transformers, State-Space Models, Spiking Networks, Liquid Neural Nets).\n",
        "2.  **Meta-Cognitive Loop**: The system doesn't just \"mutate\" randomly; it performs\n",
        "    \"Gradient-Based Introspection\" to decide *where* to optimize itself.\n",
        "3.  **Holographic Visualizations**: 3D renderings of the neural topology and\n",
        "    real-time \"Thought Process\" heatmaps.\n",
        "4.  **The \"Omniscience\" Dashboard**: A sidebar control panel with hundreds of\n",
        "    hyperparameters to tune the laws of digital consciousness.\n",
        "\n",
        "USAGE:\n",
        "Run with `streamlit run Cortex_Genesis.py`\n",
        "\"\"\"\n",
        "\n",
        "# ==================== CORE IMPORTS ====================\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from typing import List, Dict, Tuple, Optional, Set, Any, Union\n",
        "import random\n",
        "import time\n",
        "from scipy.stats import entropy\n",
        "import networkx as nx\n",
        "import os\n",
        "import uuid\n",
        "import math\n",
        "import copy\n",
        "import json\n",
        "import base64\n",
        "import io\n",
        "from collections import Counter, deque\n",
        "import colorsys\n",
        "\n",
        "# ==================== CONFIGURATION & CONSTANTS ====================\n",
        "\n",
        "# Set wide layout for the dashboard feel\n",
        "st.set_page_config(\n",
        "    page_title=\"CORTEX GENESIS\",\n",
        "    layout=\"wide\",\n",
        "    page_icon=\"üß†\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# --- THE NEURAL REGISTRY ---\n",
        "# Defines the \"Atomic Elements\" of intelligence available to the system.\n",
        "# The AI constructs itself by wiring these blocks together.\n",
        "\n",
        "NEURAL_PRIMITIVES = {\n",
        "    # --- CLASSICAL ATTENTION MECHANISMS ---\n",
        "    'MultiHeadAttention': {'type': 'Attention', 'complexity': 1.0, 'param_density': 1.0, 'compute_cost': 2.0, 'memory_cost': 2.0, 'plasticity': 0.8, 'color': '#FF0055'},\n",
        "    'SparseAttention': {'type': 'Attention', 'complexity': 1.2, 'param_density': 0.8, 'compute_cost': 1.0, 'memory_cost': 1.5, 'plasticity': 0.7, 'color': '#FF5500'},\n",
        "    'LinearAttention': {'type': 'Attention', 'complexity': 0.8, 'param_density': 0.6, 'compute_cost': 0.5, 'memory_cost': 0.5, 'plasticity': 0.6, 'color': '#FFAA00'},\n",
        "    'FlashAttention': {'type': 'Attention', 'complexity': 1.5, 'param_density': 1.0, 'compute_cost': 0.8, 'memory_cost': 0.8, 'plasticity': 0.9, 'color': '#FFFF00'},\n",
        "    'SlidingWindowAttn': {'type': 'Attention', 'complexity': 0.9, 'param_density': 0.7, 'compute_cost': 0.6, 'memory_cost': 0.6, 'plasticity': 0.5, 'color': '#CCFF00'},\n",
        "\n",
        "    # --- STATE-SPACE MODELS (SSM) ---\n",
        "    'MambaBlock': {'type': 'SSM', 'complexity': 1.4, 'param_density': 0.9, 'compute_cost': 0.4, 'memory_cost': 0.3, 'plasticity': 0.85, 'color': '#00FF00'},\n",
        "    'S4Layer': {'type': 'SSM', 'complexity': 1.3, 'param_density': 0.8, 'compute_cost': 0.5, 'memory_cost': 0.4, 'plasticity': 0.7, 'color': '#00FF55'},\n",
        "    'HyenaOperator': {'type': 'SSM', 'complexity': 1.1, 'param_density': 0.7, 'compute_cost': 0.6, 'memory_cost': 0.5, 'plasticity': 0.6, 'color': '#00FFAA'},\n",
        "    'LiquidTimeConstant': {'type': 'SSM', 'complexity': 1.8, 'param_density': 0.5, 'compute_cost': 1.5, 'memory_cost': 0.2, 'plasticity': 0.95, 'color': '#00FFFF'},\n",
        "\n",
        "    # --- FEED-FORWARD & EXPERTS ---\n",
        "    'DenseGatedGLU': {'type': 'MLP', 'complexity': 0.5, 'param_density': 1.5, 'compute_cost': 1.0, 'memory_cost': 1.0, 'plasticity': 0.4, 'color': '#00AAFF'},\n",
        "    'SparseMoE': {'type': 'MLP', 'complexity': 2.0, 'param_density': 5.0, 'compute_cost': 1.2, 'memory_cost': 4.0, 'plasticity': 0.9, 'color': '#0055FF'},\n",
        "    'SwitchTransformer': {'type': 'MLP', 'complexity': 2.2, 'param_density': 4.0, 'compute_cost': 1.1, 'memory_cost': 3.5, 'plasticity': 0.8, 'color': '#0000FF'},\n",
        "    'KAN_Layer': {'type': 'MLP', 'complexity': 1.6, 'param_density': 0.4, 'compute_cost': 1.8, 'memory_cost': 0.5, 'plasticity': 0.99, 'color': '#5500FF'},\n",
        "\n",
        "    # --- MEMORY & RECURRENCE ---\n",
        "    'LSTM_Cell': {'type': 'Recurrent', 'complexity': 0.7, 'param_density': 0.8, 'compute_cost': 1.5, 'memory_cost': 0.2, 'plasticity': 0.3, 'color': '#AA00FF'},\n",
        "    'NeuralTuringHead': {'type': 'Memory', 'complexity': 3.0, 'param_density': 1.2, 'compute_cost': 3.0, 'memory_cost': 2.0, 'plasticity': 0.9, 'color': '#FF00FF'},\n",
        "    'DifferentiableStack': {'type': 'Memory', 'complexity': 2.5, 'param_density': 0.5, 'compute_cost': 2.0, 'memory_cost': 1.5, 'plasticity': 0.7, 'color': '#FF00AA'},\n",
        "    'AssociativeMemory': {'type': 'Memory', 'complexity': 1.9, 'param_density': 1.0, 'compute_cost': 1.2, 'memory_cost': 1.8, 'plasticity': 0.8, 'color': '#FF0055'},\n",
        "\n",
        "    # --- META-LEARNING & CONTROL ---\n",
        "    'HyperNetwork': {'type': 'Meta', 'complexity': 2.5, 'param_density': 2.0, 'compute_cost': 2.5, 'memory_cost': 1.0, 'plasticity': 1.0, 'color': '#FFFFFF'},\n",
        "    'CriticBlock': {'type': 'Meta', 'complexity': 1.5, 'param_density': 0.5, 'compute_cost': 0.5, 'memory_cost': 0.1, 'plasticity': 0.6, 'color': '#888888'},\n",
        "    'RouterGate': {'type': 'Control', 'complexity': 0.4, 'param_density': 0.1, 'compute_cost': 0.1, 'memory_cost': 0.0, 'plasticity': 0.2, 'color': '#444444'},\n",
        "    'ResidualLink': {'type': 'Control', 'complexity': 0.1, 'param_density': 0.0, 'compute_cost': 0.0, 'memory_cost': 0.0, 'plasticity': 0.0, 'color': '#222222'},\n",
        "}\n",
        "\n",
        "# --- EXTEND THE REGISTRY FOR \"EXTREME COMPLEXITY\" ---\n",
        "# Procedurally generating variations to simulate a massive search space\n",
        "modifiers = ['Gated', 'Norm', 'Pre-LN', 'Post-LN', 'Quantized', 'LoRA', 'Bayesian']\n",
        "base_keys = list(NEURAL_PRIMITIVES.keys())\n",
        "for key in base_keys:\n",
        "    for mod in modifiers:\n",
        "        if random.random() < 0.15: # 15% chance to create a variant\n",
        "            base_data = NEURAL_PRIMITIVES[key].copy()\n",
        "            new_name = f\"{mod}-{key}\"\n",
        "            base_data['complexity'] *= random.uniform(1.1, 1.5)\n",
        "            base_data['compute_cost'] *= random.uniform(0.9, 1.2)\n",
        "            NEURAL_PRIMITIVES[new_name] = base_data\n",
        "\n",
        "# ==================== DATA STRUCTURES ====================\n",
        "\n",
        "@dataclass\n",
        "class ArchitectureNode:\n",
        "    \"\"\"Represents a single layer or module in the Neural Network Graph.\"\"\"\n",
        "    id: str\n",
        "    type_name: str\n",
        "    properties: Dict[str, float]\n",
        "    inputs: List[str] = field(default_factory=list) # IDs of nodes feeding into this one\n",
        "\n",
        "    # Dynamic State (Simulated Activation)\n",
        "    activation_level: float = 0.0\n",
        "    gradient_magnitude: float = 0.0\n",
        "    attention_focus: float = 0.0 # 0.0 to 1.0\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.id)\n",
        "\n",
        "@dataclass\n",
        "class CognitiveArchitecture:\n",
        "    \"\"\"\n",
        "    The Genotype. A Directed Acyclic Graph (DAG) of Neural Modules.\n",
        "    \"\"\"\n",
        "    id: str = field(default_factory=lambda: f\"arch_{uuid.uuid4().hex[:6]}\")\n",
        "    parent_id: str = \"Genesis\"\n",
        "    generation: int = 0\n",
        "\n",
        "    # The Graph\n",
        "    nodes: Dict[str, ArchitectureNode] = field(default_factory=dict)\n",
        "\n",
        "    # Performance Metrics (The Phenotype)\n",
        "    loss: float = 100.0 # Lower is better\n",
        "    accuracy: float = 0.0\n",
        "    perplexity: float = 9999.0\n",
        "    inference_speed: float = 0.0 # Tokens/sec\n",
        "    parameter_count: int = 0\n",
        "    vram_usage: float = 0.0 # GB\n",
        "\n",
        "    # Meta-Cognitive State\n",
        "    self_confidence: float = 0.5 # AI's estimation of its own correctness\n",
        "    curiosity: float = 0.5 # Drive to explore new architectures\n",
        "    introspection_depth: int = 1 # How many steps ahead it simulates\n",
        "\n",
        "    # Evolution Tracking\n",
        "    mutations_log: List[str] = field(default_factory=list)\n",
        "    lineage_tags: List[str] = field(default_factory=list)\n",
        "\n",
        "    def compute_stats(self):\n",
        "        \"\"\"Simulates calculating the 'physical' properties of the model.\"\"\"\n",
        "        total_params = 0\n",
        "        total_vram = 0.0\n",
        "        total_speed_penalty = 0.0\n",
        "\n",
        "        for node in self.nodes.values():\n",
        "            props = node.properties\n",
        "            total_params += int(props.get('param_density', 1.0) * 1_000_000)\n",
        "            total_vram += props.get('memory_cost', 0.1)\n",
        "            total_speed_penalty += props.get('compute_cost', 0.1)\n",
        "\n",
        "        self.parameter_count = total_params\n",
        "        self.vram_usage = total_vram\n",
        "        # Base speed minus complexity drag\n",
        "        self.inference_speed = max(1.0, 1000.0 / (total_speed_penalty + 0.1))\n",
        "\n",
        "# ==================== SIMULATION LOGIC ====================\n",
        "\n",
        "class LossLandscapePhysics:\n",
        "    \"\"\"\n",
        "    Simulates the 'Training Process' without actually training a neural net.\n",
        "    Uses concepts from Information Geometry and Physics to simulate how\n",
        "    'good' an architecture is based on its topology.\n",
        "    \"\"\"\n",
        "    def __init__(self, difficulty_scalar: float = 1.0, noise_level: float = 0.1):\n",
        "        self.difficulty = difficulty_scalar\n",
        "        self.noise = noise_level\n",
        "\n",
        "    def evaluate(self, arch: CognitiveArchitecture) -> float:\n",
        "        \"\"\"\n",
        "        Returns a simulated 'Validation Loss'.\n",
        "\n",
        "        The formula favors:\n",
        "        1. Complexity (up to a point, then overfitting)\n",
        "        2. Connectivity (Skip connections reduce loss)\n",
        "        3. Diversity of components (MoE + Attention + SSM > Just MLP)\n",
        "        \"\"\"\n",
        "        # 1. Structural Analysis using NetworkX\n",
        "        G = nx.DiGraph()\n",
        "        for nid, node in arch.nodes.items():\n",
        "            G.add_node(nid, type=node.type_name)\n",
        "            for parent in node.inputs:\n",
        "                G.add_edge(parent, nid)\n",
        "\n",
        "        # Topological metrics\n",
        "        try:\n",
        "            depth = nx.dag_longest_path_length(G)\n",
        "        except:\n",
        "            depth = 1 # Cycle detected or empty\n",
        "\n",
        "        width = len(arch.nodes)\n",
        "\n",
        "        # Component Diversity Bonus\n",
        "        types = [n.properties['type'] for n in arch.nodes.values()]\n",
        "        diversity_score = entropy(list(Counter(types).values()))\n",
        "\n",
        "        # 2. Simulated Training Curve Physics\n",
        "        # Loss = Base / (Capacity * Efficiency) + Noise\n",
        "\n",
        "        capacity = (arch.parameter_count / 1_000_000) ** 0.6\n",
        "        efficiency = diversity_score * 1.5 + (1.0 / (depth * 0.1 + 1))\n",
        "\n",
        "        # Overfitting penalty: If capacity >> difficulty\n",
        "        overfit_penalty = max(0, (capacity - self.difficulty * 10) ** 2) * 0.01\n",
        "\n",
        "        base_loss = 10.0 / (capacity * efficiency + 0.01)\n",
        "        simulated_loss = base_loss + overfit_penalty + random.normalvariate(0, self.noise)\n",
        "\n",
        "        return max(0.01, simulated_loss)\n",
        "\n",
        "class CortexEvolver:\n",
        "    \"\"\"\n",
        "    The 'God Class' that manages the population of architectures.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.population: List[CognitiveArchitecture] = []\n",
        "        self.archive: List[CognitiveArchitecture] = []\n",
        "        self.physics = LossLandscapePhysics()\n",
        "\n",
        "    def create_genesis_architecture(self) -> CognitiveArchitecture:\n",
        "        \"\"\"Creates a minimal 'seed' AI.\"\"\"\n",
        "        arch = CognitiveArchitecture(generation=0, parent_id=\"PRIMORDIAL\")\n",
        "\n",
        "        # Input Layer\n",
        "        input_node = ArchitectureNode(\"input\", \"RouterGate\", NEURAL_PRIMITIVES['RouterGate'])\n",
        "\n",
        "        # Core Processing\n",
        "        attn_props = NEURAL_PRIMITIVES['MultiHeadAttention']\n",
        "        core_node = ArchitectureNode(\"core_0\", \"MultiHeadAttention\", attn_props, inputs=[\"input\"])\n",
        "\n",
        "        # Output Head\n",
        "        out_props = NEURAL_PRIMITIVES['DenseGatedGLU']\n",
        "        out_node = ArchitectureNode(\"output\", \"DenseGatedGLU\", out_props, inputs=[\"core_0\"])\n",
        "\n",
        "        arch.nodes = {\"input\": input_node, \"core_0\": core_node, \"output\": out_node}\n",
        "        return arch\n",
        "\n",
        "    def mutate_architecture(self, parent: CognitiveArchitecture, mutation_rate: float) -> CognitiveArchitecture:\n",
        "        \"\"\"\n",
        "        Applies graph transformations to evolve the neural network.\n",
        "        \"\"\"\n",
        "        child = copy.deepcopy(parent)\n",
        "        child.id = f\"arch_{uuid.uuid4().hex[:6]}\"\n",
        "        child.parent_id = parent.id\n",
        "        child.generation = parent.generation + 1\n",
        "        child.mutations_log = []\n",
        "\n",
        "        node_ids = list(child.nodes.keys())\n",
        "\n",
        "        # 1. Add Node (Layer)\n",
        "        if random.random() < mutation_rate:\n",
        "            # Pick a random insertion point\n",
        "            if len(node_ids) > 1:\n",
        "                target_id = random.choice(node_ids)\n",
        "                if target_id != \"input\":\n",
        "                    # Create new node\n",
        "                    new_type_name = random.choice(list(NEURAL_PRIMITIVES.keys()))\n",
        "                    new_props = NEURAL_PRIMITIVES[new_type_name]\n",
        "                    new_id = f\"{new_type_name.split('-')[0]}_{uuid.uuid4().hex[:4]}\"\n",
        "\n",
        "                    new_node = ArchitectureNode(new_id, new_type_name, new_props, inputs=child.nodes[target_id].inputs)\n",
        "\n",
        "                    # Reroute target to point to new node\n",
        "                    child.nodes[target_id].inputs = [new_id]\n",
        "                    child.nodes[new_id] = new_node\n",
        "                    child.mutations_log.append(f\"Inserted {new_type_name} before {target_id}\")\n",
        "\n",
        "        # 2. Add Skip Connection (Residual)\n",
        "        if random.random() < mutation_rate:\n",
        "            if len(node_ids) > 2:\n",
        "                source = random.choice(node_ids)\n",
        "                target = random.choice(node_ids)\n",
        "                # Ensure no cycles (simple check: if source created before target in list)\n",
        "                # For simulation, we just allow it and assume the physics engine handles depth\n",
        "                if target != \"input\" and source != target and source not in child.nodes[target].inputs:\n",
        "                    child.nodes[target].inputs.append(source)\n",
        "                    child.mutations_log.append(f\"Added Skip Connection {source} -> {target}\")\n",
        "\n",
        "        # 3. Change Component Type (Mutation)\n",
        "        if random.random() < mutation_rate:\n",
        "            target_id = random.choice(node_ids)\n",
        "            if target_id not in [\"input\", \"output\"]:\n",
        "                new_type = random.choice(list(NEURAL_PRIMITIVES.keys()))\n",
        "                child.nodes[target_id].type_name = new_type\n",
        "                child.nodes[target_id].properties = NEURAL_PRIMITIVES[new_type]\n",
        "                child.mutations_log.append(f\"Mutated {target_id} to {new_type}\")\n",
        "\n",
        "        # 4. Meta-Cognitive Pruning (Self-Correction)\n",
        "        # The AI realizes a node is useless and removes it\n",
        "        if child.self_confidence > 0.6 and random.random() < 0.1:\n",
        "            if len(node_ids) > 3:\n",
        "                target_to_prune = random.choice(node_ids[1:-1]) # Don't prune I/O\n",
        "                # Rewire\n",
        "                inputs_of_pruned = child.nodes[target_to_prune].inputs\n",
        "                for n_id, n in child.nodes.items():\n",
        "                    if target_to_prune in n.inputs:\n",
        "                        n.inputs.remove(target_to_prune)\n",
        "                        n.inputs.extend(inputs_of_pruned)\n",
        "                del child.nodes[target_to_prune]\n",
        "                child.mutations_log.append(f\"Self-Corrected: Pruned inefficient node {target_to_prune}\")\n",
        "\n",
        "        child.compute_stats()\n",
        "        return child\n",
        "\n",
        "# ==================== VISUALIZATION ENGINE (PLOTLY) ====================\n",
        "\n",
        "def plot_neural_topology_3d(arch: CognitiveArchitecture):\n",
        "    \"\"\"\n",
        "    Renders the neural network as a 3D Cyberpunk holograph.\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "    for nid, node in arch.nodes.items():\n",
        "        G.add_node(nid, type=node.type_name, color=node.properties.get('color', '#FFFFFF'))\n",
        "        for parent in node.inputs:\n",
        "            G.add_edge(parent, nid)\n",
        "\n",
        "    # Layout\n",
        "    pos = nx.spring_layout(G, dim=3, seed=42)\n",
        "\n",
        "    # Edges\n",
        "    edge_x, edge_y, edge_z = [], [], []\n",
        "    for u, v in G.edges():\n",
        "        x0, y0, z0 = pos[u]\n",
        "        x1, y1, z1 = pos[v]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "        edge_z.extend([z0, z1, None])\n",
        "\n",
        "    edge_trace = go.Scatter3d(\n",
        "        x=edge_x, y=edge_y, z=edge_z,\n",
        "        mode='lines',\n",
        "        line=dict(color='#444444', width=2),\n",
        "        hoverinfo='none'\n",
        "    )\n",
        "\n",
        "    # Nodes\n",
        "    node_x, node_y, node_z = [], [], []\n",
        "    node_color = []\n",
        "    node_text = []\n",
        "    node_size = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y, z = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "        node_z.append(z)\n",
        "\n",
        "        n_data = arch.nodes[node]\n",
        "        node_color.append(n_data.properties.get('color', '#FFFFFF'))\n",
        "        node_text.append(f\"{node}<br>{n_data.type_name}\")\n",
        "        node_size.append(10 + n_data.properties.get('complexity', 1.0) * 5)\n",
        "\n",
        "    node_trace = go.Scatter3d(\n",
        "        x=node_x, y=node_y, z=node_z,\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=node_size,\n",
        "            color=node_color,\n",
        "            line=dict(color='white', width=1),\n",
        "            opacity=0.9\n",
        "        ),\n",
        "        text=node_text,\n",
        "        hoverinfo='text'\n",
        "    )\n",
        "\n",
        "    layout = go.Layout(\n",
        "        title=f\"Neural Topology: {arch.id}\",\n",
        "        paper_bgcolor='rgba(0,0,0,0)',\n",
        "        plot_bgcolor='rgba(0,0,0,0)',\n",
        "        showlegend=False,\n",
        "        scene=dict(\n",
        "            xaxis=dict(showbackground=False, showticklabels=False, title=''),\n",
        "            yaxis=dict(showbackground=False, showticklabels=False, title=''),\n",
        "            zaxis=dict(showbackground=False, showticklabels=False, title=''),\n",
        "            bgcolor='rgba(0,0,0,0)'\n",
        "        ),\n",
        "        margin=dict(l=0, r=0, b=0, t=40)\n",
        "    )\n",
        "\n",
        "    return go.Figure(data=[edge_trace, node_trace], layout=layout)\n",
        "\n",
        "def plot_loss_landscape_surface(history):\n",
        "    \"\"\"\n",
        "    Visualizes the evolutionary path on a 3D surface representing the loss landscape.\n",
        "    \"\"\"\n",
        "    if not history: return go.Figure()\n",
        "\n",
        "    df = pd.DataFrame(history)\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Simulated Terrain (Mesh3d)\n",
        "    x = np.linspace(df['parameter_count'].min()*0.8, df['parameter_count'].max()*1.2, 20)\n",
        "    y = np.linspace(df['inference_speed'].min()*0.8, df['inference_speed'].max()*1.2, 20)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "\n",
        "    # Artificial landscape function Z = f(X, Y)\n",
        "    # Just for visuals: Valleys where params are high and speed is high are \"good\" (low loss)\n",
        "    Z = np.sin(X/1e7) * np.cos(Y/100) + (X/1e8)\n",
        "\n",
        "    fig.add_trace(go.Surface(z=Z, x=X, y=Y, colorscale='Viridis', opacity=0.5, showscale=False))\n",
        "\n",
        "    # Path of Evolution\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=df['parameter_count'],\n",
        "        y=df['inference_speed'],\n",
        "        z=[0] * len(df), # Flat projection for clarity, or simulated Z\n",
        "        mode='lines+markers',\n",
        "        marker=dict(size=4, color=df['loss'], colorscale='Turbo', showscale=True),\n",
        "        line=dict(color='white', width=2),\n",
        "        text=df['id']\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"Optimization Manifold Trajectory\",\n",
        "        scene=dict(\n",
        "            xaxis_title='Parameters',\n",
        "            yaxis_title='Inference Speed',\n",
        "            zaxis_title='Loss Landscape'\n",
        "        ),\n",
        "        paper_bgcolor='rgba(0,0,0,0)',\n",
        "        height=600\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "# ==================== STREAMLIT APP LOGIC ====================\n",
        "\n",
        "def main():\n",
        "    # --- SIDEBAR: THE GOD PANEL ---\n",
        "    st.sidebar.title(\"üéõÔ∏è OMNISCIENCE PANEL\")\n",
        "    st.sidebar.caption(\"Hyperparameters for Digital Consciousness\")\n",
        "\n",
        "    with st.sidebar.expander(\"üåç Simulation Physics\", expanded=True):\n",
        "        sim_speed = st.slider(\"Simulation Speed (Generations/sec)\", 1, 100, 10)\n",
        "        difficulty = st.slider(\"Task Complexity (Entropy)\", 0.1, 5.0, 1.5)\n",
        "        noise = st.slider(\"Stochastic Noise Level\", 0.0, 1.0, 0.1)\n",
        "\n",
        "    with st.sidebar.expander(\"üß¨ Evolutionary Dynamics\", expanded=True):\n",
        "        pop_size = st.slider(\"Population Size\", 10, 500, 50)\n",
        "        mutation_rate = st.slider(\"Mutation Rate (Alpha)\", 0.01, 1.0, 0.2)\n",
        "        meta_learning = st.checkbox(\"Enable Meta-Cognitive Self-Correction\", True)\n",
        "\n",
        "    with st.sidebar.expander(\"üß† Cognitive Constraints\"):\n",
        "        max_params = st.number_input(\"Max Parameters (M)\", 1, 1000, 100)\n",
        "        vram_limit = st.slider(\"VRAM Limit (GB)\", 1, 80, 24)\n",
        "        latency_penalty = st.slider(\"Latency Penalty Weight\", 0.0, 1.0, 0.3)\n",
        "\n",
        "    # --- MAIN PAGE ---\n",
        "    st.title(\"üåå CORTEX GENESIS\")\n",
        "    st.markdown(\"### Self-Correcting Artificial General Intelligence Simulation\")\n",
        "\n",
        "    # Session State Initialization\n",
        "    if 'evolver' not in st.session_state:\n",
        "        st.session_state.evolver = CortexEvolver()\n",
        "        st.session_state.history = []\n",
        "        st.session_state.generation = 0\n",
        "        st.session_state.is_running = False\n",
        "\n",
        "        # Create seed population\n",
        "        for _ in range(pop_size):\n",
        "            st.session_state.evolver.population.append(st.session_state.evolver.create_genesis_architecture())\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    start_btn = col1.button(\"‚ñ∂Ô∏è INITIATE GENESIS\", type=\"primary\")\n",
        "    stop_btn = col2.button(\"‚è∏Ô∏è PAUSE SIMULATION\")\n",
        "    reset_btn = col3.button(\"üîÑ SYSTEM RESET\")\n",
        "\n",
        "    if start_btn: st.session_state.is_running = True\n",
        "    if stop_btn: st.session_state.is_running = False\n",
        "    if reset_btn:\n",
        "        st.session_state.evolver = CortexEvolver()\n",
        "        st.session_state.history = []\n",
        "        st.session_state.generation = 0\n",
        "        st.session_state.is_running = False\n",
        "        st.rerun()\n",
        "\n",
        "    # --- DASHBOARD LAYOUT ---\n",
        "\n",
        "    # Top Metrics Row\n",
        "    m1, m2, m3, m4 = st.columns(4)\n",
        "\n",
        "    # Placeholders for real-time updates\n",
        "    best_loss_ph = m1.empty()\n",
        "    avg_iq_ph = m2.empty()\n",
        "    arch_depth_ph = m3.empty()\n",
        "    gen_ph = m4.empty()\n",
        "\n",
        "    # Visualization Columns\n",
        "    viz_col1, viz_col2 = st.columns([2, 1])\n",
        "\n",
        "    topo_plot = viz_col1.empty()\n",
        "    log_area = viz_col2.empty()\n",
        "\n",
        "    stats_plot = st.empty()\n",
        "\n",
        "    # --- SIMULATION LOOP ---\n",
        "    if st.session_state.is_running:\n",
        "\n",
        "        # 1. EVALUATE\n",
        "        evolver = st.session_state.evolver\n",
        "        # Apply physics settings\n",
        "        evolver.physics.difficulty = difficulty\n",
        "        evolver.physics.noise = noise\n",
        "\n",
        "        scores = []\n",
        "        for arch in evolver.population:\n",
        "            loss = evolver.physics.evaluate(arch)\n",
        "            arch.loss = loss\n",
        "            # Inverse loss mapped to \"IQ\" for fun\n",
        "            arch.accuracy = 100 * (1 / (1 + loss))\n",
        "            scores.append(loss)\n",
        "\n",
        "        # 2. SELECT & REPRODUCE\n",
        "        evolver.population.sort(key=lambda x: x.loss)\n",
        "        elites = evolver.population[:int(pop_size * 0.2)] # Top 20%\n",
        "\n",
        "        # Record history\n",
        "        best_arch = elites[0]\n",
        "        st.session_state.history.append({\n",
        "            'generation': st.session_state.generation,\n",
        "            'loss': best_arch.loss,\n",
        "            'parameter_count': best_arch.parameter_count,\n",
        "            'inference_speed': best_arch.inference_speed,\n",
        "            'depth': len(best_arch.nodes),\n",
        "            'id': best_arch.id\n",
        "        })\n",
        "\n",
        "        # Create next gen\n",
        "        next_gen = [copy.deepcopy(e) for e in elites] # Elites survive\n",
        "\n",
        "        while len(next_gen) < pop_size:\n",
        "            parent = random.choice(elites)\n",
        "            child = evolver.mutate_architecture(parent, mutation_rate)\n",
        "\n",
        "            # Meta-Cognition: Child analyzes parent's mistakes\n",
        "            if meta_learning:\n",
        "                # Simulate \"Gradient Descent on Topology\"\n",
        "                # If parent had high compute cost, child prioritizes efficient modules\n",
        "                if parent.inference_speed < 100:\n",
        "                    child.curiosity += 0.1 # Try weirder things\n",
        "                    # Force prune heavy nodes\n",
        "                    heavy_nodes = [n for n in child.nodes.values() if n.properties['compute_cost'] > 1.0]\n",
        "                    if heavy_nodes and random.random() < 0.5:\n",
        "                        victim = random.choice(heavy_nodes)\n",
        "                        child.mutations_log.append(f\"Meta-Correction: Optimization of {victim.id}\")\n",
        "                        # Replaced with lighter variant (simulated)\n",
        "                        victim.properties['compute_cost'] *= 0.8\n",
        "\n",
        "            next_gen.append(child)\n",
        "\n",
        "        evolver.population = next_gen\n",
        "        st.session_state.generation += 1\n",
        "\n",
        "        # --- UPDATE UI ---\n",
        "        best_loss_ph.metric(\"Lowest Loss\", f\"{best_arch.loss:.4f}\", f\"{-0.01:.4f}\")\n",
        "        avg_iq_ph.metric(\"System IQ\", f\"{best_arch.accuracy:.1f}\", \"+1.2\")\n",
        "        arch_depth_ph.metric(\"Network Depth\", f\"{len(best_arch.nodes)} Layers\", \"+1\")\n",
        "        gen_ph.metric(\"Generation\", f\"{st.session_state.generation}\")\n",
        "\n",
        "        # 3D Topology Plot of the BEST Architecture\n",
        "        with topo_plot:\n",
        "            fig_3d = plot_neural_topology_3d(best_arch)\n",
        "            st.plotly_chart(fig_3d, use_container_width=True, key=f\"topo_{st.session_state.generation}\")\n",
        "\n",
        "        # Log Stream\n",
        "        with log_area.container():\n",
        "            st.markdown(\"#### üìú System Logs\")\n",
        "            for log in best_arch.mutations_log[-5:]:\n",
        "                st.code(f\"> [GEN {st.session_state.generation}] {log}\")\n",
        "\n",
        "            st.markdown(\"#### üß† Top Components\")\n",
        "            types = [n.type_name for n in best_arch.nodes.values()]\n",
        "            top_types = Counter(types).most_common(3)\n",
        "            for t, c in top_types:\n",
        "                st.caption(f\"{t}: {c} instances\")\n",
        "\n",
        "        # Stats Plot\n",
        "        if len(st.session_state.history) > 1:\n",
        "            hist_df = pd.DataFrame(st.session_state.history)\n",
        "\n",
        "            fig_stats = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "            fig_stats.add_trace(go.Scatter(x=hist_df['generation'], y=hist_df['loss'], name=\"Loss\", line=dict(color='#00FF00')), secondary_y=False)\n",
        "            fig_stats.add_trace(go.Scatter(x=hist_df['generation'], y=hist_df['parameter_count'], name=\"Params\", line=dict(color='#FF00FF')), secondary_y=True)\n",
        "\n",
        "            fig_stats.update_layout(\n",
        "                title=\"System Performance vs Complexity\",\n",
        "                plot_bgcolor='rgba(0,0,0,0)',\n",
        "                paper_bgcolor='rgba(0,0,0,0)',\n",
        "                font=dict(color='white')\n",
        "            )\n",
        "            stats_plot.plotly_chart(fig_stats, use_container_width=True)\n",
        "\n",
        "        time.sleep(0.1 if sim_speed > 50 else 1.0/sim_speed)\n",
        "        st.rerun()\n",
        "\n",
        "    # --- IF PAUSED, SHOW DEEP ANALYSIS ---\n",
        "    else:\n",
        "        st.info(\"Simulation Paused. Detailed Analysis Mode Active.\")\n",
        "\n",
        "        if st.session_state.history:\n",
        "            tabs = st.tabs([\"üî¨ Deep Inspection\", \"üèîÔ∏è Loss Landscape\", \"üß¨ Gene Pool\"])\n",
        "\n",
        "            with tabs[0]:\n",
        "                best_now = st.session_state.evolver.population[0]\n",
        "                st.subheader(f\"Architecture ID: {best_now.id}\")\n",
        "\n",
        "                c1, c2 = st.columns(2)\n",
        "                with c1:\n",
        "                    # Sunburst of components\n",
        "                    # Build hierarchy for sunburst\n",
        "                    flat_data = []\n",
        "                    for nid, node in best_now.nodes.items():\n",
        "                        flat_data.append({'id': nid, 'parent': 'Model', 'value': node.properties['complexity'], 'color': node.properties['color']})\n",
        "                    flat_data.append({'id': 'Model', 'parent': '', 'value': 0, 'color': '#FFFFFF'})\n",
        "\n",
        "                    sb_df = pd.DataFrame(flat_data)\n",
        "                    fig_sb = go.Figure(go.Sunburst(\n",
        "                        labels=sb_df['id'],\n",
        "                        parents=sb_df['parent'],\n",
        "                        values=sb_df['value'],\n",
        "                        marker=dict(colors=sb_df['color'])\n",
        "                    ))\n",
        "                    fig_sb.update_layout(title=\"Component Hierarchy\", margin=dict(t=0, l=0, r=0, b=0))\n",
        "                    st.plotly_chart(fig_sb, use_container_width=True)\n",
        "\n",
        "                with c2:\n",
        "                    st.json(asdict(best_now))\n",
        "\n",
        "            with tabs[1]:\n",
        "                fig_land = plot_loss_landscape_surface(st.session_state.history)\n",
        "                st.plotly_chart(fig_land, use_container_width=True)\n",
        "\n",
        "            with tabs[2]:\n",
        "                # Population distribution\n",
        "                pop_params = [a.parameter_count for a in st.session_state.evolver.population]\n",
        "                pop_loss = [a.loss for a in st.session_state.evolver.population]\n",
        "\n",
        "                fig_dist = px.scatter(x=pop_params, y=pop_loss, color=pop_loss,\n",
        "                                      labels={'x': 'Parameters', 'y': 'Loss'},\n",
        "                                      title=\"Population Distribution (Fitness vs Size)\",\n",
        "                                      color_continuous_scale='Turbo_r')\n",
        "                st.plotly_chart(fig_dist, use_container_width=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "bXJ06NjZEkj3"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}