{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDBRxKonhkS3",
        "outputId": "c7a546f5-8980-4b9f-8644-901320b5b7cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU DETECTED: Titan-Neura 'Hybrid Apex' Active\n",
            "Neural HRF Activated...\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import warnings\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.fft import fft\n",
        "from scipy.special import expit, softmax\n",
        "\n",
        "# Sklearn Core & Metrics\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, PowerTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.svm import SVC, NuSVC\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_predict, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Gradient Boosting\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# GPU CHECK\n",
        "try:\n",
        "    import cupy as cp\n",
        "    GPU_AVAILABLE = True\n",
        "    print(\"‚úÖ GPU DETECTED: Titan-Neura 'Hybrid Apex' Active\")\n",
        "except ImportError:\n",
        "    GPU_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è GPU NOT FOUND: Running in Standard Mode\")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==================================================================================\n",
        "#   INVENTION 2: THE NEURAL APEX (The Deep Stacker)\n",
        "#   \"A Neural Brain that learns to conduct the 21-Dimensional Orchestra\"\n",
        "# ==================================================================================\n",
        "# ==================================================================================\n",
        "#   INVENTION 2: THE ADAPTIVE NEURAL APEX (Smart-Scaling Brain)\n",
        "#   \"If the universe is small, be simple. If the universe is vast, be deep.\"\n",
        "# ==================================================================================\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# ==================================================================================\n",
        "#   INVENTION 2: THE GAMMA-RAY APEX (Newtonian Neural Network)\n",
        "#   \"Do not approximate the truth. Calculate it.\"\n",
        "# ==================================================================================\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "class TheNeuralApex(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self):\n",
        "        # THE GAMMA RAY CONFIGURATION\n",
        "        self.brain = MLPClassifier(\n",
        "            # Structure: Wide base to capture all 12 opinions, sharp funnel to decision.\n",
        "            hidden_layer_sizes=(100, 50),\n",
        "\n",
        "            # Activation: ReLU is sharp. It cuts space like a knife.\n",
        "            activation='relu',\n",
        "\n",
        "            # SOLVER: 'lbfgs' is the Gamma Ray.\n",
        "            # It uses 2nd-order calculus (Hessian Matrix) to find the EXACT solution.\n",
        "            # It crushes XGBoost on small-to-medium clean data.\n",
        "            solver='lbfgs',\n",
        "\n",
        "            # Regularization: 1e-5. We have NO mercy for noise. We want pure signal.\n",
        "            alpha=1e-5,\n",
        "\n",
        "            # Patience: Infinite. It will run until it hits the mathematical limit.\n",
        "            max_iter=5000,\n",
        "\n",
        "            # Tolerance: We demand 8 decimal places of precision.\n",
        "            tol=1e-8,\n",
        "\n",
        "            random_state=42\n",
        "        )\n",
        "        self.classes_ = None\n",
        "\n",
        "    def fit(self, X_meta, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        # L-BFGS expects clean data, X_meta is probabilities so it's perfect.\n",
        "        self.brain.fit(X_meta, y)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X_meta):\n",
        "        return self.brain.predict_proba(X_meta)\n",
        "\n",
        "    def predict(self, X_meta):\n",
        "        return self.brain.predict(X_meta)\n",
        "\n",
        "\n",
        "# ==================================================================================\n",
        "#   INVENTION 1 COMPONENTS (HRF 21D)\n",
        "# ==================================================================================\n",
        "\n",
        "# --- 1. THE HOLOGRAPHIC SOUL (Unit 3 - Multiverse Edition) ---\n",
        "class HolographicSoulUnit(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, k=15):\n",
        "        self.k = k\n",
        "        self.dna_ = {\"freq\": 2.0, \"gamma\": 0.5, \"power\": 2.0, \"metric\": \"minkowski\", \"p\": 2.0, \"phase\": 0.0, \"dim_reduction\": \"none\"}\n",
        "        self.projector_ = None\n",
        "        self.X_raw_source_ = None\n",
        "        self._X_train_gpu = None\n",
        "        self._y_train_gpu = None\n",
        "        self._X_train_sq_norm = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        self._apply_projection(X)\n",
        "        self.y_train_ = y\n",
        "        if GPU_AVAILABLE:\n",
        "            self._X_train_gpu = cp.asarray(self.X_train_, dtype=cp.float32)\n",
        "            self._y_train_gpu = cp.asarray(self.y_train_)\n",
        "            self._X_train_sq_norm = cp.sum(self._X_train_gpu ** 2, axis=1)\n",
        "        return self\n",
        "\n",
        "    def _apply_projection(self, X):\n",
        "        if self.dna_[\"dim_reduction\"] == \"holo\":\n",
        "            n_components = max(2, int(np.sqrt(X.shape[1])))\n",
        "            self.projector_ = GaussianRandomProjection(n_components=n_components, random_state=42)\n",
        "            self.X_train_ = self.projector_.fit_transform(X)\n",
        "        else:\n",
        "            self.projector_ = None\n",
        "            self.X_train_ = X\n",
        "\n",
        "    def set_raw_source(self, X):\n",
        "        self.X_raw_source_ = X\n",
        "\n",
        "    def evolve(self, X_val, y_val, generations=10):\n",
        "        if not GPU_AVAILABLE: return 0.0\n",
        "        X_val_curr = self.projector_.transform(X_val) if self.projector_ else X_val\n",
        "        X_val_g = cp.asarray(X_val_curr, dtype=cp.float32)\n",
        "        y_val_g = cp.asarray(y_val)\n",
        "        val_sq_norm = cp.sum(X_val_g ** 2, axis=1)\n",
        "\n",
        "        best_dna = self.dna_.copy()\n",
        "        best_acc = self._score_on_gpu(X_val_g, y_val_g, val_sq_norm)\n",
        "\n",
        "        for gen in range(generations):\n",
        "            mutant = best_dna.copy()\n",
        "            trait = random.choice(list(mutant.keys()))\n",
        "            if trait == \"freq\": mutant[\"freq\"] *= np.random.uniform(0.8, 1.25)\n",
        "            elif trait == \"gamma\": mutant[\"gamma\"] = np.random.uniform(0.1, 5.0)\n",
        "            elif trait == \"power\": mutant[\"power\"] = random.choice([0.5, 1.0, 2.0, 3.0, 4.0])\n",
        "            self.dna_ = mutant\n",
        "            acc = self._score_on_gpu(X_val_g, y_val_g, val_sq_norm)\n",
        "            if acc > best_acc:\n",
        "                best_acc = acc\n",
        "                best_dna = mutant\n",
        "            self.dna_ = best_dna\n",
        "\n",
        "        self.dna_ = best_dna\n",
        "        return best_acc\n",
        "\n",
        "    def _score_on_gpu(self, X_val_g, y_val_g, val_sq_norm=None):\n",
        "        probs = self._predict_proba_gpu_internal(X_val_g, val_sq_norm)\n",
        "        preds = cp.argmax(probs, axis=1)\n",
        "        return float(cp.mean(preds == y_val_g))\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X_curr = self.projector_.transform(X) if self.projector_ else X\n",
        "        if GPU_AVAILABLE:\n",
        "            X_g = cp.asarray(X_curr, dtype=cp.float32)\n",
        "            x_sq_norm = cp.sum(X_g ** 2, axis=1)\n",
        "            probs = self._predict_proba_gpu_internal(X_g, x_sq_norm)\n",
        "            return cp.asnumpy(probs)\n",
        "        else:\n",
        "            return np.ones((len(X), len(self.classes_))) / len(self.classes_)\n",
        "\n",
        "    def _predict_proba_gpu_internal(self, X_te_g, X_te_sq_norm=None):\n",
        "        n_test = len(X_te_g)\n",
        "        batch_size = 2048\n",
        "        p_norm = self.dna_.get(\"p\", 2.0)\n",
        "        gamma, freq, power, phase = self.dna_[\"gamma\"], self.dna_[\"freq\"], self.dna_[\"power\"], self.dna_[\"phase\"]\n",
        "\n",
        "        probas = []\n",
        "        for i in range(0, n_test, batch_size):\n",
        "            end = min(i + batch_size, n_test)\n",
        "            batch_te = X_te_g[i:end]\n",
        "\n",
        "            # Fast Euclidean\n",
        "            batch_sq = X_te_sq_norm[i:end][:, None] if X_te_sq_norm is not None else cp.sum(batch_te**2, axis=1, keepdims=True)\n",
        "            train_sq = self._X_train_sq_norm[None, :]\n",
        "            dot_prod = cp.dot(batch_te, self._X_train_gpu.T)\n",
        "            dists = cp.sqrt(cp.maximum(batch_sq + train_sq - 2 * dot_prod, 0.0))\n",
        "\n",
        "            # Resonance\n",
        "            top_k_idx = cp.argsort(dists, axis=1)[:, : self.k]\n",
        "            row_idx = cp.arange(len(batch_te))[:, None]\n",
        "            top_dists = dists[row_idx, top_k_idx]\n",
        "            top_y = self._y_train_gpu[top_k_idx]\n",
        "\n",
        "            w = cp.exp(-gamma * (top_dists**2)) * cp.maximum(1.0 + cp.cos(freq * top_dists + phase), 0.0)\n",
        "            w = cp.power(w, power)\n",
        "\n",
        "            batch_probs = cp.zeros((len(batch_te), len(self.classes_)))\n",
        "            for c_idx, cls in enumerate(self.classes_):\n",
        "                batch_probs[:, c_idx] = cp.sum(w * (top_y == cls), axis=1)\n",
        "\n",
        "            total = cp.sum(batch_probs, axis=1, keepdims=True)\n",
        "            total[total==0] = 1.0\n",
        "            probas.append(batch_probs / total)\n",
        "\n",
        "        return cp.concatenate(probas)\n",
        "\n",
        "    def predict(self, X): return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
        "\n",
        "\n",
        "# --- 18. THE GOLDEN SPIRAL (Unit 18 - Nature's Code) ---\n",
        "class GoldenSpiralUnit(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, k=21, n_estimators=50):\n",
        "        self.k = k\n",
        "        self.n_estimators = n_estimators\n",
        "        self.classes_ = None\n",
        "        self.X_train_ = None\n",
        "        self.y_train_ = None\n",
        "        self.dna_ = {\"resonance\": 1.618, \"decay\": 1.618, \"shift\": 137.5}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        if GPU_AVAILABLE:\n",
        "            self.X_train_ = cp.asarray(X, dtype=cp.float32)\n",
        "            self.y_train_ = cp.asarray(y)\n",
        "        else:\n",
        "            self.X_train_ = np.array(X, dtype=np.float32)\n",
        "            self.y_train_ = np.array(y)\n",
        "        return self\n",
        "\n",
        "    def evolve(self, X, y, generations=5): return 0.0 # Placeholder\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if not GPU_AVAILABLE: return np.ones((len(X), len(self.classes_))) / len(self.classes_)\n",
        "        X_g = cp.asarray(X, dtype=cp.float32)\n",
        "        n_test = len(X_g)\n",
        "\n",
        "        # Distance\n",
        "        X2 = cp.sum(X_g**2, axis=1, keepdims=True)\n",
        "        Y2 = cp.sum(self.X_train_**2, axis=1)\n",
        "        XY = cp.dot(X_g, self.X_train_.T)\n",
        "        dists = cp.sqrt(cp.maximum(X2 + Y2 - 2*XY, 0.0))\n",
        "\n",
        "        top_k_idx = cp.argsort(dists, axis=1)[:, :self.k]\n",
        "        top_dists = dists[cp.arange(n_test)[:, None], top_k_idx]\n",
        "        top_y = self.y_train_[top_k_idx]\n",
        "\n",
        "        total_probs = cp.zeros((n_test, len(self.classes_)), dtype=cp.float32)\n",
        "        rng = cp.random.RandomState(42)\n",
        "        decay_vars = rng.uniform(0.5, 3.0, self.n_estimators)\n",
        "        shift_vars = rng.uniform(0.0, 360.0, self.n_estimators)\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            w = (1.0 / (cp.power(top_dists, decay_vars[i]) + 1e-9)) * \\\n",
        "                cp.maximum(1.0 + 0.5 * cp.cos(cp.log(top_dists + 1e-9) * 1.618 + np.deg2rad(shift_vars[i])), 0.0)\n",
        "\n",
        "            tree_p = cp.zeros((n_test, len(self.classes_)), dtype=cp.float32)\n",
        "            for c_idx, cls in enumerate(self.classes_):\n",
        "                tree_p[:, c_idx] = cp.sum(w * (top_y == cls), axis=1)\n",
        "\n",
        "            t_sum = cp.sum(tree_p, axis=1, keepdims=True)\n",
        "            total_probs += tree_p / (t_sum + 1e-9)\n",
        "\n",
        "        return cp.asnumpy(total_probs / self.n_estimators)\n",
        "\n",
        "    def predict(self, X): return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
        "\n",
        "\n",
        "# --- 19. THE ENTROPY FOREST (Unit 19 - Thermodynamics) ---\n",
        "class EntropyMaxwellUnit(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, n_estimators=50):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.forest_stats_ = []\n",
        "        self.classes_ = None\n",
        "        self.dna_ = {\"n_components\": 100}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        if not GPU_AVAILABLE: return self\n",
        "        X_g = cp.asarray(X, dtype=cp.float32)\n",
        "        y_g = cp.asarray(y)\n",
        "        n_samples = len(X)\n",
        "        rng = cp.random.RandomState(42)\n",
        "\n",
        "        self.forest_stats_ = []\n",
        "        for _ in range(self.n_estimators):\n",
        "            idx = rng.choice(n_samples, n_samples, replace=True)\n",
        "            X_b, y_b = X_g[idx], y_g[idx]\n",
        "            stats = {}\n",
        "            for cls in self.classes_:\n",
        "                X_c = X_b[y_b == cls]\n",
        "                if len(X_c) < 2: X_c = X_g[y_g == cls]\n",
        "                stats[cls] = (cp.mean(X_c, axis=0), cp.var(X_c, axis=0) + 1e-5, len(X_c)/n_samples)\n",
        "            self.forest_stats_.append(stats)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if not GPU_AVAILABLE: return np.zeros((len(X), len(self.classes_)))\n",
        "        X_g = cp.asarray(X, dtype=cp.float32)\n",
        "        total_probs = cp.zeros((len(X), len(self.classes_)), dtype=cp.float32)\n",
        "\n",
        "        for stats in self.forest_stats_:\n",
        "            univ_probs = cp.zeros((len(X), len(self.classes_)), dtype=cp.float32)\n",
        "            for i, cls in enumerate(self.classes_):\n",
        "                mu, sigma, prior = stats[cls]\n",
        "                log_p = -0.5 * cp.sum(cp.log(2*np.pi*sigma), axis=0) - 0.5 * cp.sum((X_g - mu)**2 / sigma, axis=1)\n",
        "                univ_probs[:, i] = log_p + cp.log(prior)\n",
        "\n",
        "            max_p = cp.max(univ_probs, axis=1, keepdims=True)\n",
        "            exp_p = cp.exp(univ_probs - max_p)\n",
        "            total_probs += exp_p / cp.sum(exp_p, axis=1, keepdims=True)\n",
        "\n",
        "        return cp.asnumpy(total_probs / self.n_estimators)\n",
        "\n",
        "    def predict(self, X): return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
        "\n",
        "\n",
        "# --- 20. THE QUANTUM FOREST (Unit 20 - Parallel Ridge) ---\n",
        "class QuantumFluxUnit(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, n_estimators=20, gamma=1.5):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.gamma = gamma\n",
        "        self.forest_ = []\n",
        "        self.classes_ = None\n",
        "        self.dna_ = {\"gamma\": gamma, \"n_components\": 200}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        if not GPU_AVAILABLE: return self\n",
        "        X_g = cp.asarray(X, dtype=cp.float32)\n",
        "        y_onehot = cp.zeros((len(y), len(self.classes_)), dtype=cp.float32)\n",
        "        y_raw = cp.asarray(y)\n",
        "        for i, c in enumerate(self.classes_): y_onehot[y_raw == c, i] = 1.0\n",
        "\n",
        "        rng = cp.random.RandomState(42)\n",
        "        self.forest_ = []\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            g_var = self.gamma * rng.uniform(0.8, 1.2)\n",
        "            n_comp = self.dna_[\"n_components\"]\n",
        "            W = rng.normal(0, np.sqrt(2*g_var), (X.shape[1], n_comp)).astype(cp.float32)\n",
        "            B = rng.uniform(0, 2*np.pi, n_comp).astype(cp.float32)\n",
        "            Z = cp.cos(cp.dot(X_g, W) + B) * cp.sqrt(2./n_comp)\n",
        "\n",
        "            try:\n",
        "                weights = cp.linalg.solve(cp.dot(Z.T, Z) + cp.eye(n_comp), cp.dot(Z.T, y_onehot))\n",
        "                self.forest_.append((W, B, weights))\n",
        "            except: pass\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if not GPU_AVAILABLE: return np.zeros((len(X), len(self.classes_)))\n",
        "        X_g = cp.asarray(X, dtype=cp.float32)\n",
        "        total_probs = cp.zeros((len(X), len(self.classes_)), dtype=cp.float32)\n",
        "        valid = 0\n",
        "\n",
        "        for W, B, weights in self.forest_:\n",
        "            Z = cp.cos(cp.dot(X_g, W) + B) * cp.sqrt(2./len(B))\n",
        "            raw = cp.dot(Z, weights)\n",
        "            max_r = cp.max(raw, axis=1, keepdims=True)\n",
        "            exp_r = cp.exp(raw - max_r)\n",
        "            total_probs += exp_r / cp.sum(exp_r, axis=1, keepdims=True)\n",
        "            valid += 1\n",
        "\n",
        "        return cp.asnumpy(total_probs / max(1, valid))\n",
        "\n",
        "    def predict(self, X): return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
        "\n",
        "\n",
        "# --- 21. THE GRAVITY FOREST (Unit 21 - Newtonian) ---\n",
        "class EventHorizonUnit(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, n_estimators=50):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.centroids_ = None\n",
        "        self.masses_ = None\n",
        "        self.classes_ = None\n",
        "        self.dna_ = {\"horizon_pct\": 10.0, \"decay_power\": 2.0}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        if not GPU_AVAILABLE: return self\n",
        "        X_g = cp.asarray(X, dtype=cp.float32)\n",
        "        y_g = cp.asarray(y)\n",
        "        self.centroids_ = []\n",
        "        self.masses_ = []\n",
        "\n",
        "        for cls in self.classes_:\n",
        "            X_c = X_g[y_g == cls]\n",
        "            if len(X_c) > 0:\n",
        "                self.centroids_.append(cp.mean(X_c, axis=0))\n",
        "                self.masses_.append(cp.log1p(len(X_c)))\n",
        "            else:\n",
        "                self.centroids_.append(cp.zeros(X.shape[1]))\n",
        "                self.masses_.append(0.0)\n",
        "\n",
        "        self.centroids_ = cp.array(self.centroids_)\n",
        "        self.masses_ = cp.array(self.masses_)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if not GPU_AVAILABLE: return np.zeros((len(X), len(self.classes_)))\n",
        "        X_g = cp.asarray(X, dtype=cp.float32)\n",
        "\n",
        "        X2 = cp.sum(X_g**2, axis=1, keepdims=True)\n",
        "        C2 = cp.sum(self.centroids_**2, axis=1)\n",
        "        XC = cp.dot(X_g, self.centroids_.T)\n",
        "        dist_sq = cp.maximum(X2 + C2 - 2*XC, 1e-9)\n",
        "\n",
        "        total_probs = cp.zeros((len(X), len(self.classes_)), dtype=cp.float32)\n",
        "        rng = cp.random.RandomState(42)\n",
        "        decay_vars = rng.uniform(self.dna_[\"decay_power\"] * 0.25, self.dna_[\"decay_power\"] * 1.25, self.n_estimators)\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            log_force = cp.log(self.masses_) - (decay_vars[i] * 0.5 * cp.log(dist_sq))\n",
        "            max_f = cp.max(log_force, axis=1, keepdims=True)\n",
        "            exp_f = cp.exp(log_force - max_f)\n",
        "            total_probs += exp_f / cp.sum(exp_f, axis=1, keepdims=True)\n",
        "\n",
        "        return cp.asnumpy(total_probs / self.n_estimators)\n",
        "\n",
        "    def predict(self, X): return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
        "\n",
        "\n",
        "# --- 25. THE NEURAL MANIFOLD (Unit 25 - Raw ELM) ---\n",
        "class NeuralManifoldUnit(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, n_hidden=100, activation=\"tanh\", alpha=0.5):\n",
        "        self.n_hidden, self.activation, self.alpha = n_hidden, activation, alpha\n",
        "        self.input_weights_, self.output_weights_ = None, None\n",
        "        self.classes_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        if not GPU_AVAILABLE: return self\n",
        "        X_g = cp.asarray(X, dtype=cp.float32)\n",
        "        y_enc = cp.zeros((len(y), len(self.classes_)))\n",
        "        y_g = cp.asarray(y)\n",
        "        for i, c in enumerate(self.classes_): y_enc[y_g == c, i] = 1\n",
        "\n",
        "        rng = cp.random.RandomState(42)\n",
        "        self.input_weights_ = rng.normal(size=(X.shape[1], self.n_hidden), dtype=cp.float32)\n",
        "        H = cp.tanh(cp.dot(X_g, self.input_weights_))\n",
        "\n",
        "        # Ridge ELM\n",
        "        H_inv = cp.linalg.pinv(cp.dot(H.T, H) + self.alpha * cp.eye(self.n_hidden))\n",
        "        self.output_weights_ = cp.dot(cp.dot(H_inv, H.T), y_enc)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if not GPU_AVAILABLE: return np.ones((len(X), len(self.classes_))) / len(self.classes_)\n",
        "        X_g = cp.asarray(X, dtype=cp.float32)\n",
        "        H = cp.tanh(cp.dot(X_g, self.input_weights_))\n",
        "        raw = cp.dot(H, self.output_weights_)\n",
        "        exp_out = cp.exp(raw - cp.max(raw, axis=1, keepdims=True))\n",
        "        return cp.asnumpy(exp_out / cp.sum(exp_out, axis=1, keepdims=True))\n",
        "\n",
        "    def predict(self, X): return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
        "\n",
        "# ==================================================================================\n",
        "#   THE TITAN-26: FULL ARSENAL (The \"Unbeatable\" Config)\n",
        "# ==================================================================================\n",
        "class HarmonicResonanceClassifier_TitanNeura(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, verbose=True):\n",
        "        self.verbose = verbose\n",
        "        self.scaler_ = RobustScaler(quantile_range=(15.0, 85.0))\n",
        "        self.classes_ = None\n",
        "\n",
        "        # --- INVENTION 2: THE APEX BRAIN (Regulated Gamma Ray) ---\n",
        "        # We increase alpha to 1.0 to force it to generalize, not memorize.\n",
        "        self.apex_brain_ = MLPClassifier(\n",
        "            hidden_layer_sizes=(64,), activation='relu', solver='lbfgs',\n",
        "            alpha=1.0, max_iter=2000, random_state=42\n",
        "        )\n",
        "\n",
        "        # --- INVENTION 1: THE 26 ORGANS (FULL ROSTER) ---\n",
        "\n",
        "        # [LOGIC SECTOR - 5 Units]\n",
        "        self.u01 = ExtraTreesClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
        "        self.u02 = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
        "        self.u03 = HistGradientBoostingClassifier(max_iter=200, random_state=42)\n",
        "        self.u04 = XGBClassifier(n_estimators=500, learning_rate=0.05, n_jobs=-1, random_state=42)\n",
        "        self.u05 = XGBClassifier(n_estimators=300, max_depth=3, n_jobs=-1, random_state=42) # Shallow XGB\n",
        "\n",
        "        # [MANIFOLD SECTOR - 6 Units]\n",
        "        self.u06 = NuSVC(nu=0.1, probability=True, random_state=42)\n",
        "        self.u07 = SVC(kernel=\"poly\", degree=2, probability=True, random_state=42)\n",
        "        self.u08 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", n_jobs=-1)\n",
        "        self.u09 = KNeighborsClassifier(n_neighbors=9, weights=\"distance\", metric=\"manhattan\", n_jobs=-1)\n",
        "        self.u10 = QuadraticDiscriminantAnalysis(reg_param=0.5)\n",
        "        self.u11 = SVC(kernel=\"rbf\", C=10.0, probability=True, random_state=42)\n",
        "\n",
        "        # [ELITE SOUL SECTOR - 6 Units]\n",
        "        # Using your Discovery DNA\n",
        "        self.u12 = HolographicSoulUnit(k=15) # Obsidian\n",
        "        self.u12.dna_ = {\"freq\": 49.0, \"gamma\": 15.5, \"p\": 3.1, \"power\": 2.0}\n",
        "        self.u13 = HolographicSoulUnit(k=15) # Thunder\n",
        "        self.u13.dna_ = {\"freq\": 82.5, \"gamma\": 20.0, \"p\": 2.7, \"power\": 2.0}\n",
        "        self.u14 = HolographicSoulUnit(k=15) # Ghost\n",
        "        self.u14.dna_ = {\"freq\": 10.0, \"gamma\": 50.0, \"p\": 2.0, \"power\": 3.0}\n",
        "        self.u15 = HolographicSoulUnit(k=25) # Delta\n",
        "        self.u15.dna_ = {\"freq\": 50.0, \"gamma\": 10.0, \"p\": 2.5, \"power\": 2.0}\n",
        "        self.u16 = HolographicSoulUnit(k=25) # Singular\n",
        "        self.u16.dna_ = {\"freq\": 92.0, \"gamma\": 35.0, \"p\": 3.2, \"power\": 4.0}\n",
        "        self.u17 = HolographicSoulUnit(k=15) # Twin-F\n",
        "        self.u17.dna_ = {\"freq\": 2.0, \"gamma\": 0.5, \"p\": 2.0, \"power\": 2.0} # Baseline\n",
        "\n",
        "        # [COSMIC SECTOR - 4 Units]\n",
        "        self.u18 = GoldenSpiralUnit(k=21)\n",
        "        self.u19 = EntropyMaxwellUnit(n_estimators=30)\n",
        "        self.u20 = QuantumFluxUnit(n_estimators=20)\n",
        "        self.u21 = EventHorizonUnit(n_estimators=30)\n",
        "\n",
        "        # [COMPETITOR BENCHMARKS - 3 Units] (The Spies)\n",
        "        self.u22 = SVC(probability=True, random_state=42) # Vanilla SVM\n",
        "        self.u23 = RandomForestClassifier(n_estimators=100, random_state=42) # Vanilla RF\n",
        "        self.u24 = XGBClassifier(n_estimators=100, random_state=42) # Vanilla XGB\n",
        "\n",
        "        # [NEURAL SECTOR - 2 Units]\n",
        "        self.u25 = NeuralManifoldUnit(n_hidden=300)\n",
        "        self.u26 = NeuralManifoldUnit(n_hidden=100, activation=\"sine\") # Exotic Neural\n",
        "\n",
        "        self.active_elites_ = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X, y = check_X_y(X, y)\n",
        "        self.classes_ = np.unique(y)\n",
        "\n",
        "        if self.verbose:\n",
        "             print(\" -----------------------------------------------------------\")\n",
        "             print(\"  ‚ö†Ô∏è TITAN-26 PROTOCOL INITIATED (Full Arsenal)\")\n",
        "             print(\" -----------------------------------------------------------\")\n",
        "\n",
        "        X_scaled = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # 1. DEFINE ALL 26 CANDIDATES\n",
        "        all_units = [\n",
        "            self.u01, self.u02, self.u03, self.u04, self.u05,\n",
        "            self.u06, self.u07, self.u08, self.u09, self.u10, self.u11,\n",
        "            self.u12, self.u13, self.u14, self.u15, self.u16, self.u17,\n",
        "            self.u18, self.u19, self.u20, self.u21,\n",
        "            self.u22, self.u23, self.u24,\n",
        "            self.u25, self.u26\n",
        "        ]\n",
        "\n",
        "        # 2. RAPID SELECTION\n",
        "        if self.verbose: print(\" > Phase 2: Organ Evolution (Training 26 Units)...\")\n",
        "        # Use stratified split to ensure classes are balanced\n",
        "        X_tr, X_val, y_tr, y_val = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "        unit_scores = []\n",
        "        for i, unit in enumerate(all_units):\n",
        "            try:\n",
        "                if hasattr(unit, \"set_raw_source\"): unit.set_raw_source(X_tr)\n",
        "                unit.fit(X_tr, y_tr)\n",
        "\n",
        "                # Evolve only if strictly necessary\n",
        "                if hasattr(unit, \"evolve\") and not isinstance(unit, HolographicSoulUnit):\n",
        "                     unit.evolve(X_val, y_val, generations=2)\n",
        "\n",
        "                score = unit.score(X_val, y_val)\n",
        "                unit_scores.append((score, unit))\n",
        "\n",
        "                name = unit.__class__.__name__[:15]\n",
        "                if isinstance(unit, HolographicSoulUnit): name = f\"Soul-{i-11:02d}\"\n",
        "\n",
        "                if self.verbose: print(f\"    Unit-{i+1:02d} [{name}...]: {score:.2%}\")\n",
        "            except Exception as e:\n",
        "                unit_scores.append((0.0, unit))\n",
        "\n",
        "        # 3. SELECT THE \"COUNCIL OF 12\"\n",
        "        unit_scores.sort(key=lambda x: x[0], reverse=True)\n",
        "        self.active_elites_ = [u for s, u in unit_scores[:12]]\n",
        "        self.top_score_ = unit_scores[0][0]\n",
        "        if self.verbose: print(f\" > Phase 3: The Council of 12 Selected. Best Score: {self.top_score_:.2%}\")\n",
        "\n",
        "        # 4. GENERATE META-DATA FOR THE NEURAL BRAIN\n",
        "        if self.verbose: print(\" > Phase 4: Training The Neural Apex (Deep Stacking)...\")\n",
        "\n",
        "        meta_features_list = []\n",
        "        for unit in self.active_elites_:\n",
        "            try:\n",
        "                if hasattr(unit, \"predict_proba\"):\n",
        "                    preds = cross_val_predict(unit, X_scaled, y, cv=3, method=\"predict_proba\", n_jobs=-1)\n",
        "                else:\n",
        "                    d = cross_val_predict(unit, X_scaled, y, cv=3, method=\"decision_function\", n_jobs=-1)\n",
        "                    preds = softmax(d, axis=1)\n",
        "            except:\n",
        "                unit.fit(X_scaled, y)\n",
        "                preds = unit.predict_proba(X_scaled)\n",
        "\n",
        "            if preds.shape[1] == 1: preds = np.hstack([1-preds, preds])\n",
        "            meta_features_list.append(preds)\n",
        "            unit.fit(X_scaled, y)\n",
        "\n",
        "        X_meta = np.hstack(meta_features_list)\n",
        "\n",
        "        # 5. TRAIN THE APEX BRAIN\n",
        "        self.apex_brain_.fit(X_meta, y)\n",
        "        apex_acc = accuracy_score(y, self.apex_brain_.predict(X_meta))\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\" > NEURAL APEX TRAINING COMPLETE.\")\n",
        "            print(f\"   Internal Coherence: {apex_acc:.2%}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X_scaled = self.scaler_.transform(X)\n",
        "        meta_features_list = []\n",
        "        for unit in self.active_elites_:\n",
        "            if hasattr(unit, \"predict_proba\"):\n",
        "                p = unit.predict_proba(X_scaled)\n",
        "            else:\n",
        "                d = unit.decision_function(X_scaled)\n",
        "                p = softmax(d, axis=1)\n",
        "            meta_features_list.append(p)\n",
        "        X_meta = np.hstack(meta_features_list)\n",
        "\n",
        "        # --- THE SAFETY VALVE ---\n",
        "        # 1. Neural Opinion (Smart but risky)\n",
        "        p_brain = self.apex_brain_.predict_proba(X_meta)\n",
        "\n",
        "        # 2. Top Elite Opinion (Conservative and safe)\n",
        "        p_elite = meta_features_list[0]\n",
        "\n",
        "        # 3. BLEND: 80% Brain + 20% Safety Floor\n",
        "        # This prevents the brain from making \"stupid\" mistakes on edge cases.\n",
        "        return (0.8 * p_brain) + (0.2 * p_elite)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
        "\n",
        "# ==================================================================================\n",
        "#   MAIN EXECUTION BLOCK\n",
        "# ==================================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Simulate EEG Data (1000 samples, 14 channels)\n",
        "    print(\"Neural HRF Activated...\")\n",
        "    '''\n",
        "    X_test = np.random.randn(1000, 14).astype(np.float32)\n",
        "    # Synthetic classes (0 or 1) based on some non-linear logic\n",
        "    y_test = (np.sin(X_test[:, 0]) + np.cos(X_test[:, 1]) > 0).astype(int)\n",
        "\n",
        "    # Initialize The Hybrid Titan\n",
        "    model = HarmonicResonanceClassifier_TitanNeura(verbose=True)\n",
        "\n",
        "    # Train\n",
        "    start = time.time()\n",
        "    model.fit(X_test, y_test)\n",
        "    end = time.time()\n",
        "\n",
        "    # Evaluate\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"RESULTS: Titan-Neura (Invention 2)\")\n",
        "    print(f\"Time Taken: {end - start:.2f}s\")\n",
        "    print(f\"Final Accuracy on Training Set (Self-Check): {acc:.2%}\")\n",
        "    print(\"=\"*60)'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def run_comparative_benchmark(dataset_name, openml_id, sample_limit=None):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üöÄ INITIATING HYBRID BENCHMARK: {dataset_name} (OpenML ID: {openml_id})\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # 1. Load Data from Official OpenML\n",
        "    print(\" > üì• Downloading dataset from OpenML Cloud...\")\n",
        "    try:\n",
        "        data = fetch_openml(data_id=openml_id, as_frame=True, parser='auto')\n",
        "        X = data.data\n",
        "        y = data.target\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error fetching data: {e}\")\n",
        "        return\n",
        "\n",
        "    # 2. Robust Preprocessing\n",
        "    # Convert Categorical Columns to Numeric Codes\n",
        "    if hasattr(X, \"select_dtypes\"):\n",
        "        cat_cols = X.select_dtypes(include=['category', 'object']).columns\n",
        "        if len(cat_cols) > 0:\n",
        "            print(f\" > Encoding {len(cat_cols)} categorical features...\")\n",
        "            for col in cat_cols:\n",
        "                X[col] = X[col].astype('category').cat.codes\n",
        "        X = X.values # Convert to simple Numpy array for the Engine\n",
        "\n",
        "    # Handle Missing Values (Simple Mean Imputation for speed)\n",
        "    if np.isnan(X).any():\n",
        "        print(\" > ‚ö†Ô∏è NaNs detected. Filling with 0.0 (Fast Impute).\")\n",
        "        X = np.nan_to_num(X)\n",
        "\n",
        "    # Encode Target Labels (Strings -> Integers)\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "    # 3. Stratified Sampling (If limit is set)\n",
        "    if sample_limit and len(X) > sample_limit:\n",
        "        print(f\" > ‚úÇÔ∏è Downsampling from {len(X)} to {sample_limit} (Stratified)...\")\n",
        "        _, X, _, y = train_test_split(\n",
        "            X, y, test_size=sample_limit, stratify=y, random_state=42\n",
        "        )\n",
        "\n",
        "    print(f\" > ‚úÖ Data Ready. Shape: {X.shape} | Classes: {len(np.unique(y))}\")\n",
        "\n",
        "    # 4. Train/Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "    # --- THE BATTLEFIELD ---\n",
        "    results = []\n",
        "\n",
        "    # A. The Old Guard (XGBoost)\n",
        "    print(\"\\n > ‚öîÔ∏è  Benchmarking: XGBoost (Standard)...\")\n",
        "    xgb = XGBClassifier(n_estimators=100, eval_metric='logloss', random_state=42)\n",
        "    t0 = time.time()\n",
        "    xgb.fit(X_train, y_train)\n",
        "    acc_xgb = accuracy_score(y_test, xgb.predict(X_test))\n",
        "    time_xgb = time.time() - t0\n",
        "    results.append((\"XGBoost (Baseline)\", acc_xgb, time_xgb))\n",
        "    print(f\"    -> Accuracy: {acc_xgb:.2%}\")\n",
        "\n",
        "    # B. The Old Guard (Random Forest)\n",
        "    print(\" > ‚öîÔ∏è  Benchmarking: Random Forest (Standard)...\")\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    t0 = time.time()\n",
        "    rf.fit(X_train, y_train)\n",
        "    acc_rf = accuracy_score(y_test, rf.predict(X_test))\n",
        "    time_rf = time.time() - t0\n",
        "    results.append((\"Random Forest\", acc_rf, time_rf))\n",
        "    print(f\"    -> Accuracy: {acc_rf:.2%}\")\n",
        "\n",
        "    # C. THE INVENTION (Titan-Neura)\n",
        "    print(\"\\n > üß† ACTIVATING INVENTION: Titan-Neura (Hybrid Apex)...\")\n",
        "    # We assume the class is already defined in the previous cell\n",
        "    titan = HarmonicResonanceClassifier_TitanNeura(verbose=True)\n",
        "    t0 = time.time()\n",
        "    titan.fit(X_train, y_train)\n",
        "    acc_titan = accuracy_score(y_test, titan.predict(X_test))\n",
        "    time_titan = time.time() - t0\n",
        "    results.append((\"Titan-Neura (Hybrid)\", acc_titan, time_titan))\n",
        "\n",
        "    # --- FINAL SCOREBOARD ---\n",
        "    print(\"\\n\" + \"=\"*75)\n",
        "    print(f\" üèÜ FINAL RESULTS: {dataset_name}\")\n",
        "    print(\"=\"*75)\n",
        "    print(f\" {'MODEL':<25} | {'ACCURACY':<10} | {'TIME':<8} | {'STATUS'}\")\n",
        "    print(\"-\" * 75)\n",
        "\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    winner_score = results[0][1]\n",
        "\n",
        "    for name, acc, t in results:\n",
        "        # Calculate gap to winner\n",
        "        gap = acc - winner_score\n",
        "        if acc == winner_score:\n",
        "            status = \"üëë WINNER\"\n",
        "        else:\n",
        "            status = f\"{gap:.2%}\"\n",
        "\n",
        "        print(f\" {name:<25} | {acc:.4%}   | {t:.1f}s     | {status}\")\n",
        "    print(\"=\"*75 + \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fJZS2tbKiee8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "hV7q3Xpkm0C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXECUTE THE COMMAND FOR EEG EYE STATE ---\n",
        "run_comparative_benchmark(\n",
        "    dataset_name=\"EEG Eye State\",\n",
        "    openml_id=1471,\n",
        "    sample_limit=14980  # Keeping the limit to ensure speed while maintaining statistical significance\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCrfCmUhjBO9",
        "outputId": "a6d9f468-1d43-4610-eb5f-38a4a5202665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üöÄ INITIATING HYBRID BENCHMARK: EEG Eye State (OpenML ID: 1471)\n",
            "======================================================================\n",
            " > üì• Downloading dataset from OpenML Cloud...\n",
            " > ‚úÖ Data Ready. Shape: (14980, 14) | Classes: 2\n",
            "\n",
            " > ‚öîÔ∏è  Benchmarking: XGBoost (Standard)...\n",
            "    -> Accuracy: 92.99%\n",
            " > ‚öîÔ∏è  Benchmarking: Random Forest (Standard)...\n",
            "    -> Accuracy: 93.09%\n",
            "\n",
            " > üß† ACTIVATING INVENTION: Titan-Neura (Hybrid Apex)...\n",
            " -----------------------------------------------------------\n",
            "  ‚ö†Ô∏è TITAN-NEURA PROTOCOL INITIATED (Elite Soul Edition)\n",
            " -----------------------------------------------------------\n",
            " > Phase 2: Organ Evolution (Training Elite Units)...\n",
            "    Unit-01 [ExtraTreesClass...]: 95.12%\n",
            "    Unit-02 [RandomForestCla...]: 93.16%\n",
            "    Unit-03 [HistGradientBoo...]: 92.41%\n",
            "    Unit-04 [XGBClassifier...]: 92.82%\n",
            "    Unit-05 [KNeighborsClass...]: 95.49%\n",
            "    Unit-06 [KNeighborsClass...]: 93.91%\n",
            "    Unit-07 [HoloSoul-ELITE...]: 96.25%\n",
            "    Unit-08 [HoloSoul-ELITE...]: 96.20%\n",
            "    Unit-09 [HoloSoul-ELITE...]: 95.33%\n",
            "    Unit-10 [HoloSoul-ELITE...]: 95.95%\n",
            "    Unit-11 [HoloSoul-ELITE...]: 95.95%\n",
            "    Unit-12 [GoldenSpiralUni...]: 94.58%\n",
            "    Unit-13 [EntropyMaxwellU...]: 46.02%\n",
            "    Unit-14 [EventHorizonUni...]: 44.10%\n",
            "    Unit-15 [NeuralManifoldU...]: 84.61%\n",
            " > Phase 3: The Council of 12 Selected. Best Score: 96.25%\n",
            " > Phase 4: Training The Neural Apex (Deep Stacking)...\n",
            "   > [NEURAL APEX] Dataset Size: 11984 | Mode: DEEP_CORTEX\n",
            " > NEURAL APEX TRAINING COMPLETE.\n",
            "   Internal Coherence (Training Acc): 96.44%\n",
            " > System Ready.\n",
            "\n",
            "===========================================================================\n",
            " üèÜ FINAL RESULTS: EEG Eye State\n",
            "===========================================================================\n",
            " MODEL                     | ACCURACY   | TIME     | STATUS\n",
            "---------------------------------------------------------------------------\n",
            " Titan-Neura (Hybrid)      | 97.2964%   | 99.6s     | üëë WINNER\n",
            " Random Forest             | 93.0908%   | 3.1s     | -4.21%\n",
            " XGBoost (Baseline)        | 92.9907%   | 0.5s     | -4.31%\n",
            "===========================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST 3: Wall-Following Robot Navigation\n",
        "# ID: 1497\n",
        "# Type: Sensor/Geometric (Ultrasound Waves)\n",
        "\n",
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Wall-Following Robot\",\n",
        "    openml_id=1497,\n",
        "    sample_limit=5456 #25\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytWhP1w_kMz-",
        "outputId": "56351b13-716d-47c9-d3fa-22f1ebaacb84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üöÄ INITIATING HYBRID BENCHMARK: Wall-Following Robot (OpenML ID: 1497)\n",
            "======================================================================\n",
            " > üì• Downloading dataset from OpenML Cloud...\n",
            " > ‚úÖ Data Ready. Shape: (5456, 24) | Classes: 4\n",
            "\n",
            " > ‚öîÔ∏è  Benchmarking: XGBoost (Standard)...\n",
            "    -> Accuracy: 99.91%\n",
            " > ‚öîÔ∏è  Benchmarking: Random Forest (Standard)...\n",
            "    -> Accuracy: 99.27%\n",
            "\n",
            " > üß† ACTIVATING INVENTION: Titan-Neura (Hybrid Apex)...\n",
            " -----------------------------------------------------------\n",
            "  ‚ö†Ô∏è TITAN-26 PROTOCOL INITIATED (Full Arsenal)\n",
            " -----------------------------------------------------------\n",
            " > Phase 2: Organ Evolution (Training 26 Units)...\n",
            "    Unit-01 [ExtraTreesClass...]: 96.79%\n",
            "    Unit-02 [RandomForestCla...]: 99.20%\n",
            "    Unit-03 [HistGradientBoo...]: 99.77%\n",
            "    Unit-04 [XGBClassifier...]: 99.66%\n",
            "    Unit-05 [XGBClassifier...]: 99.66%\n",
            "    Unit-06 [NuSVC...]: 92.33%\n",
            "    Unit-07 [SVC...]: 76.40%\n",
            "    Unit-08 [KNeighborsClass...]: 88.66%\n",
            "    Unit-09 [KNeighborsClass...]: 92.33%\n",
            "    Unit-10 [QuadraticDiscri...]: 63.46%\n",
            "    Unit-11 [SVC...]: 90.72%\n",
            "    Unit-18 [GoldenSpiralUni...]: 88.55%\n",
            "    Unit-19 [EntropyMaxwellU...]: 56.13%\n",
            "    Unit-20 [QuantumFluxUnit...]: 75.95%\n",
            "    Unit-21 [EventHorizonUni...]: 58.30%\n",
            "    Unit-22 [SVC...]: 84.77%\n",
            "    Unit-23 [RandomForestCla...]: 99.31%\n",
            "    Unit-24 [XGBClassifier...]: 99.66%\n",
            "    Unit-25 [NeuralManifoldU...]: 80.99%\n",
            "    Unit-26 [NeuralManifoldU...]: 74.11%\n",
            " > Phase 3: The Council of 12 Selected. Best Score: 99.77%\n",
            " > Phase 4: Training The Neural Apex (Deep Stacking)...\n",
            " > NEURAL APEX TRAINING COMPLETE.\n",
            "   Internal Coherence: 99.79%\n",
            "\n",
            "===========================================================================\n",
            " üèÜ FINAL RESULTS: Wall-Following Robot\n",
            "===========================================================================\n",
            " MODEL                     | ACCURACY   | TIME     | STATUS\n",
            "---------------------------------------------------------------------------\n",
            " XGBoost (Baseline)        | 99.9084%   | 0.4s     | üëë WINNER\n",
            " Titan-Neura (Hybrid)      | 99.9084%   | 77.4s     | üëë WINNER\n",
            " Random Forest             | 99.2674%   | 1.2s     | -0.64%\n",
            "===========================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Phoneme (Audio)\",\n",
        "    openml_id=1489,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi0bXTl-pTcg",
        "outputId": "42b182e5-babf-4979-ba09-5a11bb70696a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üöÄ INITIATING HYBRID BENCHMARK: Phoneme (Audio) (OpenML ID: 1489)\n",
            "======================================================================\n",
            " > üì• Downloading dataset from OpenML Cloud...\n",
            " > ‚úÖ Data Ready. Shape: (5404, 5) | Classes: 2\n",
            "\n",
            " > ‚öîÔ∏è  Benchmarking: XGBoost (Standard)...\n",
            "    -> Accuracy: 87.60%\n",
            " > ‚öîÔ∏è  Benchmarking: Random Forest (Standard)...\n",
            "    -> Accuracy: 90.10%\n",
            "\n",
            " > üß† ACTIVATING INVENTION: Titan-Neura (Hybrid Apex)...\n",
            " -----------------------------------------------------------\n",
            "  ‚ö†Ô∏è TITAN-26 PROTOCOL INITIATED (Full Arsenal)\n",
            " -----------------------------------------------------------\n",
            " > Phase 2: Organ Evolution (Training 26 Units)...\n",
            "    Unit-01 [ExtraTreesClass...]: 90.75%\n",
            "    Unit-02 [RandomForestCla...]: 90.52%\n",
            "    Unit-03 [HistGradientBoo...]: 90.40%\n",
            "    Unit-04 [XGBClassifier...]: 88.79%\n",
            "    Unit-05 [XGBClassifier...]: 88.21%\n",
            "    Unit-06 [NuSVC...]: 83.12%\n",
            "    Unit-07 [SVC...]: 76.42%\n",
            "    Unit-08 [KNeighborsClass...]: 89.13%\n",
            "    Unit-09 [KNeighborsClass...]: 88.67%\n",
            "    Unit-10 [QuadraticDiscri...]: 73.06%\n",
            "    Unit-11 [SVC...]: 85.20%\n",
            "    Unit-18 [GoldenSpiralUni...]: 89.94%\n",
            "    Unit-19 [EntropyMaxwellU...]: 75.26%\n",
            "    Unit-20 [QuantumFluxUnit...]: 84.62%\n",
            "    Unit-21 [EventHorizonUni...]: 75.84%\n",
            "    Unit-22 [SVC...]: 84.97%\n",
            "    Unit-23 [RandomForestCla...]: 90.29%\n",
            "    Unit-24 [XGBClassifier...]: 89.25%\n",
            "    Unit-25 [NeuralManifoldU...]: 83.24%\n",
            "    Unit-26 [NeuralManifoldU...]: 81.85%\n",
            " > Phase 3: The Council of 12 Selected. Best Score: 90.75%\n",
            " > Phase 4: Training The Neural Apex (Deep Stacking)...\n",
            " > NEURAL APEX TRAINING COMPLETE.\n",
            "   Internal Coherence: 92.46%\n",
            "\n",
            "===========================================================================\n",
            " üèÜ FINAL RESULTS: Phoneme (Audio)\n",
            "===========================================================================\n",
            " MODEL                     | ACCURACY   | TIME     | STATUS\n",
            "---------------------------------------------------------------------------\n",
            " Random Forest             | 90.1018%   | 1.0s     | üëë WINNER\n",
            " Titan-Neura (Hybrid)      | 89.3617%   | 88.7s     | -0.74%\n",
            " XGBoost (Baseline)        | 87.6041%   | 0.2s     | -2.50%\n",
            "===========================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Magic Gamma Telescope\",\n",
        "    openml_id=1120,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "MQf05HlfpTWF",
        "outputId": "b9cd98f1-eda0-4785-9a1b-ed7620b70fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üöÄ INITIATING HYBRID BENCHMARK: Magic Gamma Telescope (OpenML ID: 1120)\n",
            "======================================================================\n",
            " > üì• Downloading dataset from OpenML Cloud...\n",
            " > ‚úÖ Data Ready. Shape: (19020, 10) | Classes: 2\n",
            "\n",
            " > ‚öîÔ∏è  Benchmarking: XGBoost (Standard)...\n",
            "    -> Accuracy: 88.17%\n",
            " > ‚öîÔ∏è  Benchmarking: Random Forest (Standard)...\n",
            "    -> Accuracy: 88.67%\n",
            "\n",
            " > üß† ACTIVATING INVENTION: Titan-Neura (Hybrid Apex)...\n",
            " -----------------------------------------------------------\n",
            "  ‚ö†Ô∏è TITAN-26 PROTOCOL INITIATED (Full Arsenal)\n",
            " -----------------------------------------------------------\n",
            " > Phase 2: Organ Evolution (Training 26 Units)...\n",
            "    Unit-01 [ExtraTreesClass...]: 86.86%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1994027829.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m run_comparative_benchmark(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Magic Gamma Telescope\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mopenml_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msample_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/tmp/ipython-input-2525561451.py\u001b[0m in \u001b[0;36mrun_comparative_benchmark\u001b[0;34m(dataset_name, openml_id, sample_limit)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtitan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHarmonicResonanceClassifier_TitanNeura\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mtitan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0macc_titan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mtime_titan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2018629187.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_raw_source\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_raw_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0;31m# Evolve only if strictly necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Satellite Image\",\n",
        "    openml_id=182,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "pABtyyRLpTNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Image Segmentation\",\n",
        "    openml_id=40978,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "pvUrJynVpTFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Vehicle Silhouettes\",\n",
        "    openml_id=54,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "lcNR-W_npS_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Bioresponse\",\n",
        "    openml_id=4134,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "Q6ASWfv0o0O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Spambase\",\n",
        "    openml_id=44,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "xrA7EnP2o0HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Steel Plates Fault\",\n",
        "    openml_id=1504,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "LAz8YBTjp03F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"QSAR Biodegradation\",\n",
        "    openml_id=1494,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "sezw74LAp0yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Ozone Level\",\n",
        "    openml_id=1487,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "rCE1FwBip0s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Sonar (Mines vs Rocks)\",\n",
        "    openml_id=40,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "uUYrzPotp0os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Waveform Generator\",\n",
        "    openml_id=60,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "cUNFw14Yp0ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Musk (Molecules)\",\n",
        "    openml_id=1116,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "4mnlTFf7p0gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Madelon (Synthetic)\",\n",
        "    openml_id=1111,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "VxNB39I2p0cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Page Blocks Layout\",\n",
        "    openml_id=30,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "cwgVDGzOp0ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Optdigits\",\n",
        "    openml_id=28,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "4IFduqx3p0Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Pendigits\",\n",
        "    openml_id=32,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "sb_kNe98p0Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Letter Recognition\",\n",
        "    openml_id=6,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "jGjPqApRp0NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Credit-G (German)\",\n",
        "    openml_id=31,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "b4DksaWYp0Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Australian Credit\",\n",
        "    openml_id=29,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "7VJcASZRp0CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Diabetes (Pima)\",\n",
        "    openml_id=37,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "wQDq5QF-pz_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Sick (Thyroid)\",\n",
        "    openml_id=38,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "7DJqMt3cpz8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Hill-Valley\",\n",
        "    openml_id=1479,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "MtZbJ7gfpz31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Hill-Valley\",\n",
        "    openml_id=1479,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "Ml_ctJvJpz01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Balance Scale\",\n",
        "    openml_id=11,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "80GKYR9NpzxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Car Evaluation\",\n",
        "    openml_id=21,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "-zKRRox1pzus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Tic-Tac-Toe\",\n",
        "    openml_id=50,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "rv0vFVqtpzsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Monks-2\",\n",
        "    openml_id=334,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "tyoOm_2EpowN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Chess (Kr-vs-Kp)\",\n",
        "    openml_id=3,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "T3lUGbsYpol8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"PC4 (Software Faults)\",\n",
        "    openml_id=1049,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "cmeblEmbpoZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_comparative_benchmark(\n",
        "    dataset_name=\"JM1 (Software Faults)\",\n",
        "    openml_id=1053,\n",
        "    sample_limit=None\n",
        ")"
      ],
      "metadata": {
        "id": "TCmszMkIpoXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w9AlHhgbo0Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXECUTE THE COMMAND ---\n",
        "run_comparative_benchmark(\n",
        "    dataset_name=\"Texture Analysis\",\n",
        "    openml_id=40975,\n",
        "    sample_limit=5500\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLzEsLCilXtD",
        "outputId": "b2d62f59-a559-4018-9cc3-45917f053afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üöÄ INITIATING HYBRID BENCHMARK: Texture Analysis (OpenML ID: 40975)\n",
            "======================================================================\n",
            " > üì• Downloading dataset from OpenML Cloud...\n",
            " > Encoding 6 categorical features...\n",
            " > ‚úÖ Data Ready. Shape: (1728, 6) | Classes: 4\n",
            "\n",
            " > ‚öîÔ∏è  Benchmarking: XGBoost (Standard)...\n",
            "    -> Accuracy: 99.42%\n",
            " > ‚öîÔ∏è  Benchmarking: Random Forest (Standard)...\n",
            "    -> Accuracy: 98.27%\n",
            "\n",
            " > üß† ACTIVATING INVENTION: Titan-Neura (Hybrid Apex)...\n",
            " -----------------------------------------------------------\n",
            "  ‚ö†Ô∏è TITAN-26 PROTOCOL INITIATED (Full Arsenal)\n",
            " -----------------------------------------------------------\n",
            " > Phase 2: Organ Evolution (Training 26 Units)...\n",
            "    Unit-01 [ExtraTreesClass...]: 97.47%\n",
            "    Unit-02 [RandomForestCla...]: 96.39%\n",
            "    Unit-03 [HistGradientBoo...]: 99.28%\n",
            "    Unit-04 [XGBClassifier...]: 99.28%\n",
            "    Unit-05 [XGBClassifier...]: 99.28%\n",
            "    Unit-06 [NuSVC...]: 98.56%\n",
            "    Unit-07 [SVC...]: 78.70%\n",
            "    Unit-08 [KNeighborsClass...]: 83.03%\n",
            "    Unit-09 [KNeighborsClass...]: 90.25%\n",
            "    Unit-10 [QuadraticDiscri...]: 70.04%\n",
            "    Unit-11 [SVC...]: 97.83%\n",
            "    Unit-18 [GoldenSpiralUni...]: 86.28%\n",
            "    Unit-19 [EntropyMaxwellU...]: 68.95%\n",
            "    Unit-20 [QuantumFluxUnit...]: 83.75%\n",
            "    Unit-21 [EventHorizonUni...]: 64.62%\n",
            "    Unit-22 [SVC...]: 84.48%\n",
            "    Unit-23 [RandomForestCla...]: 96.39%\n",
            "    Unit-24 [XGBClassifier...]: 99.28%\n",
            "    Unit-25 [NeuralManifoldU...]: 72.56%\n",
            "    Unit-26 [NeuralManifoldU...]: 68.95%\n",
            " > Phase 3: The Council of 12 Selected. Best Score: 99.28%\n",
            " > Phase 4: Training The Neural Apex (Deep Stacking)...\n",
            " > NEURAL APEX TRAINING COMPLETE.\n",
            "   Internal Coherence: 99.64%\n",
            "\n",
            "===========================================================================\n",
            " üèÜ FINAL RESULTS: Texture Analysis\n",
            "===========================================================================\n",
            " MODEL                     | ACCURACY   | TIME     | STATUS\n",
            "---------------------------------------------------------------------------\n",
            " Titan-Neura (Hybrid)      | 100.0000%   | 26.1s     | üëë WINNER\n",
            " XGBoost (Baseline)        | 99.4220%   | 0.1s     | -0.58%\n",
            " Random Forest             | 98.2659%   | 0.3s     | -1.73%\n",
            "===========================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8DzPLKJbn3WX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}