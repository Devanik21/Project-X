{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xhrdlEHgY6u",
        "outputId": "fb0fd7b6-0b06-47d5-8e2d-00e796bd8167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> [TITAN PROTOCOL] T4 GPU DETECTED. INFINITE MEMORY ENGINE ONLINE.\n",
            "Active\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import warnings\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.preprocessing import QuantileTransformer, LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "# --- COMPETITORS ---\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    from lightgbm import LGBMClassifier\n",
        "except ImportError:\n",
        "    print(\">>> [WARNING] XGBoost or LightGBM not installed. Benchmarks will be limited.\")\n",
        "\n",
        "# --- GPU ACTIVATION ---\n",
        "try:\n",
        "    import cupy as cp\n",
        "    print(\">>> [TITAN PROTOCOL] T4 GPU DETECTED. INFINITE MEMORY ENGINE ONLINE.\")\n",
        "    cp.random.seed(42)\n",
        "    GPU_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\">>> [FATAL] GPU REQUIRED FOR TITAN.\")\n",
        "    sys.exit()\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. THE MEMORY UNIT (The Synapse)\n",
        "# ==========================================\n",
        "class MEMORY_UNIT:\n",
        "    def __init__(self, n_neurons, input_dim, seed, activation_func):\n",
        "        cp.random.seed(seed)\n",
        "        self.n_neurons = n_neurons\n",
        "        self.activation = activation_func # <--- The Chosen One\n",
        "\n",
        "        self.W_in = cp.random.uniform(-1.0, 1.0, (n_neurons, input_dim)).astype(cp.float32)\n",
        "        self.W_cortex = cp.random.normal(0, 1.0 / np.sqrt(n_neurons), (n_neurons, n_neurons)).astype(cp.float32)\n",
        "\n",
        "        # Spectral stabilizer (Simplified for universal AFs)\n",
        "        try:\n",
        "            v = cp.random.randn(n_neurons)\n",
        "            for _ in range(5):\n",
        "                v = self.W_cortex @ v\n",
        "                v = v / cp.linalg.norm(v)\n",
        "            max_eig = cp.linalg.norm(self.W_cortex @ v)\n",
        "            if max_eig > 0: self.W_cortex /= max_eig\n",
        "        except: pass\n",
        "        self.readout = None\n",
        "\n",
        "    def process(self, X_gpu):\n",
        "        state = cp.zeros((X_gpu.shape[0], self.n_neurons), dtype=cp.float32)\n",
        "        for _ in range(5):\n",
        "            pre = (X_gpu @ self.W_in.T) + (state @ self.W_cortex.T)\n",
        "            state = self.activation(pre) # <--- Use the scanned function\n",
        "        return state\n",
        "\n",
        "    # fit_residual and predict_correction remain the same\n",
        "    def fit_residual(self, X_gpu, Residual_gpu, alpha=10.0):\n",
        "        H = self.process(X_gpu)\n",
        "        I = cp.eye(self.n_neurons, dtype=cp.float32)\n",
        "        self.readout = cp.linalg.solve(H.T @ H + alpha*I, H.T @ Residual_gpu)\n",
        "\n",
        "    def predict_correction(self, X_gpu):\n",
        "        H = self.process(X_gpu)\n",
        "        return H @ self.readout\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 0. THE RESONANCE SCANNER (God's Eye)\n",
        "# ==========================================\n",
        "class RESONANCE_SCANNER:\n",
        "    def __init__(self):\n",
        "        self.activations = {}\n",
        "        self._generate_100_functions()\n",
        "\n",
        "    def _generate_100_functions(self):\n",
        "        # 1. Standard Activations\n",
        "        self.activations['tanh'] = lambda x: cp.tanh(x)\n",
        "        self.activations['relu'] = lambda x: cp.maximum(0, x)\n",
        "        self.activations['sigmoid'] = lambda x: 1 / (1 + cp.exp(-x))\n",
        "        self.activations['swish'] = lambda x: x * (1 / (1 + cp.exp(-x)))\n",
        "        self.activations['mish'] = lambda x: x * cp.tanh(cp.log(1 + cp.exp(x)))\n",
        "\n",
        "        # 2. Harmonic Series (The \"Siren\" Frequencies)\n",
        "        # We test different frequencies to find the \"Pitch\" of the data\n",
        "        for freq in [0.5, 1.0, 1.5, 2.0, 3.0, 5.0, 8.0, 13.0, 21.0, 34.0, 55.0]: # Fibonacci Frequencies\n",
        "            self.activations[f'sin_omega_{freq}'] = lambda x, f=freq: cp.sin(f * x)\n",
        "            self.activations[f'cos_omega_{freq}'] = lambda x, f=freq: cp.cos(f * x)\n",
        "\n",
        "        # 3. Gaussian Kernels (For Localized Spikes)\n",
        "        for sigma in [0.1, 0.5, 1.0, 2.0, 5.0]:\n",
        "            self.activations[f'gaussian_{sigma}'] = lambda x, s=sigma: cp.exp(-cp.square(x) / (2 * s**2))\n",
        "\n",
        "        # 4. Hybrid & Exotic (The \"Chaos\" Functions)\n",
        "        self.activations['sinc'] = lambda x: cp.sin(x) / (x + 1e-6)\n",
        "        self.activations['morlet'] = lambda x: cp.cos(5*x) * cp.exp(-x**2/2) # Wavelet\n",
        "        self.activations['x_sin_x'] = lambda x: x * cp.sin(x)\n",
        "        self.activations['sin_tanh'] = lambda x: cp.sin(cp.tanh(x))\n",
        "\n",
        "        # ... (We can generate more parametrically to reach 100+)\n",
        "        # Generating fine-tuned frequency bands to hit 100+ variations\n",
        "        for i in range(1, 60):\n",
        "            f = 0.1 * i\n",
        "            self.activations[f'fine_sin_{f:.1f}'] = lambda x, freq=f: cp.sin(freq * x)\n",
        "\n",
        "    def scan(self, X_gpu, Residual_gpu, n_neurons=100):\n",
        "        \"\"\"\n",
        "        Rapidly tests all activations on the FULL dataset to find the best fit.\n",
        "        \"\"\"\n",
        "        best_name = \"tanh\"\n",
        "        best_score = -np.inf\n",
        "\n",
        "        # Create a single random projection to test the AFs fairly\n",
        "        # We use a small probe size (n_neurons=100) for extreme speed\n",
        "        cp.random.seed(42)\n",
        "        W_probe = cp.random.uniform(-1.0, 1.0, (n_neurons, X_gpu.shape[1])).astype(cp.float32)\n",
        "\n",
        "        # Pre-compute projection\n",
        "        Projected_X = X_gpu @ W_probe.T\n",
        "\n",
        "        print(f\"   [SCANNER] Testing {len(self.activations)} Quantum Activation Functions...\", end=\"\")\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        # Fast Loop\n",
        "        for name, func in self.activations.items():\n",
        "            try:\n",
        "                # 1. Apply Candidate Activation\n",
        "                H = func(Projected_X)\n",
        "\n",
        "                # 2. Fast Ridge Solver (One-Shot Learning)\n",
        "                # We simply check: \"Can this activation shape explain the error?\"\n",
        "                # Solve: H * w = Residual\n",
        "                # We use a tiny alpha for stability\n",
        "                I = cp.eye(n_neurons, dtype=cp.float32)\n",
        "                # This inverse is tiny (100x100), takes microseconds on GPU\n",
        "                w_out = cp.linalg.solve(H.T @ H + 1.0*I, H.T @ Residual_gpu)\n",
        "\n",
        "                # 3. Measure Fit (Energy Reduction)\n",
        "                pred = H @ w_out\n",
        "                # Score = How much variance of the residual did we capture?\n",
        "                # Higher is better.\n",
        "                error_norm = cp.linalg.norm(Residual_gpu - pred)\n",
        "                total_norm = cp.linalg.norm(Residual_gpu)\n",
        "                score = 1.0 - (error_norm / total_norm)\n",
        "\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_name = name\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        elapsed = time.time() - start\n",
        "        print(f\" Done in {elapsed:.2f}s.\")\n",
        "        print(f\"   [SCANNER] Resonance Detected: '{best_name.upper()}' (Fit Score: {best_score:.4f})\")\n",
        "\n",
        "        return best_name, self.activations[best_name]\n",
        "\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 2. TITAN INF (The Unified Intelligence) - VALIDATED\n",
        "# ==========================================\n",
        "# ==========================================\n",
        "# 2. TITAN OMEGA (The Universal Intelligence)\n",
        "# ==========================================\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "class TITAN_INF(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self):\n",
        "        self.memory_vault = []\n",
        "        self.base_model = None\n",
        "        self.input_dim = 0\n",
        "        self.n_classes = 0\n",
        "\n",
        "    def _tournament_selection(self, X, y):\n",
        "        print(f\" > [G.O.D. PROTOCOL] Initiating Host Selection Tournament...\")\n",
        "\n",
        "        # 1. DEFINE THE GLADIATORS\n",
        "        competitors = [\n",
        "            (\"XGBoost\", XGBClassifier(n_estimators=200, use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)),\n",
        "            (\"LightGBM\", LGBMClassifier(n_estimators=200, random_state=42, verbosity=-1, n_jobs=-1)),\n",
        "            (\"ExtraTrees\", ExtraTreesClassifier(n_estimators=200, n_jobs=-1, random_state=42)),\n",
        "            (\"RandomForest\", RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)),\n",
        "           # (\"SVM (RBF)\", SVC(probability=True, kernel='rbf', random_state=42)), # Powerful for small/complex data\n",
        "           # (\"KNN (k=5)\", KNeighborsClassifier(n_neighbors=5, n_jobs=-1)),       # Good for local geometry\n",
        "           # (\"LogisticReg\", LogisticRegression(max_iter=1000, n_jobs=-1)),       # Baseline for linear\n",
        "           # (\"LDA\", LinearDiscriminantAnalysis()),\n",
        "           # (\"QDA\", QuadraticDiscriminantAnalysis()),                            # Good for Gaussian distributions\n",
        "           # (\"Ridge\", RidgeClassifier(random_state=42))                          # Fast linear\n",
        "        ]\n",
        "\n",
        "        best_name = \"None\"\n",
        "        best_score = -1.0\n",
        "        best_model = None\n",
        "\n",
        "        # 2. RAPID BATTLE (3-Fold CV for speed)\n",
        "        # We use a smaller fold here just to pick the winner quickly\n",
        "        for name, model in competitors:\n",
        "            try:\n",
        "                # Ridge doesn't support predict_proba by default, handle exception or skip\n",
        "                if name == \"Ridge\":\n",
        "                    # Ridge is special, let's skip for probability requirement or calibrate it\n",
        "                    # For simplicity in this universal script, we skip non-proba models for the base\n",
        "                    continue\n",
        "\n",
        "                # Quick check\n",
        "                score = np.mean(cross_val_score(model, X, y, cv=5, scoring='accuracy', n_jobs=-1))\n",
        "                print(f\"   [SCAR] {name:<12} | Score: {score:.4%}\")\n",
        "\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_name = name\n",
        "                    best_model = model\n",
        "            except Exception as e:\n",
        "                # Some models might fail on specific data types (e.g. QDA on collinear), we ignore them\n",
        "                pass\n",
        "\n",
        "        print(f\" > [VICTORY] Champion Selected: {best_name.upper()} (Base Acc: {best_score:.4%})\")\n",
        "        return best_model\n",
        "\n",
        "    def perceive(self, X, y):\n",
        "        self.input_dim = X.shape[1]\n",
        "        self.n_classes = len(np.unique(y))\n",
        "\n",
        "        # 1. SELECT THE PERFECT HOST\n",
        "        self.base_model = self._tournament_selection(X, y)\n",
        "\n",
        "        # 2. TRAIN CHAMPION (100% Data)\n",
        "        print(f\" > [TITAN] Assimilating {self.base_model.__class__.__name__}...\")\n",
        "        self.base_model.fit(X, y)\n",
        "\n",
        "        # 3. GENERATE HONEST RESIDUALS (5-Fold CV)\n",
        "        print(f\" > [TITAN] Generating Holographic Residuals (5-Fold CV)...\")\n",
        "        try:\n",
        "            cv_probs = cross_val_predict(self.base_model, X, y, cv=5, method='predict_proba', n_jobs=-1)\n",
        "        except:\n",
        "            # Fallback if cross_val fails (e.g., extremely small classes)\n",
        "            print(\"   [WARNING] CV Failed. Fallback to OOB residuals.\")\n",
        "            self.base_model.fit(X, y)\n",
        "            cv_probs = self.base_model.predict_proba(X)\n",
        "\n",
        "        # 4. ENTER THE INFINITE LOOP\n",
        "        self._fit_evolution(X, y, cv_probs)\n",
        "\n",
        "    def _fit_evolution(self, X, y, base_probs):\n",
        "        current_probs = base_probs\n",
        "        current_preds = np.argmax(current_probs, axis=1)\n",
        "        best_acc = accuracy_score(y, current_preds)\n",
        "        current_probs = base_probs\n",
        "        current_logits = cp.asarray(np.log(current_probs + 1e-9))\n",
        "\n",
        "        # Initialize Scanner\n",
        "        self.scanner = RESONANCE_SCANNER()\n",
        "\n",
        "        X_gpu = cp.asarray(X, dtype=cp.float32)\n",
        "        current_logits = cp.asarray(np.log(current_probs + 1e-9))\n",
        "        y_gpu = cp.asarray(y)\n",
        "        # [UPDATED] The Silencer: Label Smoothing (Prevents Gradient Explosion)\n",
        "        # Instead of 0.0 and 1.0, we use 0.01 and 0.99.\n",
        "        # This keeps the \"Death Ray\" from burning out the weights.\n",
        "        smooth_factor = 0.01\n",
        "        Y_target = cp.zeros((len(y), self.n_classes), dtype=cp.float32) + (smooth_factor / self.n_classes)\n",
        "        for i in range(self.n_classes):\n",
        "            Y_target[y_gpu==i, i] = 1.0 - smooth_factor\n",
        "\n",
        "        print(f\"   [BASE] Holographic Accuracy: {best_acc:.4%}\")\n",
        "\n",
        "        # --- THE OMEGA LOOP ---\n",
        "        cycle = 0\n",
        "        patience = 0\n",
        "        patience_limit = 30\n",
        "        max_units = 100000\n",
        "\n",
        "        while cycle < max_units:\n",
        "            cycle += 1\n",
        "\n",
        "            probs = cp.exp(current_logits) / cp.sum(cp.exp(current_logits), axis=1, keepdims=True)\n",
        "            residual = Y_target - probs\n",
        "\n",
        "            # 2. GOD'S EYE SCAN (Every 5 cycles to adapt to changing error landscape)\n",
        "            # We don't need to scan every single cycle, but let's scan occasionally\n",
        "            # or if patience is getting high.\n",
        "            if cycle == 1 or cycle % 5 == 0:\n",
        "                best_af_name, best_af_func = self.scanner.scan(X_gpu, residual)\n",
        "\n",
        "\n",
        "            # HYPER-MUTATION\n",
        "            best_unit_cycle = None\n",
        "            best_acc_cycle = -1\n",
        "            best_logits_cycle = None\n",
        "\n",
        "            for _ in range(10):\n",
        "                n_neurons = np.random.randint(500, 3000)\n",
        "                alpha = 10 ** np.random.uniform(-1, 4)\n",
        "                seed = np.random.randint(0, 100000) + cycle\n",
        "\n",
        "                # PASS THE CHOSEN FUNCTION HERE\n",
        "                unit = MEMORY_UNIT(n_neurons, self.input_dim, seed, best_af_func)\n",
        "                unit.fit_residual(X_gpu, residual, alpha=alpha)\n",
        "\n",
        "                correction = unit.predict_correction(X_gpu)\n",
        "                lr = 0.1 / (1 + (cycle * 0.01))\n",
        "\n",
        "                temp_logits = current_logits + (correction * lr)\n",
        "                temp_preds = cp.asnumpy(cp.argmax(temp_logits, axis=1))\n",
        "                temp_acc = accuracy_score(y, temp_preds)\n",
        "\n",
        "                if temp_acc > best_acc_cycle:\n",
        "                    best_acc_cycle = temp_acc\n",
        "                    best_unit_cycle = unit\n",
        "                    best_logits_cycle = temp_logits\n",
        "\n",
        "            if best_acc_cycle > best_acc:\n",
        "                self.memory_vault.append(best_unit_cycle)\n",
        "                current_logits = best_logits_cycle\n",
        "                best_acc = best_acc_cycle\n",
        "                patience = 0\n",
        "                print(f\"   [EVOLVE] Cycle {cycle}: IMPROVEMENT -> Acc: {best_acc:.4%}\")\n",
        "            else:\n",
        "                patience += 1\n",
        "                if cycle % 5 == 0:\n",
        "                    print(f\"   [FIGHTING] Cycle {cycle}: Stagnant. (Patience {patience}/{patience_limit})\")\n",
        "\n",
        "                if patience >= patience_limit:\n",
        "                    print(f\"   [STOP] Evolution halted. No improvement for {patience_limit} cycles.\")\n",
        "                    break\n",
        "\n",
        "            if best_acc >= 0.9999:\n",
        "                print(\"   [GOD MODE] Perfect Accuracy Achieved. Stopping.\")\n",
        "                break\n",
        "\n",
        "        print(f\"   [TITAN] Evolution Complete. Total Memory Units: {len(self.memory_vault)}. Final Training Acc: {best_acc:.4%}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        base_probs = self.base_model.predict_proba(X)\n",
        "        current_logits = cp.asarray(np.log(base_probs + 1e-9))\n",
        "        X_gpu = cp.asarray(X, dtype=cp.float32)\n",
        "\n",
        "        cycle = 0\n",
        "        for unit in self.memory_vault:\n",
        "            cycle += 1\n",
        "            correction = unit.predict_correction(X_gpu)\n",
        "            lr = 0.1 / (1 + (cycle * 0.01))\n",
        "            current_logits += (correction * lr)\n",
        "\n",
        "        return cp.asnumpy(cp.argmax(current_logits, axis=1))\n",
        "\n",
        "# ==========================================\n",
        "# 3. THE ARENA ENGINE\n",
        "# ==========================================\n",
        "# ==========================================\n",
        "# 3. THE ARENA ENGINE (UPDATED: VERBOSE LOADER)\n",
        "# ==========================================\n",
        "def TITAN_VS_GOLIATHS(data_id, name):\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\" >>> PARADIGM SHIFT PROTOCOL: {name.upper()} (ID: {data_id})\")\n",
        "    print(f\" >>> OBJECTIVE: Demonstrate Superiority of Infinite Memory over Static Models\")\n",
        "    print(f\"{'='*100}\")\n",
        "\n",
        "    # 1. SUMMON DATA (With Status Updates)\n",
        "    try:\n",
        "        print(f\" > [SYSTEM] Establishing Neural Link to OpenML (ID: {data_id})...\")\n",
        "        start_load = time.time()\n",
        "\n",
        "        # We explicitly request 'pandas' parser for speed.\n",
        "        # If this fails, install pyarrow: pip install pyarrow\n",
        "        data = fetch_openml(data_id=data_id, as_frame=True, parser='pandas')\n",
        "\n",
        "        print(f\" > [SYSTEM] Data Downloaded in {time.time() - start_load:.2f}s. Parsing Structure...\")\n",
        "\n",
        "        X_raw = data.data\n",
        "        y_raw = data.target\n",
        "\n",
        "        print(f\" > [SYSTEM] Dimensions Detected: {X_raw.shape}. Normalizing entropy...\")\n",
        "\n",
        "        if X_raw.isnull().values.any():\n",
        "            print(\"   > [WARNING] Null values detected. Filling with void (0).\")\n",
        "            X_raw = X_raw.fillna(0)\n",
        "\n",
        "        le = LabelEncoder()\n",
        "        y = le.fit_transform(y_raw)\n",
        "\n",
        "        # Handle Categorical Columns by forcing float conversion if possible, or encoding\n",
        "        # This prevents the \"silent hang\" when scalars try to eat strings\n",
        "        X = X_raw.values.astype(np.float32) if hasattr(X_raw, 'values') else X_raw.astype(np.float32)\n",
        "\n",
        "        print(f\" > [SYSTEM] Scaling Geometries (Standard + Quantile)...\")\n",
        "        scaler_std = StandardScaler()\n",
        "        X_std = scaler_std.fit_transform(X)\n",
        "\n",
        "        scaler_qt = QuantileTransformer(output_distribution='normal', random_state=42, n_quantiles=min(1000, len(X)))\n",
        "        X_qt = scaler_qt.fit_transform(X)\n",
        "\n",
        "        X_train_std, X_test_std, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=42)\n",
        "        X_train_qt, X_test_qt, _, _ = train_test_split(X_qt, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        print(f\" > [SYSTEM] Data Ready. Entering The Arena.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n [FATAL ERROR] Data Summon Failed: {e}\")\n",
        "        print(\" [HINT] If this is a connection error, check internet. If 'parser' error, pip install pyarrow.\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # 2. STATIC MODEL BENCHMARKS\n",
        "    print(\"\\n >>> PHASE 1: STATIC MODEL EVALUATION (THE OLD GUARD)\")\n",
        "    print(f\" {'-'*80}\")\n",
        "    competitors = [\n",
        "        (\"XGBoost\", XGBClassifier(n_estimators=200, use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)),\n",
        "        (\"LightGBM\", LGBMClassifier(n_estimators=200, random_state=42, verbosity=-1, n_jobs=-1)),\n",
        "        (\"ExtraTrees\", ExtraTreesClassifier(n_estimators=200, random_state=42, n_jobs=-1)),\n",
        "        (\"RandomForest\", RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)),\n",
        "    ]\n",
        "\n",
        "    for model_name, model in competitors:\n",
        "        start_time = time.time()\n",
        "        try:\n",
        "            model.fit(X_train_std, y_train)\n",
        "            preds = model.predict(X_test_std)\n",
        "            acc = accuracy_score(y_test, preds)\n",
        "            elapsed = time.time() - start_time\n",
        "            results.append({\"Model\": model_name, \"Accuracy\": acc, \"Time\": elapsed})\n",
        "            print(f\"  > [COMPLETED] {model_name:<16} | Accuracy: {acc:.4%} | Time: {elapsed:.2f}s\")\n",
        "        except Exception as e:\n",
        "            print(f\"  > [FAILED]    {model_name:<16} | Error: {e}\")\n",
        "\n",
        "    # 3. TITAN EVOLUTION\n",
        "    print(\"\\n >>> PHASE 2: TITAN INF AWAKENING (THE NEW PARADIGM)\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    titan = TITAN_INF()\n",
        "    # We pass ONLY Training data. The model handles the internal split.\n",
        "    titan.perceive(X_train_qt, y_train)\n",
        "\n",
        "    # We predict on Test data WITHOUT passing y_test.\n",
        "    titan_preds = titan.predict(X_test_qt)\n",
        "    titan_acc = accuracy_score(y_test, titan_preds)\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    results.append({\"Model\": \"TITAN INF (Ours)\", \"Accuracy\": titan_acc, \"Time\": elapsed})\n",
        "\n",
        "    # 4. FINAL REPORT\n",
        "    df = pd.DataFrame(results).sort_values(by=\"Accuracy\", ascending=False)\n",
        "\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\" >>> FINAL INTELLIGENCE REPORT: {name}\")\n",
        "    print(f\"{'='*100}\")\n",
        "    print(f\"{'RANK':<6} | {'MODEL ARCHITECTURE':<25} | {'ACCURACY':<12} | {'ERROR RATE':<12} | {'TIME (s)':<10}\")\n",
        "    print(f\"{'-'*100}\")\n",
        "\n",
        "    rank = 1\n",
        "    for row in df.itertuples():\n",
        "        error_rate = 1.0 - row.Accuracy\n",
        "        model_name = row.Model\n",
        "        if \"TITAN\" in model_name: model_name = f\"** {model_name} **\" # Highlight Winner\n",
        "\n",
        "        print(f\" #{rank:<5} | {model_name:<25} | {row.Accuracy:.4%}     | {error_rate:.4%}       | {row.Time:.4f}\")\n",
        "        rank += 1\n",
        "    print(f\"{'='*100}\\n\")\n",
        "\n",
        "# --- EXECUTE PROTOCOL ---\n",
        "if __name__ == \"__main__\":\n",
        "    print('Active')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TITAN_VS_GOLIATHS(1494, \"QSAR Biodegradation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4I0o5xLjdQN",
        "outputId": "bb296421-b7f9-4c21-f42c-8b74bb39ae26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            " >>> PARADIGM SHIFT PROTOCOL: QSAR BIODEGRADATION (ID: 1494)\n",
            " >>> OBJECTIVE: Demonstrate Superiority of Infinite Memory over Static Models\n",
            "====================================================================================================\n",
            " > [SYSTEM] Establishing Neural Link to OpenML (ID: 1494)...\n",
            " > [SYSTEM] Data Downloaded in 0.02s. Parsing Structure...\n",
            " > [SYSTEM] Dimensions Detected: (1055, 41). Normalizing entropy...\n",
            " > [SYSTEM] Scaling Geometries (Standard + Quantile)...\n",
            " > [SYSTEM] Data Ready. Entering The Arena.\n",
            "\n",
            " >>> PHASE 1: STATIC MODEL EVALUATION (THE OLD GUARD)\n",
            " --------------------------------------------------------------------------------\n",
            "  > [COMPLETED] XGBoost          | Accuracy: 87.2038% | Time: 0.18s\n",
            "  > [COMPLETED] LightGBM         | Accuracy: 87.2038% | Time: 0.26s\n",
            "  > [COMPLETED] ExtraTrees       | Accuracy: 87.6777% | Time: 0.40s\n",
            "  > [COMPLETED] RandomForest     | Accuracy: 88.6256% | Time: 0.57s\n",
            "\n",
            " >>> PHASE 2: TITAN INF AWAKENING (THE NEW PARADIGM)\n",
            " > [G.O.D. PROTOCOL] Initiating Host Selection Tournament...\n",
            "   [SCAR] XGBoost      | Score: 85.0690%\n",
            "   [SCAR] LightGBM     | Score: 86.1348%\n",
            "   [SCAR] ExtraTrees   | Score: 86.2560%\n",
            "   [SCAR] RandomForest | Score: 86.2553%\n",
            " > [VICTORY] Champion Selected: EXTRATREES (Base Acc: 86.2560%)\n",
            " > [TITAN] Assimilating ExtraTreesClassifier...\n",
            " > [TITAN] Generating Holographic Residuals (5-Fold CV)...\n",
            "   [BASE] Holographic Accuracy: 86.2559%\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.18s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_2.5' (Fit Score: 0.0751)\n",
            "   [EVOLVE] Cycle 1: IMPROVEMENT -> Acc: 87.3223%\n",
            "   [EVOLVE] Cycle 2: IMPROVEMENT -> Acc: 88.1517%\n",
            "   [EVOLVE] Cycle 3: IMPROVEMENT -> Acc: 89.2180%\n",
            "   [EVOLVE] Cycle 4: IMPROVEMENT -> Acc: 90.5213%\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.10s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_2.5' (Fit Score: 0.0723)\n",
            "   [EVOLVE] Cycle 5: IMPROVEMENT -> Acc: 91.2322%\n",
            "   [EVOLVE] Cycle 6: IMPROVEMENT -> Acc: 91.8246%\n",
            "   [EVOLVE] Cycle 7: IMPROVEMENT -> Acc: 92.8910%\n",
            "   [EVOLVE] Cycle 8: IMPROVEMENT -> Acc: 93.6019%\n",
            "   [EVOLVE] Cycle 9: IMPROVEMENT -> Acc: 94.1943%\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.13s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_2.5' (Fit Score: 0.0688)\n",
            "   [EVOLVE] Cycle 10: IMPROVEMENT -> Acc: 95.0237%\n",
            "   [EVOLVE] Cycle 11: IMPROVEMENT -> Acc: 95.8531%\n",
            "   [EVOLVE] Cycle 12: IMPROVEMENT -> Acc: 96.4455%\n",
            "   [EVOLVE] Cycle 13: IMPROVEMENT -> Acc: 96.5640%\n",
            "   [EVOLVE] Cycle 14: IMPROVEMENT -> Acc: 96.6825%\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.10s.\n",
            "   [SCANNER] Resonance Detected: 'COS_OMEGA_34.0' (Fit Score: 0.0678)\n",
            "   [EVOLVE] Cycle 15: IMPROVEMENT -> Acc: 97.2749%\n",
            "   [EVOLVE] Cycle 16: IMPROVEMENT -> Acc: 97.8673%\n",
            "   [EVOLVE] Cycle 17: IMPROVEMENT -> Acc: 98.2227%\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.11s.\n",
            "   [SCANNER] Resonance Detected: 'COS_OMEGA_34.0' (Fit Score: 0.0678)\n",
            "   [FIGHTING] Cycle 20: Stagnant. (Patience 3/30)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.10s.\n",
            "   [SCANNER] Resonance Detected: 'COS_OMEGA_34.0' (Fit Score: 0.0678)\n",
            "   [FIGHTING] Cycle 25: Stagnant. (Patience 8/30)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.09s.\n",
            "   [SCANNER] Resonance Detected: 'COS_OMEGA_34.0' (Fit Score: 0.0678)\n",
            "   [FIGHTING] Cycle 30: Stagnant. (Patience 13/30)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.09s.\n",
            "   [SCANNER] Resonance Detected: 'COS_OMEGA_34.0' (Fit Score: 0.0678)\n",
            "   [FIGHTING] Cycle 35: Stagnant. (Patience 18/30)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.10s.\n",
            "   [SCANNER] Resonance Detected: 'COS_OMEGA_34.0' (Fit Score: 0.0678)\n",
            "   [FIGHTING] Cycle 40: Stagnant. (Patience 23/30)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.09s.\n",
            "   [SCANNER] Resonance Detected: 'COS_OMEGA_34.0' (Fit Score: 0.0678)\n",
            "   [FIGHTING] Cycle 45: Stagnant. (Patience 28/30)\n",
            "   [STOP] Evolution halted. No improvement for 30 cycles.\n",
            "   [TITAN] Evolution Complete. Total Memory Units: 17. Final Training Acc: 98.2227%\n",
            "\n",
            "====================================================================================================\n",
            " >>> FINAL INTELLIGENCE REPORT: QSAR Biodegradation\n",
            "====================================================================================================\n",
            "RANK   | MODEL ARCHITECTURE        | ACCURACY     | ERROR RATE   | TIME (s)  \n",
            "----------------------------------------------------------------------------------------------------\n",
            " #1     | RandomForest              | 88.6256%     | 11.3744%       | 0.5702\n",
            " #2     | ExtraTrees                | 87.6777%     | 12.3223%       | 0.4032\n",
            " #3     | XGBoost                   | 87.2038%     | 12.7962%       | 0.1756\n",
            " #4     | LightGBM                  | 87.2038%     | 12.7962%       | 0.2576\n",
            " #5     | ** TITAN INF (Ours) **    | 86.7299%     | 13.2701%       | 48.8502\n",
            "====================================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TITAN_VS_GOLIATHS(4534, \"Phishing Websites\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrxr082xjY9v",
        "outputId": "7c9887cb-45c6-4134-9c3e-ae3239f88b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            " >>> PARADIGM SHIFT PROTOCOL: PHISHING WEBSITES (ID: 4534)\n",
            " >>> OBJECTIVE: Demonstrate Superiority of Infinite Memory over Static Models\n",
            "====================================================================================================\n",
            " > [SYSTEM] Establishing Neural Link to OpenML (ID: 4534)...\n",
            " > [SYSTEM] Data Downloaded in 0.05s. Parsing Structure...\n",
            " > [SYSTEM] Dimensions Detected: (11055, 30). Normalizing entropy...\n",
            " > [SYSTEM] Scaling Geometries (Standard + Quantile)...\n",
            " > [SYSTEM] Data Ready. Entering The Arena.\n",
            "\n",
            " >>> PHASE 1: STATIC MODEL EVALUATION (THE OLD GUARD)\n",
            " --------------------------------------------------------------------------------\n",
            "  > [COMPLETED] XGBoost          | Accuracy: 97.2863% | Time: 0.23s\n",
            "  > [COMPLETED] LightGBM         | Accuracy: 96.9697% | Time: 0.29s\n",
            "  > [COMPLETED] ExtraTrees       | Accuracy: 96.7888% | Time: 1.00s\n",
            "  > [COMPLETED] RandomForest     | Accuracy: 96.7888% | Time: 0.86s\n",
            "\n",
            " >>> PHASE 2: TITAN INF AWAKENING (THE NEW PARADIGM)\n",
            " > [TITAN] Creating Oracle Holdout Layer (80/20 Split)...\n",
            " > [G.O.D. PROTOCOL] Initiating Host Selection Tournament...\n",
            "   [SCAR] XGBoost      | Score: 96.5795%\n",
            "   [SCAR] ExtraTrees   | Score: 96.9046%\n",
            "   [SCAR] RandomForest | Score: 96.7491%\n",
            "   [SCAR] LGBM         | Score: 96.0283%\n",
            " > [VICTORY] Champion Selected: EXTRATREES (Base Acc: 96.9046%)\n",
            " > [TITAN] Assimilating ExtraTreesClassifier...\n",
            " > [TITAN] Generating Holographic Residuals...\n",
            "   [ORACLE] Initial True Accuracy: 96.5517%\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.29s.\n",
            "   [SCANNER] Resonance Detected: 'RELU' (Fit Score: 0.0041)\n",
            "   [EVOLVE] Cycle 1: GENUINE IMPROVEMENT -> Oracle Acc: 96.7213% (Func: relu)\n",
            "   [FIGHTING] Cycle 6: Stagnant. (Patience 5/20)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.17s.\n",
            "   [SCANNER] Resonance Detected: 'RELU' (Fit Score: 0.0041)\n",
            "   [FIGHTING] Cycle 11: Stagnant. (Patience 10/20)\n",
            "   [FIGHTING] Cycle 16: Stagnant. (Patience 15/20)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.18s.\n",
            "   [SCANNER] Resonance Detected: 'RELU' (Fit Score: 0.0041)\n",
            "   [FIGHTING] Cycle 21: Stagnant. (Patience 20/20)\n",
            "   [STOP] Evolution halted. Oracle has spoken.\n",
            "   [TITAN] Evolution Complete. Total Memory Units: 1. Final Oracle Acc: 96.7213%\n",
            "\n",
            "====================================================================================================\n",
            " >>> FINAL INTELLIGENCE REPORT: Phishing Websites\n",
            "====================================================================================================\n",
            "RANK   | MODEL ARCHITECTURE        | ACCURACY     | ERROR RATE   | TIME (s)  \n",
            "----------------------------------------------------------------------------------------------------\n",
            " #1     | XGBoost                   | 97.2863%     | 2.7137%       | 0.2276\n",
            " #2     | LightGBM                  | 96.9697%     | 3.0303%       | 0.2933\n",
            " #3     | ExtraTrees                | 96.7888%     | 3.2112%       | 0.9954\n",
            " #4     | RandomForest              | 96.7888%     | 3.2112%       | 0.8644\n",
            " #5     | ** TITAN INF (Ours) **    | 96.4722%     | 3.5278%       | 42.4249\n",
            "====================================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TITAN_VS_GOLIATHS(1479, \"Hill Valley\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef6c4JDcImsr",
        "outputId": "420f6021-cc1f-46bb-a19e-d7e670dd9079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            " >>> PARADIGM SHIFT PROTOCOL: HILL VALLEY (ID: 1479)\n",
            " >>> OBJECTIVE: Demonstrate Superiority of Infinite Memory over Static Models\n",
            "====================================================================================================\n",
            " > [SYSTEM] Establishing Neural Link to OpenML (ID: 1479)...\n",
            " > [SYSTEM] Data Downloaded in 0.04s. Parsing Structure...\n",
            " > [SYSTEM] Dimensions Detected: (1212, 100). Normalizing entropy...\n",
            " > [SYSTEM] Scaling Geometries (Standard + Quantile)...\n",
            " > [SYSTEM] Data Ready. Entering The Arena.\n",
            "\n",
            " >>> PHASE 1: STATIC MODEL EVALUATION (THE OLD GUARD)\n",
            " --------------------------------------------------------------------------------\n",
            "  > [COMPLETED] XGBoost          | Accuracy: 53.0864% | Time: 1.14s\n",
            "  > [COMPLETED] LightGBM         | Accuracy: 59.2593% | Time: 1.35s\n",
            "  > [COMPLETED] ExtraTrees       | Accuracy: 58.0247% | Time: 0.55s\n",
            "  > [COMPLETED] RandomForest     | Accuracy: 55.9671% | Time: 2.16s\n",
            "\n",
            " >>> PHASE 2: TITAN INF AWAKENING (THE NEW PARADIGM)\n",
            " > [TITAN] Creating Oracle Holdout Layer (80/20 Split)...\n",
            " > [G.O.D. PROTOCOL] Initiating Host Selection Tournament...\n",
            "   [SCAR] XGBoost      | Score: 51.8710%\n",
            "   [SCAR] ExtraTrees   | Score: 58.8387%\n",
            "   [SCAR] RandomForest | Score: 56.1290%\n",
            "   [SCAR] LGBM         | Score: 55.4839%\n",
            " > [VICTORY] Champion Selected: EXTRATREES (Base Acc: 58.8387%)\n",
            " > [TITAN] Assimilating ExtraTreesClassifier...\n",
            " > [TITAN] Generating Holographic Residuals...\n",
            "   [ORACLE] Initial True Accuracy: 60.3093%\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.18s.\n",
            "   [SCANNER] Resonance Detected: 'MISH' (Fit Score: 0.2499)\n",
            "   [EVOLVE] Cycle 1: GENUINE IMPROVEMENT -> Oracle Acc: 60.8247% (Func: mish)\n",
            "   [FIGHTING] Cycle 6: Stagnant. (Patience 5/20)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.09s.\n",
            "   [SCANNER] Resonance Detected: 'MISH' (Fit Score: 0.2499)\n",
            "   [FIGHTING] Cycle 11: Stagnant. (Patience 10/20)\n",
            "   [FIGHTING] Cycle 16: Stagnant. (Patience 15/20)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.09s.\n",
            "   [SCANNER] Resonance Detected: 'MISH' (Fit Score: 0.2499)\n",
            "   [FIGHTING] Cycle 21: Stagnant. (Patience 20/20)\n",
            "   [STOP] Evolution halted. Oracle has spoken.\n",
            "   [TITAN] Evolution Complete. Total Memory Units: 1. Final Oracle Acc: 60.8247%\n",
            "\n",
            "====================================================================================================\n",
            " >>> FINAL INTELLIGENCE REPORT: Hill Valley\n",
            "====================================================================================================\n",
            "RANK   | MODEL ARCHITECTURE        | ACCURACY     | ERROR RATE   | TIME (s)  \n",
            "----------------------------------------------------------------------------------------------------\n",
            " #1     | LightGBM                  | 59.2593%     | 40.7407%       | 1.3494\n",
            " #2     | ExtraTrees                | 58.0247%     | 41.9753%       | 0.5458\n",
            " #3     | RandomForest              | 55.9671%     | 44.0329%       | 2.1647\n",
            " #4     | ** TITAN INF (Ours) **    | 55.9671%     | 44.0329%       | 61.9889\n",
            " #5     | XGBoost                   | 53.0864%     | 46.9136%       | 1.1413\n",
            "====================================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TITAN_VS_GOLIATHS(40499, \"Texture Analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCiCLH-9gjvl",
        "outputId": "cd464701-a620-4f65-c80f-21a41457e3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            " >>> PARADIGM SHIFT PROTOCOL: TEXTURE ANALYSIS (ID: 40499)\n",
            " >>> OBJECTIVE: Demonstrate Superiority of Infinite Memory over Static Models\n",
            "====================================================================================================\n",
            "\n",
            " >>> PHASE 1: STATIC MODEL EVALUATION (THE OLD GUARD)\n",
            " --------------------------------------------------------------------------------\n",
            "\n",
            " >>> PHASE 2: TITAN INF AWAKENING (THE NEW PARADIGM)\n",
            " > [G.O.D. PROTOCOL] Initiating Host Selection Tournament...\n",
            "   [SCAR] XGBoost      | Score: 97.9091%\n",
            "   [SCAR] LightGBM     | Score: 98.3182%\n",
            "   [SCAR] ExtraTrees   | Score: 98.2273%\n",
            "   [SCAR] RandomForest | Score: 97.5455%\n",
            "   [SCAR] SVM (RBF)    | Score: 99.0682%\n",
            "   [SCAR] KNN (k=5)    | Score: 97.9545%\n",
            "   [SCAR] LogisticReg  | Score: 98.9773%\n",
            "   [SCAR] LDA          | Score: 98.8182%\n",
            "   [SCAR] QDA          | Score: 13.6136%\n",
            " > [VICTORY] Champion Selected: SVM (RBF) (Base Acc: 99.0682%)\n",
            " > [TITAN] Assimilating SVC...\n",
            " > [TITAN] Generating Holographic Residuals (5-Fold CV)...\n",
            "   [BASE] Holographic Accuracy: 99.0000%\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.28s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_0.2' (Fit Score: 0.0525)\n",
            "   [EVOLVE] Cycle 1: IMPROVEMENT -> Acc: 99.0455%\n",
            "   [EVOLVE] Cycle 2: IMPROVEMENT -> Acc: 99.0909%\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.18s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_0.2' (Fit Score: 0.0512)\n",
            "   [FIGHTING] Cycle 5: Stagnant. (Patience 3/30)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.15s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_0.2' (Fit Score: 0.0512)\n",
            "   [FIGHTING] Cycle 10: Stagnant. (Patience 8/30)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.16s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_0.2' (Fit Score: 0.0512)\n",
            "   [FIGHTING] Cycle 15: Stagnant. (Patience 13/30)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.15s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_0.2' (Fit Score: 0.0512)\n",
            "   [FIGHTING] Cycle 20: Stagnant. (Patience 18/30)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.15s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_0.2' (Fit Score: 0.0512)\n",
            "   [FIGHTING] Cycle 25: Stagnant. (Patience 23/30)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.18s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_0.2' (Fit Score: 0.0512)\n",
            "   [FIGHTING] Cycle 30: Stagnant. (Patience 28/30)\n",
            "   [STOP] Evolution halted. No improvement for 30 cycles.\n",
            "   [TITAN] Evolution Complete. Total Memory Units: 2. Final Training Acc: 99.0909%\n",
            "\n",
            "====================================================================================================\n",
            " >>> FINAL INTELLIGENCE REPORT: Texture Analysis\n",
            "====================================================================================================\n",
            "RANK   | MODEL ARCHITECTURE        | ACCURACY     | ERROR RATE   | TIME (s)  \n",
            "----------------------------------------------------------------------------------------------------\n",
            " #1     | ** TITAN INF (Ours) **    | 99.2727%     | 0.7273%       | 146.5466\n",
            "====================================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TITAN_VS_GOLIATHS(1471, \"EEG Eye State\")"
      ],
      "metadata": {
        "id": "QacX3uREgn4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75646614-f6ef-4bdd-d6b9-c0fc09fb8562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            " >>> PARADIGM SHIFT PROTOCOL: EEG EYE STATE (ID: 1471)\n",
            " >>> OBJECTIVE: Demonstrate Superiority of Infinite Memory over Static Models\n",
            "====================================================================================================\n",
            " > [SYSTEM] Establishing Neural Link to OpenML (ID: 1471)...\n",
            " > [SYSTEM] Data Downloaded in 2.96s. Parsing Structure...\n",
            " > [SYSTEM] Dimensions Detected: (14980, 14). Normalizing entropy...\n",
            " > [SYSTEM] Scaling Geometries (Standard + Quantile)...\n",
            " > [SYSTEM] Data Ready. Entering The Arena.\n",
            "\n",
            " >>> PHASE 1: STATIC MODEL EVALUATION (THE OLD GUARD)\n",
            " --------------------------------------------------------------------------------\n",
            "  > [COMPLETED] XGBoost          | Accuracy: 94.1923% | Time: 0.44s\n",
            "  > [COMPLETED] LightGBM         | Accuracy: 92.4566% | Time: 0.44s\n",
            "  > [COMPLETED] ExtraTrees       | Accuracy: 94.6929% | Time: 1.95s\n",
            "  > [COMPLETED] RandomForest     | Accuracy: 92.3565% | Time: 3.96s\n",
            "\n",
            " >>> PHASE 2: TITAN INF AWAKENING (THE NEW PARADIGM)\n",
            " > [TITAN] Summoning The Council (Layer 1)...\n",
            "   [LAYER 1] Training RF...\n",
            "   [LAYER 1] Training ET...\n",
            "   [LAYER 1] Training XGB...\n",
            " > [TITAN] Synthesizing Meta-Dimensions (Geometry)...\n",
            "   [LAYER 2] Dimension Expansion: 6 -> 21 Synaptic Pathways.\n",
            " > [TITAN] Training The Singularity (Meta-Cortex)...\n",
            " > [TITAN] System Integrity (Judge Acc): 94.1594%\n",
            " > [OMEGA] Optimizing Synaptic Weights...\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.20s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_5.3' (Fit Score: 0.4087)\n",
            "   [STOP] Cortex Stable. No Expansion Needed.\n",
            "\n",
            "====================================================================================================\n",
            " >>> FINAL INTELLIGENCE REPORT: EEG Eye State\n",
            "====================================================================================================\n",
            "RANK   | MODEL ARCHITECTURE        | ACCURACY     | ERROR RATE   | TIME (s)  \n",
            "----------------------------------------------------------------------------------------------------\n",
            " #1     | ExtraTrees                | 94.6929%     | 5.3071%       | 1.9494\n",
            " #2     | ** TITAN INF (Ours) **    | 94.5260%     | 5.4740%       | 54.9689\n",
            " #3     | XGBoost                   | 94.1923%     | 5.8077%       | 0.4387\n",
            " #4     | LightGBM                  | 92.4566%     | 7.5434%       | 0.4425\n",
            " #5     | RandomForest              | 92.3565%     | 7.6435%       | 3.9621\n",
            "====================================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TITAN_VS_GOLIATHS(1489, \"Phoneme Acoustics\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BAhfPNfTQPk",
        "outputId": "0b72d5cb-f964-46cf-dbc8-f3a17be97bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            " >>> PARADIGM SHIFT PROTOCOL: PHONEME ACOUSTICS (ID: 1489)\n",
            " >>> OBJECTIVE: Demonstrate Superiority of Infinite Memory over Static Models\n",
            "====================================================================================================\n",
            " > [SYSTEM] Establishing Neural Link to OpenML (ID: 1489)...\n",
            " > [SYSTEM] Data Downloaded in 0.02s. Parsing Structure...\n",
            " > [SYSTEM] Dimensions Detected: (5404, 5). Normalizing entropy...\n",
            " > [SYSTEM] Scaling Geometries (Standard + Quantile)...\n",
            " > [SYSTEM] Data Ready. Entering The Arena.\n",
            "\n",
            " >>> PHASE 1: STATIC MODEL EVALUATION (THE OLD GUARD)\n",
            " --------------------------------------------------------------------------------\n",
            "  > [COMPLETED] XGBoost          | Accuracy: 90.9343% | Time: 0.22s\n",
            "  > [COMPLETED] LightGBM         | Accuracy: 90.0093% | Time: 0.17s\n",
            "  > [COMPLETED] ExtraTrees       | Accuracy: 91.0268% | Time: 0.61s\n",
            "  > [COMPLETED] RandomForest     | Accuracy: 90.9343% | Time: 1.57s\n",
            "\n",
            " >>> PHASE 2: TITAN INF AWAKENING (THE NEW PARADIGM)\n",
            " > [G.O.D. PROTOCOL] Initiating Host Selection Tournament...\n",
            "   [SCAR] XGBoost      | Score: 89.3361%\n",
            "   [SCAR] LightGBM     | Score: 88.4571%\n",
            "   [SCAR] ExtraTrees   | Score: 89.9838%\n",
            "   [SCAR] RandomForest | Score: 89.7525%\n",
            "   [SCAR] SVM (RBF)    | Score: 83.7613%\n",
            "   [SCAR] LogisticReg  | Score: 73.1668%\n",
            " > [VICTORY] Champion Selected: EXTRATREES (Base Acc: 89.9838%)\n",
            " > [TITAN] Assimilating ExtraTreesClassifier on FULL Data...\n",
            " > [TITAN] Generating Truth Residuals via Cross-Validation...\n",
            " > [TITAN] Base Accuracy on Judge Set: 88.5549%\n",
            " > [OMEGA] Evolution Strategy: Improving Judge Accuracy (Target: >88.5549%)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 3.70s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_2.8' (Fit Score: 0.0229)\n",
            "   [EVOLVE] Cycle 1: VALIDATED IMPROVEMENT! Judge Acc: 88.6705% (+0.1156%)\n",
            "   [EVOLVE] Cycle 2: VALIDATED IMPROVEMENT! Judge Acc: 88.7861% (+0.1156%)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.13s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_2.8' (Fit Score: 0.0229)\n",
            "   [STAGNANT] Cycle 7: No gain on Judge set. (Patience 5)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.13s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_2.8' (Fit Score: 0.0229)\n",
            "   [STAGNANT] Cycle 12: No gain on Judge set. (Patience 10)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.13s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_2.8' (Fit Score: 0.0229)\n",
            "   [STAGNANT] Cycle 17: No gain on Judge set. (Patience 15)\n",
            "   [SCANNER] Testing 95 Quantum Activation Functions... Done in 0.13s.\n",
            "   [SCANNER] Resonance Detected: 'FINE_SIN_2.8' (Fit Score: 0.0229)\n",
            "   [STAGNANT] Cycle 22: No gain on Judge set. (Patience 20)\n",
            "   [STOP] Judge Accuracy plateaued. Stopping Evolution.\n",
            " > [TITAN] Evolution Complete. Final Judge Acc: 88.7861% (Units: 2)\n",
            "\n",
            "====================================================================================================\n",
            " >>> FINAL INTELLIGENCE REPORT: Phoneme Acoustics\n",
            "====================================================================================================\n",
            "RANK   | MODEL ARCHITECTURE        | ACCURACY     | ERROR RATE   | TIME (s)  \n",
            "----------------------------------------------------------------------------------------------------\n",
            " #1     | ** TITAN INF (Ours) **    | 91.6744%     | 8.3256%       | 31.1262\n",
            " #2     | ExtraTrees                | 91.0268%     | 8.9732%       | 0.6139\n",
            " #3     | XGBoost                   | 90.9343%     | 9.0657%       | 0.2171\n",
            " #4     | RandomForest              | 90.9343%     | 9.0657%       | 1.5653\n",
            " #5     | LightGBM                  | 90.0093%     | 9.9907%       | 0.1676\n",
            "====================================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TITAN_VS_GOLIATHS(1120, \"Magic Gamma Telescope\")"
      ],
      "metadata": {
        "id": "LXlYBARsjfle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TITAN_VS_GOLIATHS(151, \"Electricity Grid Stability\")"
      ],
      "metadata": {
        "id": "4v5RUQNziDv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fijXLIPIj5-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sSJf65dYiDql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPomesDbiDj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import warnings\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.preprocessing import QuantileTransformer, LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "\n",
        "# --- COMPETITORS ---\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    from lightgbm import LGBMClassifier\n",
        "except ImportError:\n",
        "    print(\">>> [WARNING] XGBoost or LightGBM not installed. Benchmarks will be limited.\")\n",
        "\n",
        "# --- GPU ACTIVATION ---\n",
        "try:\n",
        "    import cupy as cp\n",
        "    print(\">>> [TITAN PROTOCOL] T4 GPU DETECTED. INFINITE MEMORY ENGINE ONLINE.\")\n",
        "    cp.random.seed(42)\n",
        "    GPU_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\">>> [FATAL] GPU REQUIRED FOR TITAN.\")\n",
        "    sys.exit()\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. THE MEMORY UNIT (The Synapse)\n",
        "# ==========================================\n",
        "class MEMORY_UNIT:\n",
        "    def __init__(self, n_neurons, input_dim, seed, activation_func):\n",
        "        cp.random.seed(seed)\n",
        "        self.n_neurons = n_neurons\n",
        "        self.activation = activation_func\n",
        "        self.scaling_factor = 1.0\n",
        "\n",
        "        self.W_in = cp.random.uniform(-1.0, 1.0, (n_neurons, input_dim)).astype(cp.float32)\n",
        "        self.W_cortex = cp.random.normal(0, 1.0 / np.sqrt(n_neurons), (n_neurons, n_neurons)).astype(cp.float32)\n",
        "\n",
        "        # Spectral stabilizer\n",
        "        try:\n",
        "            v = cp.random.randn(n_neurons)\n",
        "            for _ in range(5):\n",
        "                v = self.W_cortex @ v\n",
        "                v = v / cp.linalg.norm(v)\n",
        "            max_eig = cp.linalg.norm(self.W_cortex @ v)\n",
        "            if max_eig > 0: self.W_cortex /= max_eig\n",
        "        except: pass\n",
        "        self.readout = None\n",
        "\n",
        "    def process(self, X_gpu):\n",
        "        state = cp.zeros((X_gpu.shape[0], self.n_neurons), dtype=cp.float32)\n",
        "        for _ in range(5):\n",
        "            pre = (X_gpu @ self.W_in.T) + (state @ self.W_cortex.T)\n",
        "            state = self.activation(pre)\n",
        "        return state\n",
        "\n",
        "    def fit_residual(self, X_gpu, Residual_gpu, alpha=10.0):\n",
        "        H = self.process(X_gpu)\n",
        "        I = cp.eye(self.n_neurons, dtype=cp.float32)\n",
        "        self.readout = cp.linalg.solve(H.T @ H + alpha*I, H.T @ Residual_gpu)\n",
        "\n",
        "    def predict_correction(self, X_gpu):\n",
        "        H = self.process(X_gpu)\n",
        "        return H @ self.readout\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 2. THE RESONANCE SCANNER (God's Eye)\n",
        "# ==========================================\n",
        "class RESONANCE_SCANNER:\n",
        "    def __init__(self):\n",
        "        self.activations = {}\n",
        "        self._generate_100_functions()\n",
        "\n",
        "    def _generate_100_functions(self):\n",
        "        # 1. Standard Activations\n",
        "        self.activations['tanh'] = lambda x: cp.tanh(x)\n",
        "        self.activations['relu'] = lambda x: cp.maximum(0, x)\n",
        "        self.activations['sigmoid'] = lambda x: 1 / (1 + cp.exp(-x))\n",
        "        self.activations['swish'] = lambda x: x * (1 / (1 + cp.exp(-x)))\n",
        "        self.activations['mish'] = lambda x: x * cp.tanh(cp.log(1 + cp.exp(x)))\n",
        "\n",
        "        # 2. Harmonic Series (The \"Siren\" Frequencies)\n",
        "        for freq in [0.5, 1.0, 1.5, 2.0, 3.0, 5.0, 8.0, 13.0, 21.0, 34.0, 55.0]:\n",
        "            self.activations[f'sin_omega_{freq}'] = lambda x, f=freq: cp.sin(f * x)\n",
        "            self.activations[f'cos_omega_{freq}'] = lambda x, f=freq: cp.cos(f * x)\n",
        "\n",
        "        # 3. Gaussian Kernels\n",
        "        for sigma in [0.1, 0.5, 1.0, 2.0, 5.0]:\n",
        "            self.activations[f'gaussian_{sigma}'] = lambda x, s=sigma: cp.exp(-cp.square(x) / (2 * s**2))\n",
        "\n",
        "        # 4. Hybrid & Exotic\n",
        "        self.activations['sinc'] = lambda x: cp.sin(x) / (x + 1e-6)\n",
        "        self.activations['morlet'] = lambda x: cp.cos(5*x) * cp.exp(-x**2/2)\n",
        "        self.activations['x_sin_x'] = lambda x: x * cp.sin(x)\n",
        "        self.activations['sin_tanh'] = lambda x: cp.sin(cp.tanh(x))\n",
        "\n",
        "        # Fine-tuned bands\n",
        "        for i in range(1, 40):\n",
        "            f = 0.1 * i\n",
        "            self.activations[f'fine_sin_{f:.1f}'] = lambda x, freq=f: cp.sin(freq * x)\n",
        "\n",
        "    def scan(self, X_gpu, Residual_gpu, n_neurons=100):\n",
        "        best_name = \"tanh\"\n",
        "        best_score = -np.inf\n",
        "        cp.random.seed(42)\n",
        "        W_probe = cp.random.uniform(-1.0, 1.0, (n_neurons, X_gpu.shape[1])).astype(cp.float32)\n",
        "        Projected_X = X_gpu @ W_probe.T\n",
        "\n",
        "        print(f\"   [SCANNER] Testing {len(self.activations)} Quantum Activation Functions...\", end=\"\")\n",
        "        start = time.time()\n",
        "\n",
        "        for name, func in self.activations.items():\n",
        "            try:\n",
        "                H = func(Projected_X)\n",
        "                I = cp.eye(n_neurons, dtype=cp.float32)\n",
        "                w_out = cp.linalg.solve(H.T @ H + 1.0*I, H.T @ Residual_gpu)\n",
        "                pred = H @ w_out\n",
        "                error_norm = cp.linalg.norm(Residual_gpu - pred)\n",
        "                total_norm = cp.linalg.norm(Residual_gpu)\n",
        "                score = 1.0 - (error_norm / total_norm)\n",
        "\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_name = name\n",
        "            except: continue\n",
        "\n",
        "        elapsed = time.time() - start\n",
        "        print(f\" Done in {elapsed:.2f}s.\")\n",
        "        print(f\"   [SCANNER] Resonance Detected: '{best_name.upper()}' (Fit Score: {best_score:.4f})\")\n",
        "        return best_name, self.activations[best_name]\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 3. TITAN GLASS (The Edge Case Sniper)\n",
        "# ==========================================\n",
        "class TITAN_GLASS:\n",
        "    def __init__(self, input_dim, n_classes, mirror_dim=4096):\n",
        "        self.input_dim = input_dim\n",
        "        self.n_classes = n_classes\n",
        "        self.mirror_dim = mirror_dim\n",
        "        self.W_mirror = None\n",
        "        self.readout = None\n",
        "\n",
        "    def fit(self, X_gpu, current_probs_gpu, Residual_gpu, y_gpu):\n",
        "        \"\"\"\n",
        "        Learns to correct ONLY the samples where the Base + Memory Vault failed.\n",
        "        \"\"\"\n",
        "        print(f\" > [TITAN GLASS] Focusing Infinite Mirrors on Edge Cases (Dim: {self.mirror_dim})...\")\n",
        "\n",
        "        # 1. IDENTIFY THE MISTAKES\n",
        "        # We look at where the current 'Best' prediction disagrees with Reality\n",
        "        current_preds = cp.argmax(current_probs_gpu, axis=1)\n",
        "        mistakes_mask = (current_preds != y_gpu)\n",
        "        n_mistakes = cp.sum(mistakes_mask).item()\n",
        "\n",
        "        print(f\"   [GLASS] Detected {n_mistakes} Stubborn Edge Cases in Training Data.\")\n",
        "\n",
        "        if n_mistakes == 0:\n",
        "            print(f\"   [GLASS] Zero errors detected. The Reflection is unnecessary.\")\n",
        "            return\n",
        "\n",
        "        # 2. GENERATE FOCUS WEIGHTS\n",
        "        # We tell the math solver: \"Paying attention to a MISTAKE is 50x more important\"\n",
        "        n_samples = X_gpu.shape[0]\n",
        "        weights = cp.ones(n_samples, dtype=cp.float32)\n",
        "        weights[mistakes_mask] = 50.0\n",
        "\n",
        "        # Square root of weights for the Linear Algebra trick\n",
        "        sqrt_W = cp.sqrt(weights)[:, None] # Shape (N, 1)\n",
        "\n",
        "        # 3. PROJECT INTO INFINITE DIMENSIONS\n",
        "        cp.random.seed(1337)\n",
        "        total_in_dim = self.input_dim + self.n_classes\n",
        "        self.W_mirror = cp.random.normal(0, 1.0 / np.sqrt(self.mirror_dim),\n",
        "                                       (self.mirror_dim, total_in_dim)).astype(cp.float32)\n",
        "\n",
        "        Combined_State = cp.hstack([X_gpu, current_probs_gpu])\n",
        "\n",
        "        # 4. APPLY SIREN ACTIVATION (High Frequency)\n",
        "        Projection = Combined_State @ self.W_mirror.T\n",
        "        H = cp.sin(Projection)\n",
        "\n",
        "        # 5. WEIGHTED RIDGE REGRESSION\n",
        "        H_weighted = H * sqrt_W\n",
        "        Residual_weighted = Residual_gpu * sqrt_W\n",
        "\n",
        "        alpha = 10.0\n",
        "        I = cp.eye(self.mirror_dim, dtype=cp.float32)\n",
        "\n",
        "        try:\n",
        "            self.readout = cp.linalg.solve(H_weighted.T @ H_weighted + alpha*I, H_weighted.T @ Residual_weighted)\n",
        "            print(f\"   [TITAN GLASS] Mirrors Aligned. Focus applied to {n_mistakes} samples.\")\n",
        "        except:\n",
        "            print(\"   [TITAN GLASS] Singularity. Bypassing.\")\n",
        "            self.readout = None\n",
        "\n",
        "    def reflect(self, X_gpu, current_probs_gpu):\n",
        "        if self.readout is None:\n",
        "            return 0.0\n",
        "\n",
        "        Combined_State = cp.hstack([X_gpu, current_probs_gpu])\n",
        "        Projection = Combined_State @ self.W_mirror.T\n",
        "        H = cp.sin(Projection)\n",
        "        return H @ self.readout\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 4. TITAN INF (The Unified Intelligence)\n",
        "# ==========================================\n",
        "class TITAN_INF(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self):\n",
        "        self.memory_vault = []\n",
        "        self.base_model = None\n",
        "        self.glass = None\n",
        "        self.input_dim = 0\n",
        "        self.n_classes = 0\n",
        "        self.scanner = None\n",
        "\n",
        "    def _compress_vault(self, X_gpu, batch_size=100):\n",
        "        if len(self.memory_vault) < batch_size * 2: return\n",
        "        print(f\"   [TITAN] Compressing Memory Vault (Distilling {batch_size} units)...\")\n",
        "        units_to_compress = self.memory_vault[:batch_size]\n",
        "        remaining_units = self.memory_vault[batch_size:]\n",
        "        total_correction = cp.zeros((X_gpu.shape[0], self.n_classes), dtype=cp.float32)\n",
        "        for unit in units_to_compress:\n",
        "            pred = unit.predict_correction(X_gpu)\n",
        "            total_correction += pred * unit.scaling_factor\n",
        "        super_unit = MEMORY_UNIT(n_neurons=3000, input_dim=self.input_dim, seed=42, activation_func=cp.tanh)\n",
        "        super_unit.fit_residual(X_gpu, total_correction, alpha=1.0)\n",
        "        super_unit.scaling_factor = 1.0\n",
        "        self.memory_vault = [super_unit] + remaining_units\n",
        "        print(f\"   [TITAN] Compression Complete. Vault Size: {len(self.memory_vault)}\")\n",
        "\n",
        "    def _tournament_selection(self, X, y):\n",
        "        print(f\" > [G.O.D. PROTOCOL] Initiating Host Selection Tournament...\")\n",
        "        competitors = [\n",
        "            (\"XGBoost\", XGBClassifier(n_estimators=200, use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)),\n",
        "            (\"LightGBM\", LGBMClassifier(n_estimators=200, random_state=42, verbosity=-1, n_jobs=-1)),\n",
        "            (\"ExtraTrees\", ExtraTreesClassifier(n_estimators=200, n_jobs=-1, random_state=42)),\n",
        "            (\"RandomForest\", RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)),\n",
        "            (\"SVM (RBF)\", SVC(probability=True, kernel='rbf', random_state=42)),\n",
        "            (\"KNN (k=5)\", KNeighborsClassifier(n_neighbors=5, n_jobs=-1)),\n",
        "            (\"LogisticReg\", LogisticRegression(max_iter=1000, n_jobs=-1)),\n",
        "            (\"LDA\", LinearDiscriminantAnalysis()),\n",
        "            (\"QDA\", QuadraticDiscriminantAnalysis()),\n",
        "        ]\n",
        "        best_name, best_score, best_model = \"None\", -1.0, None\n",
        "        for name, model in competitors:\n",
        "            try:\n",
        "                score = np.mean(cross_val_score(model, X, y, cv=5, scoring='accuracy', n_jobs=-1))\n",
        "                print(f\"   [SCAR] {name:<12} | Score: {score:.4%}\")\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_name = name\n",
        "                    best_model = model\n",
        "            except: pass\n",
        "        print(f\" > [VICTORY] Champion Selected: {best_name.upper()} (Base Acc: {best_score:.4%})\")\n",
        "        return best_model\n",
        "\n",
        "    def perceive(self, X, y):\n",
        "        self.input_dim = X.shape[1]\n",
        "        self.n_classes = len(np.unique(y))\n",
        "\n",
        "        # 1. Host Selection\n",
        "        self.base_model = self._tournament_selection(X, y)\n",
        "        print(f\" > [TITAN] Assimilating {self.base_model.__class__.__name__}...\")\n",
        "        self.base_model.fit(X, y)\n",
        "\n",
        "        # 2. Residual Generation\n",
        "        print(f\" > [TITAN] Generating Holographic Residuals (5-Fold CV)...\")\n",
        "        try:\n",
        "            cv_probs = cross_val_predict(self.base_model, X, y, cv=5, method='predict_proba', n_jobs=-1)\n",
        "        except:\n",
        "            print(\"   [WARNING] CV Failed. Fallback to OOB residuals.\")\n",
        "            self.base_model.fit(X, y)\n",
        "            cv_probs = self.base_model.predict_proba(X)\n",
        "\n",
        "        # 3. Evolution Loop\n",
        "        self._fit_evolution(X, y, cv_probs)\n",
        "\n",
        "    def _fit_evolution(self, X, y, base_probs):\n",
        "        X_gpu = cp.asarray(X, dtype=cp.float32)\n",
        "        y_gpu = cp.asarray(y)\n",
        "        current_probs = base_probs\n",
        "        current_logits = cp.asarray(np.log(current_probs + 1e-9))\n",
        "\n",
        "        # Label Smoothing Target\n",
        "        smooth_factor = 0.01\n",
        "        Y_target = cp.zeros((len(y), self.n_classes), dtype=cp.float32) + (smooth_factor / self.n_classes)\n",
        "        for i in range(self.n_classes):\n",
        "            Y_target[y_gpu==i, i] = 1.0 - smooth_factor\n",
        "\n",
        "        best_acc = accuracy_score(y, np.argmax(base_probs, axis=1))\n",
        "        print(f\"   [BASE] Holographic Accuracy: {best_acc:.4%}\")\n",
        "\n",
        "        self.scanner = RESONANCE_SCANNER()\n",
        "        cycle = 0\n",
        "        patience = 0\n",
        "        patience_limit = 30\n",
        "        max_units = 100000\n",
        "\n",
        "        # --- THE OMEGA LOOP ---\n",
        "        while cycle < max_units:\n",
        "            cycle += 1\n",
        "            probs = cp.exp(current_logits) / cp.sum(cp.exp(current_logits), axis=1, keepdims=True)\n",
        "            residual = Y_target - probs\n",
        "\n",
        "            if cycle == 1 or cycle % 5 == 0:\n",
        "                best_af_name, best_af_func = self.scanner.scan(X_gpu, residual)\n",
        "\n",
        "            # HYPER-MUTATION\n",
        "            best_unit_cycle = None\n",
        "            best_acc_cycle = -1\n",
        "            best_logits_cycle = None\n",
        "\n",
        "            for _ in range(10): # 10 Mutations per cycle\n",
        "                n_neurons = np.random.randint(500, 3000)\n",
        "                alpha = 10 ** np.random.uniform(-1, 4)\n",
        "                seed = np.random.randint(0, 100000) + cycle\n",
        "\n",
        "                unit = MEMORY_UNIT(n_neurons, self.input_dim, seed, best_af_func)\n",
        "                unit.fit_residual(X_gpu, residual, alpha=alpha)\n",
        "\n",
        "                correction = unit.predict_correction(X_gpu)\n",
        "                lr = 0.1 / (1 + (cycle * 0.01))\n",
        "\n",
        "                temp_logits = current_logits + (correction * lr)\n",
        "                temp_preds = cp.asnumpy(cp.argmax(temp_logits, axis=1))\n",
        "                temp_acc = accuracy_score(y, temp_preds)\n",
        "\n",
        "                if temp_acc > best_acc_cycle:\n",
        "                    best_acc_cycle = temp_acc\n",
        "                    best_unit_cycle = unit\n",
        "                    best_logits_cycle = temp_logits\n",
        "\n",
        "            if best_acc_cycle > best_acc:\n",
        "                best_unit_cycle.scaling_factor = 0.1 / (1 + (cycle * 0.01))\n",
        "                self.memory_vault.append(best_unit_cycle)\n",
        "                current_logits = best_logits_cycle\n",
        "                best_acc = best_acc_cycle\n",
        "                patience = 0\n",
        "                print(f\"   [EVOLVE] Cycle {cycle}: IMPROVEMENT -> Acc: {best_acc:.4%}\")\n",
        "\n",
        "                if len(self.memory_vault) % 100 == 0:\n",
        "                    self._compress_vault(X_gpu, batch_size=50)\n",
        "            else:\n",
        "                patience += 1\n",
        "                if cycle % 5 == 0:\n",
        "                    print(f\"   [FIGHTING] Cycle {cycle}: Stagnant. (Patience {patience}/{patience_limit})\")\n",
        "\n",
        "                if patience >= patience_limit:\n",
        "                    print(f\"   [STOP] Evolution halted. No improvement for {patience_limit} cycles.\")\n",
        "                    break\n",
        "\n",
        "            if best_acc >= 0.9999:\n",
        "                print(\"   [GOD MODE] Perfect Accuracy Achieved. Stopping.\")\n",
        "                break\n",
        "\n",
        "        # --- PHASE 3: TITAN GLASS ACTIVATION ---\n",
        "        # Recalculate Final State for the Mirror\n",
        "        final_probs = cp.exp(current_logits) / cp.sum(cp.exp(current_logits), axis=1, keepdims=True)\n",
        "        final_residual = Y_target - final_probs\n",
        "\n",
        "        self.glass = TITAN_GLASS(self.input_dim, self.n_classes, mirror_dim=4096)\n",
        "        # *** FIX: PASSING y_gpu HERE ***\n",
        "        self.glass.fit(X_gpu, final_probs, final_residual, y_gpu)\n",
        "\n",
        "        print(f\"   [TITAN] Evolution Complete. Total Memory Units: {len(self.memory_vault)}. Final Training Acc: {best_acc:.4%}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        # 1. Base Prediction\n",
        "        base_probs = self.base_model.predict_proba(X)\n",
        "        current_logits = cp.asarray(np.log(base_probs + 1e-9))\n",
        "        X_gpu = cp.asarray(X, dtype=cp.float32)\n",
        "\n",
        "        # 2. Memory Vault Correction\n",
        "        for unit in self.memory_vault:\n",
        "            correction = unit.predict_correction(X_gpu)\n",
        "            current_logits += (correction * unit.scaling_factor)\n",
        "\n",
        "        # 3. TITAN GLASS Correction (The Final Reflection)\n",
        "        current_probs = cp.exp(current_logits) / cp.sum(cp.exp(current_logits), axis=1, keepdims=True)\n",
        "\n",
        "        if self.glass is not None:\n",
        "            reflection = self.glass.reflect(X_gpu, current_probs)\n",
        "            current_logits += reflection\n",
        "\n",
        "        return cp.asnumpy(cp.argmax(current_logits, axis=1))\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 5. THE ARENA ENGINE\n",
        "# ==========================================\n",
        "def TITAN_VS_GOLIATHS(data_id, name):\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\" >>> PARADIGM SHIFT PROTOCOL: {name.upper()} (ID: {data_id})\")\n",
        "    print(f\" >>> OBJECTIVE: Prove Superiority of Infinite Reflection & Memory\")\n",
        "    print(f\"{'='*100}\")\n",
        "\n",
        "    # 1. SUMMON DATA\n",
        "    try:\n",
        "        data = fetch_openml(data_id=data_id, as_frame=True, parser='auto')\n",
        "        X_raw = data.data\n",
        "        y_raw = data.target\n",
        "        if X_raw.isnull().values.any(): X_raw = X_raw.fillna(0)\n",
        "        le = LabelEncoder()\n",
        "        y = le.fit_transform(y_raw)\n",
        "        X = X_raw.values.astype(np.float32) if hasattr(X_raw, 'values') else X_raw.astype(np.float32)\n",
        "\n",
        "        scaler_std = StandardScaler()\n",
        "        X_std = scaler_std.fit_transform(X)\n",
        "\n",
        "        scaler_qt = QuantileTransformer(output_distribution='normal', random_state=42, n_quantiles=min(1000, len(X)))\n",
        "        X_qt = scaler_qt.fit_transform(X)\n",
        "\n",
        "        X_train_std, X_test_std, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=42)\n",
        "        X_train_qt, X_test_qt, _, _ = train_test_split(X_qt, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" [ERROR] Data Summon Failed: {e}\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # 2. STATIC MODEL BENCHMARKS\n",
        "    print(\"\\n >>> PHASE 1: STATIC MODEL EVALUATION\")\n",
        "    print(f\" {'-'*80}\")\n",
        "    competitors = [\n",
        "      # (\"RandomForest\", RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "       #(\"ExtraTrees\", ExtraTreesClassifier(n_estimators=100, random_state=42)),\n",
        "      # (\"XGBoost\", XGBClassifier(n_estimators=100, eval_metric='logloss', random_state=42))\n",
        "    ]\n",
        "\n",
        "    for model_name, model in competitors:\n",
        "        start_time = time.time()\n",
        "        try:\n",
        "            model.fit(X_train_std, y_train)\n",
        "            preds = model.predict(X_test_std)\n",
        "            acc = accuracy_score(y_test, preds)\n",
        "            elapsed = time.time() - start_time\n",
        "            results.append({\"Model\": model_name, \"Accuracy\": acc, \"Time\": elapsed})\n",
        "            print(f\"  > {model_name:<16} | Acc: {acc:.4%} | Time: {elapsed:.2f}s\")\n",
        "        except Exception as e:\n",
        "            print(f\"  > {model_name:<16} | Error: {e}\")\n",
        "\n",
        "    # 3. TITAN EVOLUTION\n",
        "    print(\"\\n >>> PHASE 2: TITAN INF (EVOLUTIONARY MEMORY)\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    titan = TITAN_INF()\n",
        "    titan.perceive(X_train_qt, y_train) # Train\n",
        "\n",
        "    print(\"\\n >>> PHASE 3: TITAN GLASS (INFINITE REFLECTION)\")\n",
        "    # Prediction (Glass is applied automatically in predict())\n",
        "    titan_preds = titan.predict(X_test_qt)\n",
        "    titan_acc = accuracy_score(y_test, titan_preds)\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    results.append({\"Model\": \"TITAN INF\", \"Accuracy\": titan_acc, \"Time\": elapsed})\n",
        "\n",
        "    # 4. FINAL REPORT\n",
        "    df = pd.DataFrame(results).sort_values(by=\"Accuracy\", ascending=False)\n",
        "\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\" >>> FINAL INTELLIGENCE REPORT: {name}\")\n",
        "    print(f\"{'='*100}\")\n",
        "    print(f\"{'RANK':<6} | {'MODEL ARCHITECTURE':<25} | {'ACCURACY':<12} | {'ERROR RATE':<12}\")\n",
        "    print(f\"{'-'*100}\")\n",
        "\n",
        "    rank = 1\n",
        "    for row in df.itertuples():\n",
        "        error_rate = 1.0 - row.Accuracy\n",
        "        model_name = row.Model\n",
        "        if \"TITAN\" in model_name: model_name = f\"** {model_name} **\"\n",
        "\n",
        "        print(f\" #{rank:<5} | {model_name:<25} | {row.Accuracy:.4%}     | {error_rate:.4%}\")\n",
        "        rank += 1\n",
        "    print(f\"{'='*100}\\n\")\n",
        "\n",
        "# --- EXECUTE PROTOCOL ---\n",
        "if __name__ == \"__main__\":\n",
        "    print('Active')\n"
      ],
      "metadata": {
        "id": "lyhf3GlbLfTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4bea88-f958-45fb-fd73-93a2af3ab369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> [TITAN PROTOCOL] T4 GPU DETECTED. INFINITE MEMORY ENGINE ONLINE.\n",
            "Active\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TITAN_VS_GOLIATHS(1479, \"Hill Valley\")"
      ],
      "metadata": {
        "id": "XSnkJrmpgSLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TITAN_VS_GOLIATHS(1120, \"Magic Gamma Telescope\")"
      ],
      "metadata": {
        "id": "kmsh6BwKQYSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TITAN_VS_GOLIATHS(1494, \"QSAR Biodegradation\")"
      ],
      "metadata": {
        "id": "d4p3rJE0aBs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TITAN_VS_GOLIATHS(4534, \"Phishing Websites\")"
      ],
      "metadata": {
        "id": "LReMQDjcfas9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fj6_Q7nRf6-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}